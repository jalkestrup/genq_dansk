{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jealk/mambaforge/envs/llama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get documents from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from hub\n",
    "ds_vejledninger = load_dataset(\n",
    "    \"jealk/dk_retrieval_benchmark\",\n",
    "    \"retsinformation\",\n",
    "    split=\"train\",\n",
    "    #download_mode=\"force_redownload\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>html_content</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.\\n1.Indledni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "1  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "2  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "3  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "4  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Vejledning om regulering af satser fra 1. janu...   \n",
       "1  Vejledning om satser i 2024 for betaling af ud...   \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...   \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...   \n",
       "4                 Vejledning om fleksløntilskud m.v.   \n",
       "\n",
       "                                        html_content  \\\n",
       "0  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "1  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "2  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "3  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "4  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "\n",
       "                                        text_content  \n",
       "0  Vejledning om regulering af satser fra 1. janu...  \n",
       "1  Vejledning om satser i 2024 for betaling af ud...  \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...  \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...  \n",
       "4  Vejledning om fleksløntilskud m.v.\\n1.Indledni...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe from the dataset using the huggingface datasets library\n",
    "df_vejledninger = ds_vejledninger.to_pandas()\n",
    "df_vejledninger.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function overview\n",
    "\n",
    "- Step 0: Chunking text\n",
    "    - Include or not?\n",
    "- Step 1: Filter chunks\n",
    "    - W. Textdescriptives\n",
    "    - W. LLM call, egnet til spørgsmål?\n",
    "- Step 2: Generate questions:\n",
    "    - Using LLamaIndex\n",
    "- Step 3: Filter generated questions\n",
    "    - (Text descriptives for long texts)\n",
    "    - LLM call: Is the answer found in chunk?\n",
    "    - LLM call: Is the answer clear and in a natural language?\n",
    "- Step 4: Update chunk-question table\n",
    "    - Embed chunks, embed questions (Local Vector DB)\n",
    "    - Use vector search to identify top 10 matches\n",
    "    - (Optional, Rerank)\n",
    "    - Filtering: Flag query/chunks where intended match is not in Top @10\n",
    "    - If question/chunk not @1\n",
    "        - Use LLM to check any question/chunk scored > than \"real\" match\n",
    "        - Update Match Matrix if OK\n",
    "    - If Delta simililarity score from 'real match' to other top @10 is < threshold:\n",
    "        - Use LLM to check question/chunk\n",
    "        - Update Match Matrix if OK\n",
    "- Step 5: Convert to BEIR format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langchain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-base-v2\")\n",
    "\n",
    "def token_length_function(text_input):\n",
    "  return len(tokenizer.encode(text_input, add_special_tokens=False))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 0,\n",
    "    length_function = token_length_function,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \"]\n",
    ")\n",
    "\n",
    "split_texts = text_splitter.split_text(df_vejledninger[\"text_content\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_documents = text_splitter.create_documents(list(df_vejledninger[\"text_content\"]), metadatas = [{\"title\": title} for title in df_vejledninger[\"title\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Llamaindex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "from llama_index.core import Document\n",
    "\n",
    "\n",
    "def create_documents(text: List[str], metadata: List[Dict[str, Any]]) -> List[Document]:\n",
    "    \"\"\"Create a list of llama_index documents from a list of strings and a list of dictionaries\n",
    "\n",
    "    Args:\n",
    "    text: A list of strings containing the text of the documents, eg. [\"Vejledning om ...\", \"...\"]\n",
    "    metadata: A list of dictionaries containing one or multiple metadata, eg. [{\"title\": \"Example 1\", \"source\": \"website_url\"}, {...}]\n",
    "\n",
    "    Returns:\n",
    "    A list of llama_index documents\n",
    "    \"\"\"\n",
    "    documents = [\n",
    "        Document(text=content, metadata=meta) for content, meta in zip(text, metadata)\n",
    "    ]\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_documents = create_documents(df_vejledninger[\"text_content\"], df_vejledninger[[\"title\", \"url\"]].to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes:   0%|          | 0/433 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (24739 > 512). Running this sequence through the model will result in indexing errors\n",
      "Parsing nodes: 100%|██████████| 433/433 [00:55<00:00,  7.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from transformers import AutoTokenizer\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "\n",
    "def document_splitter(\n",
    "    documents: List[Document],\n",
    "    chunk_size: int = 512,\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"intfloat/e5-base-v2\"),\n",
    ") -> List[TextNode]:\n",
    "    \"\"\"Split a list of llama_index documents into nodes\n",
    "\n",
    "    Args:\n",
    "    documents: A list of llama_index documents\n",
    "    chunk_size: An integer defining the maximum number of tokens in each node\n",
    "    tokenizer: A tokenizer from the Hugging Face transformers library\n",
    "\n",
    "    Returns:\n",
    "    A list of nodes, consisting of text, metadata, embeddings and node-relations\n",
    "    \"\"\"\n",
    "    node_parser = SentenceSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=0,\n",
    "        secondary_chunking_regex=str([\"\\n\"]),\n",
    "        paragraph_separator=str([\"\\n\\n\"]),\n",
    "        tokenizer=tokenizer.tokenize,\n",
    "    )\n",
    "    nodes = node_parser.get_nodes_from_documents(documents, show_progress=True)\n",
    "    return nodes\n",
    "\n",
    "\n",
    "nodes_vejledninger = document_splitter(llama_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering using text descriptives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langchain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdescriptives as td\n",
    "import spacy\n",
    "from typing import List, Dict, Optional\n",
    "import os\n",
    "\n",
    "#add optional meta data, list of dicts\n",
    "def filter_text_by_td(text_list: List[str], filter_type: bool=True) -> List[str]:\n",
    "    \"\"\"Filter nodes by the textdescriptives quality check\n",
    "\n",
    "    Args:\n",
    "    text_list> a list of stext strings\n",
    "    fiter_type: A boolean defining whether to filter by texts that passed (True) or failed (False) the textdescriptives quality check\n",
    "\n",
    "    Returns:\n",
    "    A list of text chunks that passed the textdescriptives quality check\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank(\"da\")\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    quality_pipe = nlp.add_pipe(\"textdescriptives/quality\")\n",
    "    docs = list(nlp.pipe(text_list))\n",
    "    filtered_texts = [doc.text for doc in docs if doc._.passed_quality_check==filter_type]\n",
    "    \n",
    "    return filtered_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_passed_td = filter_text_by_td([text.page_content for text in split_documents[0:300]])\n",
    "docs_passed_td = [doc for doc in split_documents if doc.page_content in texts_passed_td]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LlamaIndex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_vejledninger_sample = nodes_vejledninger[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextNode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtextdescriptives\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_nodes_by_td\u001b[39m(nodes: List[\u001b[43mTextNode\u001b[49m], filter_type: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[TextNode]:\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Filter nodes by the textdescriptives quality check\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    A list of llama_index nodes that passed the textdescriptives quality check\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mblank(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TextNode' is not defined"
     ]
    }
   ],
   "source": [
    "import textdescriptives as td\n",
    "import spacy\n",
    "\n",
    "def filter_nodes_by_td(nodes: List[TextNode], filter_type: bool=True) -> List[TextNode]:\n",
    "    \"\"\"Filter nodes by the textdescriptives quality check\n",
    "\n",
    "    Args:\n",
    "    nodes: A list of llama_index nodes\n",
    "    fiter_type: A boolean defining whether to filter by nodes that passed (True) or failed (False) the textdescriptives quality check\n",
    "\n",
    "    Returns:\n",
    "    A list of llama_index nodes that passed the textdescriptives quality check\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank(\"da\")\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    quality_pipe = nlp.add_pipe(\"textdescriptives/quality\")\n",
    "    docs = list(nlp.pipe([node.text for node in nodes]))\n",
    "    filtered_nodes = [node for node, doc in zip(nodes, docs) if doc._.passed_quality_check==filter_type]\n",
    "    \n",
    "    return filtered_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter\n",
    "nodes_passed_td = filter_nodes_by_td(nodes_vejledninger_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering using LLM call**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Du er en erfaren sagsbehandler, nedenfor er eksempler på tekstuddrag og deres tilhørende score.\\n\\n    ============================\\n    Start på eksempel, som skal have scoren 1:\\n\\n    \"Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde Indledning Efter lov om arbejdsskadesikring, jf. lovbekendtgørelse nr. 1186 af 19. august 2022 med de ændringer, der følger af lov nr. 1541 af 12. december 2023, og lov om sikring mod følger af arbejdsskade, jf. lovbekendtgørelse nr. 943 af 16. oktober 2000, skal der med virkning fra 1. januar 2024 efter indstilling fra bestyrelsen for Arbejdsmarkedets Erhvervssikring ske regulering af lovens årslønsbeløb, godtgørelsesbeløb, overgangsbeløb samt løbende erstatninger. Reguleringen af satserne fastsættes af Arbejdstilsynets direktør efter bemyndigelse fra beskæftigelsesministeren. Satser efter loven reguleres med 2 procent tillagt tilpasningsprocenten for finansåret 2024 (jf. lov om en satsreguleringsprocent).\"\\n\\n    Fordi uddraget indeholder klare og faktuelle informationer, hvorfra der kan formuleres et præcist, naturligt og kort spørgsmål der kan besvares ud fra uddraget, eksempelvis:\\n\\n    \"Hvem fastsætter reguleringen af satserne for arbejdsskadesikring og andre relaterede ydelser?\"\\n\\n    ============================\\n    Start på eksempel, som skal have scoren 0:\\n\\n    \"årligt. 8)Uddannelsesgodtgørelsen i en forlænget periode efter § 18 b, stk. 3, 2. pkt., udgør 244.140 kr. årligt. Grundlønnen for beregning og regulering af løbende erstatning og uddannelsesgodtgørelse for arbejdsskader indtruffet den 1. juli 2024 eller senere er den efter lov om arbejdsskadesikring § 24 fastsatte årsløn multipliceret med 608.000/608.000, jf. § 24 a. Fastsættes en løbende erstatning eller en uddannelsesgodtgørelse den 1. juli 2024 eller senere, udbetales erstatningen eller godtgørelsen fra tidspunktet for dennes begyndelse med et tillæg på 0,0 pct. til den erstatning eller godtgørelse, der svarer til grundlønnen. Satser for arbejdsskader indtruffet i tiden 1. januar 2024 til 30. juni 2024 Med virkning for arbejdsskader efter lov om arbejdsskadesikring, jf. lovbekendtgørelse nr. 1186 af 19. august 2022 med de ændringer, der følger af lov nr.\"\\n\\n    Fordi der uddraget ikke indeholder meget detaljerede informationer der er svære at forstå uden kontekst, generelt er fragmenteret og gør det vanskeligt at formulere et generelt spørgsmål.\\n\\n    ==============================\\n    Uddrag som du skal give en score:\\n\\n    {chunk_text}\"\\n\\n    Returner KUN tallet 0 eller 1, ingen yderligere forklaring\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gample prompts\n",
    "\n",
    "#system prompt\n",
    "\"\"\"Din opgave er at evaluere hvorvidt et uddrag af en tekst, er egnet til at stille et generelt spørgsmål til.\n",
    "    Du skal vurdere om uddraget indeholder klare og faktuelle informationer, hvorfra der kan formuleres et præcist, naturligt og kort spørgsmål der kan besvares ud fra uddraget.\n",
    "    Du skal give scoren 1 til teksten, hvis der kan opstilles et naturligt formuleret spørgsmål til uddraget, som eksempelvis kunne bruges i sammenhæng med en eksamen eller test.\n",
    "    Du skal give scoren 0 til teksten, hvis uddraget ikke indeholder generel faktuel information, hvis teksten er for usammenhængende eller detaljeret til at kunne formulere et generelt spørgsmål.\n",
    "    Returner en json med key: llm_score og value i form af en int: \"0\" eller \"1\".\n",
    "\"\"\"\n",
    "\n",
    "#Few shot user prompt\n",
    "\"\"\" Du er en erfaren sagsbehandler, nedenfor er eksempler på tekstuddrag og deres tilhørende score.\n",
    "\n",
    "    ============================\n",
    "    Start på eksempel, som skal have scoren 1:\n",
    "\n",
    "    \"Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde Indledning Efter lov om arbejdsskadesikring, jf. lovbekendtgørelse nr. 1186 af 19. august 2022 med de ændringer, der følger af lov nr. 1541 af 12. december 2023, og lov om sikring mod følger af arbejdsskade, jf. lovbekendtgørelse nr. 943 af 16. oktober 2000, skal der med virkning fra 1. januar 2024 efter indstilling fra bestyrelsen for Arbejdsmarkedets Erhvervssikring ske regulering af lovens årslønsbeløb, godtgørelsesbeløb, overgangsbeløb samt løbende erstatninger. Reguleringen af satserne fastsættes af Arbejdstilsynets direktør efter bemyndigelse fra beskæftigelsesministeren. Satser efter loven reguleres med 2 procent tillagt tilpasningsprocenten for finansåret 2024 (jf. lov om en satsreguleringsprocent).\"\n",
    "\n",
    "    Fordi uddraget indeholder klare og faktuelle informationer, hvorfra der kan formuleres et præcist, naturligt og kort spørgsmål der kan besvares ud fra uddraget, eksempelvis:\n",
    "\n",
    "    \"Hvem fastsætter reguleringen af satserne for arbejdsskadesikring og andre relaterede ydelser?\"\n",
    "\n",
    "    ============================\n",
    "    Start på eksempel, som skal have scoren 0:\n",
    "\n",
    "    \"årligt. 8)Uddannelsesgodtgørelsen i en forlænget periode efter § 18 b, stk. 3, 2. pkt., udgør 244.140 kr. årligt. Grundlønnen for beregning og regulering af løbende erstatning og uddannelsesgodtgørelse for arbejdsskader indtruffet den 1. juli 2024 eller senere er den efter lov om arbejdsskadesikring § 24 fastsatte årsløn multipliceret med 608.000/608.000, jf. § 24 a. Fastsættes en løbende erstatning eller en uddannelsesgodtgørelse den 1. juli 2024 eller senere, udbetales erstatningen eller godtgørelsen fra tidspunktet for dennes begyndelse med et tillæg på 0,0 pct. til den erstatning eller godtgørelse, der svarer til grundlønnen. Satser for arbejdsskader indtruffet i tiden 1. januar 2024 til 30. juni 2024 Med virkning for arbejdsskader efter lov om arbejdsskadesikring, jf. lovbekendtgørelse nr. 1186 af 19. august 2022 med de ændringer, der følger af lov nr.\"\n",
    "\n",
    "    Fordi der uddraget ikke indeholder meget detaljerede informationer der er svære at forstå uden kontekst, generelt er fragmenteret og gør det vanskeligt at formulere et generelt spørgsmål.\n",
    "\n",
    "    ==============================\n",
    "    Uddrag som du skal give en score:\n",
    "\n",
    "    {chunk_text}\"\n",
    "\n",
    "    Returner KUN tallet 0 eller 1, ingen yderligere forklaring\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def q_eval_system_prompt():\n",
    "    sys_prompt = \"\"\"Din opgave er at evaluere et givet tekstuddrag for at bestemme, om det er egnet til at danne grundlag for et generelt spørgsmål, der er relevant for eksempelvis en eksamen eller en test. \n",
    "    For at vurdere dette, skal du fokusere på følgende tre nøglekriterier:\n",
    "\n",
    "    1. Klarhed: Vurder, om teksten er formuleret klart og direkte, således at et spørgsmål til denne tekst, vil kunne besvares uden yderligere forklaringer. Teksten skal være læsbar og ikke usammenhængende i sin struktur.\n",
    "    \n",
    "    2. Konkret Information: Afgør, om uddraget indeholder specifikke, faktuelle informationer, der kan danne grundlag for et præcist og direkte spørgsmål. Teksten skal præsentere håndgribelige fakta eller data, som et spørgsmål kan baseres på.\n",
    "\n",
    "    3. Kontekstuel Helhed: Bedøm, om teksten leverer tilstrækkelig kontekst for at et spørgsmål baseret på uddraget vil være meningsfuldt og forståeligt uden behov for yderligere information. Teksten skal være selvstændig og give en fuld forståelse af det emne, der behandles.\n",
    "\n",
    "    Baseret på din evaluering:\n",
    "\n",
    "    - Tildel scoren 1, hvis tekstuddraget opfylder alle tre kriterier, og der kan formuleres et naturligt, klart og kontekstuelt meningsfuldt spørgsmål baseret på teksten.\n",
    "\n",
    "    - Tildel scoren 0, hvis tekstuddraget ikke opfylder et eller flere af de ovenstående kriterier, hvilket gør det uegnet til at danne grundlag for et generelt spørgsmål.\n",
    "    \"\"\"\n",
    "    return sys_prompt\n",
    "\n",
    "def q_eval_user_prompt(text: str) -> str:\n",
    "    \"\"\"Prepare the prompt for the API call.\"\"\"\n",
    "    \n",
    "    qa_egnet_tmlp = \"\"\"Du er en erfaren sagsbehandler. \n",
    "    Din Opgave:\n",
    "    Vurder det følgende tekstuddrag og angiv, om det er egnet til at stille et generelt spørgsmål til.\n",
    "\n",
    "    Uddrag:\n",
    "    {chunk_text}\n",
    "    \n",
    "    Returner din vurdering i følgende JSON-format:\n",
    "\n",
    "    {{\n",
    "    \"llm_score\": [indsæt enten 0 eller 1 her]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return qa_egnet_tmlp.format(chunk_text=text)\n",
    "\n",
    "\n",
    "def json_api_call(system_prompt: str, user_prompt: str, oai_model: str=\"gpt-3.5-turbo-0125\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {}\n",
    "\n",
    "def filter_text_by_llm(text_list: List[str]) -> List[str]:\n",
    "    \"\"\"Filter text chunks by a LLM quality check\n",
    "    \n",
    "    Args: A list of text strings\n",
    "    \n",
    "    Returns: A list of text chunks that passed the LLM quality check\n",
    "    \"\"\"\n",
    "    texts_passed_llm = []\n",
    "    system_prompt = q_eval_system_prompt()\n",
    "    for text in tqdm(text_list, desc=\"Evaluating texts\"):\n",
    "        user_prompt = q_eval_user_prompt(text)\n",
    "        response = json_api_call(system_prompt, user_prompt)\n",
    "        if response:\n",
    "            if response['llm_score'] == 1:\n",
    "                texts_passed_llm.append(text)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            logging.error(f'Failed to evaluate below text due to an earlier error. \\n {text}')\n",
    "    return texts_passed_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating texts: 100%|██████████| 50/50 [00:35<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "texts_passed_llm = filter_text_by_llm([text.page_content for text in docs_passed_td[:50]])\n",
    "docs_passed_llm = [doc for doc in split_documents if doc.page_content in texts_passed_llm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Llamaindex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nodes_by_llm(node_list: List[TextNode]) -> List[TextNode]:\n",
    "    \"\"\"Filter nodes by the llama quality check\n",
    "\n",
    "    Args:\n",
    "    nodes: A list of llama_index nodes\n",
    "    \n",
    "    Returns:\n",
    "    A list of llama_index nodes that passed the llama quality check\n",
    "    \"\"\"\n",
    "    nodes_passed_list = []\n",
    "    system_prompt = q_eval_system_prompt()\n",
    "    for llama_node in node_list:\n",
    "        user_prompt = q_eval_user_prompt(llama_node.text)\n",
    "        response = json_api_call(system_prompt, user_prompt)\n",
    "        if response:\n",
    "            if response['llm_score'] == 1:\n",
    "                nodes_passed_list.append(llama_node)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            logging.error(f'Failed to evaluate below node due to an earlier error. \\n {llama_node.text}')\n",
    "    return nodes_passed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_passed_llm = filter_nodes_by_llm(nodes_passed_td[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes_passed_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run on the last 20 nodes in the list\n",
    "nodes_passed_llm_last = filter_nodes_by_llm(nodes_passed_td[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment to compare how LLM filtering performs compared to text descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of nodes that fail the textdescriptives quality check\n",
    "nodes_failed_td = filter_nodes_by_td(nodes_vejledninger_sample, filter_type=False)\n",
    "len(nodes_failed_td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of nodes that passed the textdescriptives quality check: {len(nodes_passed_td)}')\n",
    "print(f'Number of nodes that failed the textdescriptives quality check: {len(nodes_failed_td)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample first 100 each node type\n",
    "nodes_failed_td_sample = nodes_failed_td[:20]\n",
    "nodes_passed_td_sample = nodes_passed_td[:20]\n",
    "\n",
    "#Evaluate the nodes\n",
    "evaluate_node_list(nodes_failed_td_sample)\n",
    "evaluate_node_list(nodes_passed_td_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of llm_scores for each group using Counter\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "passed_td_meta = [node.metadata for node in nodes_passed_td_sample]\n",
    "failed_td_meta = [node.metadata for node in nodes_failed_td_sample]\n",
    "\n",
    "passed_td_llm_count = dict(Counter([meta[\"llm_score\"] for meta in passed_td_meta]))\n",
    "failed_td_llm_count = dict(Counter([meta[\"llm_score\"] for meta in failed_td_meta]))\n",
    "\n",
    "#Plot a confusion matrix where x-axis is the Truth, LLM evaluation, and y-axis is the Predicted, Textdescriptives quality check\n",
    "#The matrix is a 2x2 matrix with the following values:\n",
    "TP = passed_td_llm_count[1] if 1 in passed_td_llm_count else 0\n",
    "FP = passed_td_llm_count[0] if 0 in passed_td_llm_count else 0\n",
    "TN = failed_td_llm_count[0] if 0 in failed_td_llm_count else 0\n",
    "FN = failed_td_llm_count[1] if 1 in failed_td_llm_count else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "confusion_matrix = np.array([[TP, FP], [FN, TN]])\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Passed\", \"Failed\"],\n",
    "            yticklabels=[\"Passed\", \"Failed\"])\n",
    "plt.xlabel('LLM eval')\n",
    "plt.ylabel('Textdescriptives')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion after inspecting 40 samples**\n",
    "General alignment between LLM and text descriptives. \n",
    "- 80% of those texts that pass TD also pass LLM (true positives)\n",
    "- 60% of those who fail TD also fail LLM (true negatives)\n",
    "- A fairly high rate of false negatives in the sense that 40% of those who are filtered out by TD, are according to LLM eval suitable for questions. \n",
    "\n",
    "The cause of those false negatives seem mostly to stem from text containing many formulas or lists, ex. below:\n",
    "\n",
    "*Månedlig erstatning: 8.625 kr.\\nc.Uddannelsesgodtgørelse\\nSkadedato: 2. juli 2024. Årsløn: 425.000 kr.\\nGrundløn: 425.000 kr. × 608.000/608.000 = 425.000 kr.\\nGrundydelse: 0,83 × 425.000 kr. = 352.750,00 kr. årligt.\\nÅrlig godtgørelse fra 1. juli 2024: 352.750,00 kr. × 1,000 = 352.750,00 kr., der forhøjes til nærmeste med 12 delelige kronebeløb: 352.752 kr.\\nMånedlig godtgørelse: 29.396 kr.\\n1.2 Engangsbeløb\\nSkadedato: 8. juli 2024. Afgørelsesdato: 6. december 2024. Årsløn: 350.000 kr. Tab af erhvervsevne: 25 pct. Varigt mén: 20 pct. Alder ved afgørelsen: 35 år og 2 måneder.\\na.Erstatning for tab af erhvervsevne\\nGrundløn: 350.000 kr. × 608.000/608.000 = 350.000 kr.\\nGrundydelse: 0,25 × 0,83 × 350.000 kr. × 0,92 = 66.815,00 kr. årligt.\\nÅrlig erstatning fra 1. januar 2024: 66.815,00 kr.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "### Generate questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "# Define your custom prompt template in Danish\n",
    "qa_sagsbehandler_prompt = \"\"\"Nedenfor er et uddrag (kontekst) fra en længere tekst:\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Givet ovenstående uddrag og ingen forudgående viden, er din opgave at generere præcis {num_questions_per_chunk} spørgsmål til teksten.\n",
    "En sætning skal kun indeholde 1 spørgsmål, og spørgsmålet skal være formuleret kort og præcist. \n",
    "Svaret til spørgsmålet, skal kunne findes i ovenstående uddrag.\n",
    "Spørgsmålet skal indeholde specifik kontekst, således at spørgsmålet efterfølgende kan besvares entydigt og uden kendskab til uddraget. \n",
    "Spørgsmålene skal stilles i et sprog som en borger uden juridisk ekspertise kan forstå.\n",
    "\n",
    "Eksempel på et spørgsmål der ikke har en specifik kontekst, og som fejlagtigt indeholder 2 spørgsmål i 1 sætning: \n",
    "\"Hvilket dokument har den nye vejledning erstattet, og hvornår blev den udsendt?\" -Da det ikke angivet hvilket dokument der er tale om, og derfor er svaret til spørgsmålet ikke entyidgt, uden kendskab til uddraget. Sætningen indeholder desuden 2 spørgsmål i samme sætning. \n",
    "\n",
    "Eksempel på et godt spørgsmål, som kan besvares entydigt uden kendskab til uddraget:\n",
    "\"Hvilke to indbetalinger udgør det samlede medlemsbidrag til en a-kasse?\" - Da det er klart hvad der spørges om, og der kun er 1 rigtigt svar i den givne lovtekst.\n",
    "\"\"\"\n",
    "\n",
    "def llama_prompt_template(prompt_template: str) -> PromptTemplate:\n",
    "    return PromptTemplate(prompt_template)\n",
    "    \n",
    "    \n",
    "qa_sagsbehandler_tmlp = llama_prompt_template(qa_sagsbehandler_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import generate_qa_embedding_pairs\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "#wrap function to generate qa pairs\n",
    "def generate_questions(nodes: List[TextNode], qa_generate_prompt_tmpl: PromptTemplate, num_questions_per_chunk: int=1, llm = OpenAI(temperature=0.0, model=\"gpt-4-0125-preview\")) -> Dataset:\n",
    "    qa_dataset = generate_qa_embedding_pairs(\n",
    "        qa_generate_prompt_tmpl=qa_generate_prompt_tmpl,\n",
    "        llm=llm,\n",
    "        nodes=nodes,\n",
    "        num_questions_per_chunk=num_questions_per_chunk,\n",
    "    )\n",
    "    return qa_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:44<00:00,  3.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'583172c2-4055-4a60-92e3-0c8500fb7eb9': 'Hvem fastsætter reguleringen af satserne i henhold til loven om arbejdsskadesikring fra 1. januar 2024?',\n",
       " 'f8e65c2d-2f15-4967-82b8-ccbed0e68176': 'Hvordan beregnes grundlønnen for løbende erstatninger ifølge Arbejdstilsynets vejledning fra den 5. januar 2024?',\n",
       " '89878fed-4111-4526-aeec-3cf661aab2a2': 'Hvordan beregnes grundlønnen for arbejdsskader indtruffet mellem 1. januar 2004 og 31. december 2010 ifølge den givne lovtekst?',\n",
       " 'b4d706e4-31a1-49c0-adc4-aaefc1169371': 'Hvad er den forhøjede værdi af méngodtgørelsen for et varigt mén på 100 pct. ifølge loven fra 12. december 2023?',\n",
       " '08e4c1f8-6a5a-4c43-834a-51d9afdc82dd': 'Hvilke målgrupper er omfattet af pligten til selvbooking af jobsamtaler ifølge lovbekendtgørelse nr. 701 af 22. maj 2022?',\n",
       " 'bd4f044f-8e82-479f-961f-5985bb4da2a3': 'Hvor mange individuelle jobsamtaler med jobcenteret skal en person i ledighed have inden for de første 6 måneders ledighed?',\n",
       " '0afe26ca-c0cd-4ab7-95b5-60012a40731b': 'Hvem har ansvaret for at aftale det videre kontaktforløb efter de første 6 måneders ledighed?',\n",
       " 'd4640106-4142-45fb-890e-7434329d688c': 'Hvad kan en person ikke vælge som form for samtale ifølge den beskrevne lovtekst?',\n",
       " 'ce6c22da-0614-49af-8a6b-a734a0eee42e': 'Kan jobcenteret eller arbejdsløshedskassen ændre en aftalt telefonisk jobsamtale til en samtale med personligt fremmøde?',\n",
       " '57981d77-2ffe-433b-95a1-8a91985425e2': 'Hvordan kan jobsamtaler for personer på barsel afholdes, hvis personen anmoder om det?',\n",
       " '1db28be3-eaa6-441d-b1bd-a18a3302c5c9': 'Hvornår skal en dagpengemodtager senest have afholdt en jobsamtale i arbejdsløshedskassen efter tilmelding som jobsøgende?',\n",
       " 'fcb0febd-e088-4121-a0b6-71c317848603': 'Hvem skal som udgangspunkt selv booke jobsamtaler ifølge teksten?',\n",
       " '3c34a1ef-78c0-44df-90f8-2d3f0bbc3ec9': 'Hvordan kan en jobsamtale anses for indkaldt ifølge jobcenterets procedure for kontanthjælpsmodtagere og uddannelseshjælpsmodtagere?',\n",
       " '3f7ef7f6-5714-4ff9-9978-a47b31197558': 'Hvem har ansvaret for at indkalde dagpengemodtagere til deres første jobsamtale efter de første 3 måneders ledighed?'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset = generate_questions(nodes_passed_llm, qa_sagsbehandler_tmlp)\n",
    "qa_dataset.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative instead of using LLamaIndex (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_template(text: str, num_q: int=1) -> str:\n",
    "    question_tmlp = \"\"\"Nedenfor er et uddrag (kontekst) fra en længere tekst:\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Givet ovenstående uddrag og ingen forudgående viden, er din opgave at generere præcis {num_questions_per_chunk} spørgsmål til teksten.\n",
    "    En sætning skal kun indeholde 1 spørgsmål, og spørgsmålet skal være formuleret kort og præcist. \n",
    "    Svaret til spørgsmålet, skal kunne findes i ovenstående uddrag.\n",
    "    Spørgsmålet skal indeholde specifik kontekst, således at spørgsmålet efterfølgende kan besvares entydigt og uden kendskab til uddraget. \n",
    "    Spørgsmålene skal stilles i et sprog som en borger uden juridisk ekspertise kan forstå.\n",
    "\n",
    "    Eksempel på et spørgsmål der ikke har en specifik kontekst, og som fejlagtigt indeholder 2 spørgsmål i 1 sætning: \n",
    "    \"Hvilket dokument har den nye vejledning erstattet, og hvornår blev den udsendt?\" -Da det ikke angivet hvilket dokument der er tale om, og derfor er svaret til spørgsmålet ikke entyidgt, uden kendskab til uddraget. Sætningen indeholder desuden 2 spørgsmål i samme sætning. \n",
    "\n",
    "    Eksempel på et godt spørgsmål, som kan besvares entydigt uden kendskab til uddraget:\n",
    "    \"Hvilke to indbetalinger udgør det samlede medlemsbidrag til en a-kasse?\" - Da det er klart hvad der spørges om, og der kun er 1 rigtigt svar i den givne lovtekst.\n",
    "    \"\"\"\n",
    "    return question_tmlp.format(context_str=text, num_questions_per_chunk=num_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_api_call(user_prompt: str, oai_model: str=\"gpt-4-0125-preview\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Din opgave er at stille præcise spørgsmål til et givet tekstuddrag og returnere en JSON med en liste af spørgsmål i formatet {{Q: [spørgsmål1, spørsmål2, ...}}.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {'Q': 'API error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def generate_questions(text_list: list[str], llm_model: str=\"gpt-4-0125-preview\", no_questions: int=1) -> list[str]:\n",
    "    queries = {}\n",
    "    relevant_docs = {}\n",
    "    for text in tqdm(text_list):\n",
    "        question_prompt = generate_question_template(text, no_questions)\n",
    "        response = question_api_call(question_prompt, llm_model)\n",
    "\n",
    "        #try to read the json response\n",
    "        try: \n",
    "            questions = response['Q']\n",
    "            for question in questions:\n",
    "                question_id = str(uuid.uuid4())\n",
    "                queries[question_id] = question\n",
    "                relevant_docs[question_id] = str(uuid.uuid4())\n",
    "        except:\n",
    "            print(f'Error parsing json response: {response}, expcted a list of {no_questions} questions')\n",
    "    return queries, relevant_docs\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "qer, docs = generate_questions([text.page_content for text in docs_passed_llm[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1c22968b-3a9b-4c11-90c8-ffe5d5bd0e6c': 'Hvem skal regulere løbende erstatninger tilkendt før 1. januar 2024?',\n",
       " 'aff5fb60-a9c0-4b1b-b9c4-d17b47686cc0': 'Hvordan beregnes grundlønnen for løbende erstatninger for tab af erhvervsevne ifølge Arbejdstilsynets vejledning fra den 5. januar 2024?',\n",
       " 'fa016ae7-0732-4e94-8819-ba98f9022f9d': 'Hvilke målgrupper er omfattet af pligten til selvbooking ifølge loven om en aktiv beskæftigelsesindsats fra 22. maj 2022?',\n",
       " 'e8e8c177-2050-4437-bf4f-4a767a84b8b0': 'Hvem har ansvaret for kontaktforløbet for dagpengemodtagere i de første 3 måneder fra 1. januar 2024?',\n",
       " 'ac94b479-370b-4f70-beb5-c26e2f656bb3': 'Hvor kan dagpengemodtagere foretage selvbooking af jobsamtaler?',\n",
       " '55bb37e6-c69e-4a62-9ec1-d24ccca49447': 'Hvordan opgøres ledighed for kontanthjælpsmodtagere og personer i jobafklaringsforløb ifølge lov om en aktiv beskæftigelsesindsats?',\n",
       " 'fb0664a1-672b-4cae-a365-cad0dcfbfe95': 'Hvem aftaler det videre kontaktforløb med jobcenteret efter de første 6 måneders ledighed?',\n",
       " 'b353ff4d-336d-4441-85e1-015093a9264f': \"Hvad kræves der for at opfylde betingelsen for 'personligt digitalt fremmøde' under en jobsamtale ifølge § 33, stk. 1, 2. pkt.?\",\n",
       " '25667d0a-3603-441c-912d-2ac192f4d9b5': 'Kan jobcenteret eller arbejdsløshedskassen ændre en personlig jobsamtale til en telefonisk samtale?',\n",
       " 'c5887f1c-bc99-4f63-835b-72cf2bceaab5': 'Hvordan kan personer på barsel vælge at deres jobsamtale skal foregå ifølge § 33, stk. 2, 3. pkt.?'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**old**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(text: str, num_q: int=1) -> Dict[str, Any]:\n",
    "    \"\"\"Generate questions for a chunk of text.\"\"\"\n",
    "    user_prompt = generate_question_template(text, num_q=num_q)\n",
    "    response = question_api_call(user_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hvem skal selv regulere løbende erstatninger, som er tilkendt før 1. januar 2024?',\n",
       " 'Hvad vil det fremgå af Arbejdsmarkedets Erhvervssikrings afgørelse vedrørende løbende erstatninger tilkendt i 2024?',\n",
       " 'Hvem er fritaget for at afgive risikoen efter loven?']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = generate_questions(texts_passed_llm[0], 3)\n",
    "q1['Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hvem skal selv regulere løbende erstatninger, som er tilkendt før 1. januar 2024?'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1['Q'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3, Question filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def filter_qa_length(qa_dataset, char_max: int=150) -> Dataset:\n",
    "    # Step 1: Create a deep copy of the entire dataset\n",
    "    qa_copy = deepcopy(qa_dataset)\n",
    "    \n",
    "    # Step 2: Identify queries to remove based on length\n",
    "    queries_to_remove = [query_id for query_id, query_text in qa_copy.queries.items() if len(query_text) > char_max]\n",
    "    \n",
    "    # Step 3: Identify documents to remove associated with the queries\n",
    "    docs_to_remove = set()\n",
    "    for query_id in queries_to_remove:\n",
    "        associated_docs = qa_copy.relevant_docs.get(query_id, [])\n",
    "        docs_to_remove.update(associated_docs)\n",
    "    \n",
    "    # Step 4: Remove the identified queries and documents\n",
    "    for query_id in queries_to_remove:\n",
    "        del qa_copy.queries[query_id]  # Remove query\n",
    "        del qa_copy.relevant_docs[query_id]  # Remove entry from relevant_docs\n",
    "    \n",
    "    for doc_id in docs_to_remove:\n",
    "        del qa_copy.corpus[doc_id]  # Remove associated document\n",
    "    \n",
    "    return qa_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'583172c2-4055-4a60-92e3-0c8500fb7eb9': 'Hvem fastsætter reguleringen af satserne i henhold til loven om arbejdsskadesikring fra 1. januar 2024?',\n",
       " 'f8e65c2d-2f15-4967-82b8-ccbed0e68176': 'Hvordan beregnes grundlønnen for løbende erstatninger ifølge Arbejdstilsynets vejledning fra den 5. januar 2024?',\n",
       " '89878fed-4111-4526-aeec-3cf661aab2a2': 'Hvordan beregnes grundlønnen for arbejdsskader indtruffet mellem 1. januar 2004 og 31. december 2010 ifølge den givne lovtekst?',\n",
       " 'b4d706e4-31a1-49c0-adc4-aaefc1169371': 'Hvad er den forhøjede værdi af méngodtgørelsen for et varigt mén på 100 pct. ifølge loven fra 12. december 2023?',\n",
       " '08e4c1f8-6a5a-4c43-834a-51d9afdc82dd': 'Hvilke målgrupper er omfattet af pligten til selvbooking af jobsamtaler ifølge lovbekendtgørelse nr. 701 af 22. maj 2022?',\n",
       " 'bd4f044f-8e82-479f-961f-5985bb4da2a3': 'Hvor mange individuelle jobsamtaler med jobcenteret skal en person i ledighed have inden for de første 6 måneders ledighed?',\n",
       " '0afe26ca-c0cd-4ab7-95b5-60012a40731b': 'Hvem har ansvaret for at aftale det videre kontaktforløb efter de første 6 måneders ledighed?',\n",
       " 'd4640106-4142-45fb-890e-7434329d688c': 'Hvad kan en person ikke vælge som form for samtale ifølge den beskrevne lovtekst?',\n",
       " 'ce6c22da-0614-49af-8a6b-a734a0eee42e': 'Kan jobcenteret eller arbejdsløshedskassen ændre en aftalt telefonisk jobsamtale til en samtale med personligt fremmøde?',\n",
       " '57981d77-2ffe-433b-95a1-8a91985425e2': 'Hvordan kan jobsamtaler for personer på barsel afholdes, hvis personen anmoder om det?',\n",
       " '1db28be3-eaa6-441d-b1bd-a18a3302c5c9': 'Hvornår skal en dagpengemodtager senest have afholdt en jobsamtale i arbejdsløshedskassen efter tilmelding som jobsøgende?',\n",
       " 'fcb0febd-e088-4121-a0b6-71c317848603': 'Hvem skal som udgangspunkt selv booke jobsamtaler ifølge teksten?',\n",
       " '3c34a1ef-78c0-44df-90f8-2d3f0bbc3ec9': 'Hvordan kan en jobsamtale anses for indkaldt ifølge jobcenterets procedure for kontanthjælpsmodtagere og uddannelseshjælpsmodtagere?',\n",
       " '3f7ef7f6-5714-4ff9-9978-a47b31197558': 'Hvem har ansvaret for at indkalde dagpengemodtagere til deres første jobsamtale efter de første 3 måneders ledighed?'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_qa_dataset = filter_qa_length(qa_dataset, char_max=150)\n",
    "filtered_qa_dataset.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def q_simplify_system_prompt():\n",
    "    sys_prompt = \"\"\"Din opgave er simplificere et givet spørgsmål, så det er kortere, mere præcist og formuleret i et mere naturligt sprog. Fjern detaljer omkring specifikke paragraf, datoer osv.\"\"\"\n",
    "    return sys_prompt\n",
    "\n",
    "def q_simplify_question_prompt(text: str) -> str:\n",
    "    \"\"\"Prepare the prompt for the API call.\"\"\"\n",
    "    \n",
    "    qa_egnet_tmlp = \"\"\"\n",
    "    \n",
    "    Eksempel på et eksisterende spørgsmål: 'Hvor mange individuelle jobsamtaler med jobcenteret skal en person i ledighed have inden for de første 6 måneders ledighed i henhold til loven fra 1. januar 2024?'\n",
    "    Som kan omformuleres til: 'Hvor mange jobsamtaler skal en ledig have med jobcenteret inden for de første 6 måneder?'\n",
    "    \n",
    "    Nedenfor er et spørgsmål, som du skal analysere og hvis nødvendigt, omformulere:\n",
    "\n",
    "    Spørgsmål:\n",
    "    {chunk_text}\n",
    "    \n",
    "    Returner det omformulerede spørgsmål i følgende JSON-format:\n",
    "    \n",
    "        {{\n",
    "        \"simplified_q\": \"Dit omformulerede spørgsmål\"\n",
    "        }}\n",
    "    \"\"\"\n",
    "    return qa_egnet_tmlp.format(chunk_text=text)\n",
    "\n",
    "def rephrase_query(text: str) -> str:\n",
    "    \"\"\"Rephrase a given query.\"\"\"\n",
    "    user_prompt = q_simplify_question_prompt(text)\n",
    "    response = question_api_call(user_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hvem fastsætter reguleringen af satserne i henhold til loven om arbejdsskadesikring fra 1. januar 2024?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_q = list(filtered_qa_dataset.queries.values())[0]\n",
    "sample_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simplified_q': 'Hvem fastsætter satserne for arbejdsskadesikring i loven fra 1. januar 2024?'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_q = json_api_call(q_simplify_system_prompt(), q_simplify_question_prompt(sample_q))\n",
    "simplified_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might not seem nescesary / that it even improves the question at hand..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 4: Update chunk-question table\n",
    "    - Embed chunks, embed questions (Local Vector DB)\n",
    "    - Use vector search to identify top 10 matches\n",
    "    - (Optional, Rerank)\n",
    "    - Filtering: Flag query/chunks where intended match is not in Top @10\n",
    "    - If question/chunk not @1\n",
    "        - Use LLM to check any question/chunk scored > than \"real\" match\n",
    "        - Update Match Matrix if OK\n",
    "    - If Delta simililarity score from 'real match' to other top @10 is < threshold:\n",
    "        - Use LLM to check question/chunk\n",
    "        - Update Match Matrix if OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Embedding and update of chunk-question table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create vector index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "retriever = vector_index.as_retriever(similarity_top_k=2)\n",
    "retrieved_nodes = retriever.retrieve(\"What did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "\n",
    "\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=retriever\n",
    ")\n",
    "\n",
    "# try it out on a sample query\n",
    "sample_id, sample_query = list(qa_dataset.queries.items())[0]\n",
    "sample_expected = qa_dataset.relevant_docs[sample_id]\n",
    "eval_result = retriever_evaluator.evaluate(sample_query, sample_expected)\n",
    "print(eval_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
