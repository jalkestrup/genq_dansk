{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jealk/mambaforge/envs/llama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre: Getting chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 1.59k/1.59k [00:00<00:00, 13.6MB/s]\n",
      "Downloading data: 100%|██████████| 48.6k/48.6k [00:00<00:00, 382kB/s]\n",
      "Generating train split: 100%|██████████| 200/200 [00:00<00:00, 89164.63 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_vejledning</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>url</th>\n",
       "      <th>generated_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Hvem fastsætter reguleringen af satserne for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Med hvilken procent vil satserne for arbejdssk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>Tilpasningsprocenten er ved Finansministeriets...</td>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Hvad er tilpasningsprocenten for finansåret 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>Tilpasningsprocenten er ved Finansministeriets...</td>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Fra hvilken dato træder de nye satser i lov om...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>1541 af 12. december 2023 fastsættes løbende e...</td>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Fra hvilken dato vil arbejdsskader, der sker, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title_vejledning  \\\n",
       "0  Vejledning om regulering af satser fra 1. janu...   \n",
       "1  Vejledning om regulering af satser fra 1. janu...   \n",
       "2  Vejledning om regulering af satser fra 1. janu...   \n",
       "3  Vejledning om regulering af satser fra 1. janu...   \n",
       "4  Vejledning om regulering af satser fra 1. janu...   \n",
       "\n",
       "                                          chunk_text  \\\n",
       "0  Vejledning om regulering af satser fra 1. janu...   \n",
       "1  Vejledning om regulering af satser fra 1. janu...   \n",
       "2  Tilpasningsprocenten er ved Finansministeriets...   \n",
       "3  Tilpasningsprocenten er ved Finansministeriets...   \n",
       "4  1541 af 12. december 2023 fastsættes løbende e...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "1  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "2  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "3  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "4  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "\n",
       "                                  generated_question  \n",
       "0  Hvem fastsætter reguleringen af satserne for a...  \n",
       "1  Med hvilken procent vil satserne for arbejdssk...  \n",
       "2  Hvad er tilpasningsprocenten for finansåret 20...  \n",
       "3  Fra hvilken dato træder de nye satser i lov om...  \n",
       "4  Fra hvilken dato vil arbejdsskader, der sker, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load from hub\n",
    "ds_questions = load_dataset(\n",
    "    \"jealk/dk_retrieval_benchmark\",\n",
    "    \"generated_questions\",\n",
    "    split=\"train\",\n",
    "    download_mode=\"force_redownload\",\n",
    ")\n",
    "\n",
    "df_questions = ds_questions.to_pandas()\n",
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_vejledning</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>Tilpasningsprocenten er ved Finansministeriets...</td>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>1541 af 12. december 2023 fastsættes løbende e...</td>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>og det maksimale årslønsbeløb, der var gældend...</td>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>Satser for arbejdsskader indtruffet 1. juli 20...</td>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title_vejledning  \\\n",
       "0  Vejledning om regulering af satser fra 1. janu...   \n",
       "2  Vejledning om regulering af satser fra 1. janu...   \n",
       "4  Vejledning om regulering af satser fra 1. janu...   \n",
       "6  Vejledning om regulering af satser fra 1. janu...   \n",
       "8  Vejledning om regulering af satser fra 1. janu...   \n",
       "\n",
       "                                          chunk_text  \\\n",
       "0  Vejledning om regulering af satser fra 1. janu...   \n",
       "2  Tilpasningsprocenten er ved Finansministeriets...   \n",
       "4  1541 af 12. december 2023 fastsættes løbende e...   \n",
       "6  og det maksimale årslønsbeløb, der var gældend...   \n",
       "8  Satser for arbejdsskader indtruffet 1. juli 20...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.retsinformation.dk/eli/retsinfo/20...  \n",
       "2  https://www.retsinformation.dk/eli/retsinfo/20...  \n",
       "4  https://www.retsinformation.dk/eli/retsinfo/20...  \n",
       "6  https://www.retsinformation.dk/eli/retsinfo/20...  \n",
       "8  https://www.retsinformation.dk/eli/retsinfo/20...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename and drop columns to fit promptlayer evaluation\n",
    "# Drop generated_question\n",
    "df_questions = df_questions.drop(columns=[\"generated_question\"])\n",
    "# Delete every second row\n",
    "df_questions = df_questions[::2]\n",
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde\\nIndledning\\nEfter lov om arbejdsskadesikring, jf. lovbekendtgørelse nr. 1186 af 19. august 2022 med de ændringer, der følger af lov nr. 1541 af 12. december 2023, og lov om sikring mod følger af arbejdsskade, jf. lovbekendtgørelse nr. 943 af 16. oktober 2000, skal der med virkning fra 1. januar 2024 efter indstilling fra bestyrelsen for Arbejdsmarkedets Erhvervssikring ske regulering af lovens årslønsbeløb, godtgørelsesbeløb, overgangsbeløb samt løbende erstatninger.\\nReguleringen af satserne fastsættes af Arbejdstilsynets direktør efter bemyndigelse fra beskæftigelsesministeren.\\nSatser efter loven reguleres med 2 procent tillagt tilpasningsprocenten for finansåret 2024 (jf. lov om en satsreguleringsprocent).']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save chunk_text as a list of strings\n",
    "chunk_list = df_questions[\"chunk_text\"].apply(lambda x: [x])\n",
    "chunk_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre, getting documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 1.59k/1.59k [00:00<00:00, 7.49MB/s]\n",
      "Downloading data: 100%|██████████| 20.3M/20.3M [00:02<00:00, 8.90MB/s]\n",
      "Generating train split: 100%|██████████| 433/433 [00:00<00:00, 1631.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load from hub\n",
    "ds_vejledninger = load_dataset(\n",
    "    \"jealk/dk_retrieval_benchmark\",\n",
    "    \"retsinformation\",\n",
    "    split=\"train\",\n",
    "    download_mode=\"force_redownload\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>html_content</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.\\n1.Indledni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "1  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "2  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "3  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "4  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Vejledning om regulering af satser fra 1. janu...   \n",
       "1  Vejledning om satser i 2024 for betaling af ud...   \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...   \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...   \n",
       "4                 Vejledning om fleksløntilskud m.v.   \n",
       "\n",
       "                                        html_content  \\\n",
       "0  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "1  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "2  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "3  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "4  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "\n",
       "                                        text_content  \n",
       "0  Vejledning om regulering af satser fra 1. janu...  \n",
       "1  Vejledning om satser i 2024 for betaling af ud...  \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...  \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...  \n",
       "4  Vejledning om fleksløntilskud m.v.\\n1.Indledni...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe from the dataset using the huggingface datasets library\n",
    "df_vejledninger = ds_vejledninger.to_pandas()\n",
    "df_vejledninger.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function overview\n",
    "\n",
    "- Step 0: Chunking text\n",
    "    - Include or not?\n",
    "- Step 1: Filter chunks\n",
    "    - W. Textdescriptives\n",
    "    - W. LLM call, egnet til spørgsmål?\n",
    "- Step 2: Generate questions:\n",
    "    - Using LLamaIndex\n",
    "- Step 3: Filter generated questions\n",
    "    - (Text descriptives for long texts)\n",
    "    - LLM call: Is the answer found in chunk?\n",
    "    - LLM call: Is the answer clear and in a natural language?\n",
    "- Step 4: Update chunk-question table\n",
    "    - Embed chunks, embed questions (Local Vector DB)\n",
    "    - Use vector search to identify top 10 matches\n",
    "    - (Optional, Rerank)\n",
    "    - Filtering: Flag query/chunks where intended match is not in Top @10\n",
    "    - If question/chunk not @1\n",
    "        - Use LLM to check any question/chunk scored > than \"real\" match\n",
    "        - Update Match Matrix if OK\n",
    "    - If Delta simililarity score from 'real match' to other top @10 is < threshold:\n",
    "        - Use LLM to check question/chunk\n",
    "        - Update Match Matrix if OK\n",
    "- Step 5: Convert to BEIR format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "from llama_index.core import Document\n",
    "\n",
    "\n",
    "def create_documents(text: List[str], metadata: List[Dict[str, Any]]) -> List[Document]:\n",
    "    \"\"\"Create a list of llama_index documents from a list of strings and a list of dictionaries\n",
    "\n",
    "    Args:\n",
    "    text: A list of strings containing the text of the documents, eg. [\"Vejledning om ...\", \"...\"]\n",
    "    metadata: A list of dictionaries containing one or multiple metadata, eg. [{\"title\": \"Example 1\", \"source\": \"website_url\"}, {...}]\n",
    "\n",
    "    Returns:\n",
    "    A list of llama_index documents\n",
    "    \"\"\"\n",
    "    documents = [\n",
    "        Document(text=content, metadata=meta) for content, meta in zip(text, metadata)\n",
    "    ]\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create documents from the dataframe\n",
    "llama_documents = create_documents(\n",
    "    df_vejledninger[\"text_content\"],\n",
    "    df_vejledninger[[\"title\", \"url\"]].to_dict(orient=\"records\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Parsing nodes:   0%|          | 0/433 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (24739 > 512). Running this sequence through the model will result in indexing errors\n",
      "Parsing nodes: 100%|██████████| 433/433 [01:46<00:00,  4.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from transformers import AutoTokenizer\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "\n",
    "def document_splitter(\n",
    "    documents: List[Document],\n",
    "    chunk_size: int = 512,\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"intfloat/e5-base-v2\"),\n",
    ") -> List[TextNode]:\n",
    "    \"\"\"Split a list of llama_index documents into nodes\n",
    "\n",
    "    Args:\n",
    "    documents: A list of llama_index documents\n",
    "    chunk_size: An integer defining the maximum number of tokens in each node\n",
    "    tokenizer: A tokenizer from the Hugging Face transformers library\n",
    "\n",
    "    Returns:\n",
    "    A list of nodes, consisting of text, metadata, embeddings and node-relations\n",
    "    \"\"\"\n",
    "    node_parser = SentenceSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=0,\n",
    "        secondary_chunking_regex=str([\"\\n\"]),\n",
    "        paragraph_separator=str([\"\\n\\n\"]),\n",
    "        tokenizer=tokenizer.tokenize,\n",
    "    )\n",
    "    nodes = node_parser.get_nodes_from_documents(documents, show_progress=True)\n",
    "    return nodes\n",
    "\n",
    "\n",
    "nodes_vejledninger = document_splitter(llama_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_vejledninger_sample = nodes_vejledninger[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank(\"da\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "quality_pipe = nlp.add_pipe(\"textdescriptives/quality\")\n",
    "docs = list(nlp.pipe([node.text for node in nodes_vejledninger_sample]))\n",
    "bad = [node for node, doc in zip(nodes_vejledninger_sample, docs) if doc._.passed_quality_check==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering using text descriptives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_vejledninger_sample = nodes_vejledninger[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdescriptives as td\n",
    "import spacy\n",
    "\n",
    "def filter_nodes_by_quality(nodes: List[TextNode]) -> List[TextNode]:\n",
    "    \"\"\"Filter nodes by the textdescriptives quality check\n",
    "\n",
    "    Args:\n",
    "    nodes: A list of llama_index nodes\n",
    "\n",
    "    Returns:\n",
    "    A list of llama_index nodes that passed the textdescriptives quality check\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank(\"da\")\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    quality_pipe = nlp.add_pipe(\"textdescriptives/quality\")\n",
    "    docs = list(nlp.pipe([node.text for node in nodes]))\n",
    "    filtered_nodes = [node for node, doc in zip(nodes, docs) if doc._.passed_quality_check]\n",
    "    \n",
    "    return filtered_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter\n",
    "filtered_nodes = filter_nodes_by_quality(nodes_vejledninger_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering using LLM call**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your custom prompt template in Danish\n",
    "qa_egnet_tmlp = \"\"\" Din opgave er at vurdere hvorvidt et uddrag af en tekst indeholder faktuel information som gør uddraget egnet til at stille et generelt spørgsmål til. \n",
    "============================\n",
    "Start på eksempel som skal have scoren 1:\n",
    "\n",
    "\"Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde Indledning Efter lov om arbejdsskadesikring, jf. lovbekendtgørelse nr. 1186 af 19. august 2022 med de ændringer, der følger af lov nr. 1541 af 12. december 2023, og lov om sikring mod følger af arbejdsskade, jf. lovbekendtgørelse nr. 943 af 16. oktober 2000, skal der med virkning fra 1. januar 2024 efter indstilling fra bestyrelsen for Arbejdsmarkedets Erhvervssikring ske regulering af lovens årslønsbeløb, godtgørelsesbeløb, overgangsbeløb samt løbende erstatninger. Reguleringen af satserne fastsættes af Arbejdstilsynets direktør efter bemyndigelse fra beskæftigelsesministeren. Satser efter loven reguleres med 2 procent tillagt tilpasningsprocenten for finansåret 2024 (jf. lov om en satsreguleringsprocent).\"\n",
    "\n",
    "Fordi uddraget indeholder klare og faktuelle informationer, hvorfra der kan formuleres et præcist, naturligt og kort spørgsmål der kan besvares ud fra uddraget, eksempelvis\n",
    "\n",
    "\"Hvem fastsætter reguleringen af satserne for arbejdsskadesikring og andre relaterede ydelser?\"\n",
    "\n",
    "============================\n",
    "Start på eksempel som skal have scoren 0:\n",
    "\n",
    "\"årligt. 8)Uddannelsesgodtgørelsen i en forlænget periode efter § 18 b, stk. 3, 2. pkt., udgør 244.140 kr. årligt. Grundlønnen for beregning og regulering af løbende erstatning og uddannelsesgodtgørelse for arbejdsskader indtruffet den 1. juli 2024 eller senere er den efter lov om arbejdsskadesikring § 24 fastsatte årsløn multipliceret med 608.000/608.000, jf. § 24 a. Fastsættes en løbende erstatning eller en uddannelsesgodtgørelse den 1. juli 2024 eller senere, udbetales erstatningen eller godtgørelsen fra tidspunktet for dennes begyndelse med et tillæg på 0,0 pct. til den erstatning eller godtgørelse, der svarer til grundlønnen. Satser for arbejdsskader indtruffet i tiden 1. januar 2024 til 30. juni 2024 Med virkning for arbejdsskader efter lov om arbejdsskadesikring, jf. lovbekendtgørelse nr. 1186 af 19. august 2022 med de ændringer, der følger af lov nr.\"\n",
    "\n",
    "Fordi der uddraget ikke indeholder meget detaljerede informationer der er svære at forstå uden kontekst, generelt er mere fragmenteret og gør det vanskeligt at formulere et generelt spørgsmål.\n",
    "\n",
    "==============================\n",
    "Din opgave, hvordan du skal evaluere et uddrag:\n",
    "\n",
    "Såfremt der kan opstilles et naturligt formuleret og faktuelt spørgsmål til uddraget nedenfor, som man kunne forestille sig at bruge i sammenhæng med en eksamen eller test, skal du give scoren 1 til teksten. \n",
    "\n",
    "Hvis uddraget ikke indeholder generel faktuel information hvorfra man kunne formulere et naturligt spørgsmål, giv da uddraget en score på 0.\n",
    "\n",
    "==============================\n",
    "Uddrag som du skal score, 0 eller 1:\n",
    "\n",
    "{chunk_text}\"\n",
    "\n",
    "Returner KUN tallet 0 eller 1, ingen yderligere forklaring\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde',\n",
       " 'url': 'https://www.retsinformation.dk/eli/retsinfo/2024/9001',\n",
       " 'LLM filter': 1}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_nodes[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_text_to_evaluate = \"Her er et eksempel på tekst, der skal evalueres.\"\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def evaluate_chunk(chunk_text):\n",
    "    full_prompt = qa_egnet_tmlp.format(chunk_text=chunk_text)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Du er en erfaren sagsbehandler, der skal evaluere et uddrag af en tekst. Uddraget skal vurderes på hvorvidt det det er egnet til at stille et generelt spørgsmål til. Returner en json med llm_score: 0 eller 1.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": full_prompt},\n",
    "            # If you need to provide additional context or instructions, you can add more messages here\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = json.loads(evaluate_chunk(bad[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm_score': 1}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llm_score': 1}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 0}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 0}\n",
      "{'llm_score': 0}\n",
      "{'llm_score': 1}\n"
     ]
    }
   ],
   "source": [
    "#loop though first 10 nodes of bad and evaluate\n",
    "for node in bad[:10]:\n",
    "    ans = json.loads(evaluate_chunk(node.text))\n",
    "    print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llm_score': 1}\n",
      "{'llm_score': 0}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 1}\n",
      "{'llm_score': 1}\n"
     ]
    }
   ],
   "source": [
    "#loop though first 10 nodes of bad and evaluate\n",
    "for node in filtered_nodes[:10]:\n",
    "    ans = json.loads(evaluate_chunk(node.text))\n",
    "    print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "# Define your custom prompt template in Danish\n",
    "qa_sagsbehandler_tmlp = \"\"\" Nedenfor er et uddrag (kontekst) fra en længere tekst:\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Givet ovenstående uddrag og ingen forudgående viden, er din opgave at generere spørgsmål til teksten.\n",
    "Spørgsmålet skal indeholde specifik kontekst, således at spørgsmålet kan besvares uden tvetydighed udenfor uddraget. \n",
    "Du er en erfaren sagsbehandler, og din opgave er at stille præcis {num_questions_per_chunk} spørgsmål, som kan besvares i uddraget.\n",
    "Spørgsmålene skal være af forskellig karakter og dække teksten bredt, men stilles i et sprog som en borger uden juridisk ekspertise kan forstå.\n",
    "Svaret til spørgsmålet, skal kunne findes i ovenstående uddrag.\n",
    "\n",
    "Eksempel på et spørgsmål der ikke har en specifik kontekst: \n",
    "\"Hvilket dokument har den nye vejledning erstattet, og hvornår blev det tidligere dokument udsendt?\", da spørgsmålet er tvetydigt og vil have flere svarmuligheder afhængigt af hvilken vejledning og dokument der refereres til.\n",
    "\n",
    "Eksempel på et godt spørgsmål, som kan besvares uden kendskab til uddraget:\n",
    "\"Hvor meget vil godtgørelsen for et varigt mén være, hvis det er vurderet til 100%?\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "qa_sagsbehandler_tmlp = PromptTemplate(qa_sagsbehandler_tmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticCustomError",
     "evalue": "Invalid python path: No module named 'pydantic.deprecated.decorator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/pydantic/_internal/_validators.py:87\u001b[0m, in \u001b[0;36m_import_string_logic\u001b[0;34m(dotted_path)\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydantic.deprecated.decorator'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/pydantic/_internal/_validators.py:50\u001b[0m, in \u001b[0;36mimport_string\u001b[0;34m(value)\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/pydantic/_internal/_validators.py:96\u001b[0m, in \u001b[0;36m_import_string_logic\u001b[0;34m(dotted_path)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pydantic.deprecated.decorator'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPydanticCustomError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_qa_embedding_pairs\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# define LLM\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/llama_index/finetuning/__init__.py:13\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     EmbeddingQAFinetuneDataset,\n\u001b[1;32m      8\u001b[0m     generate_qa_embedding_pairs,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentence_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     SentenceTransformersFinetuneEngine,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientFinetuneEngine\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIFinetuneEngine\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrerankers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcohere_reranker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     CohereRerankerFinetuneEngine,\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/llama_index/finetuning/gradient/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientFinetuneEngine\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradientFinetuneEngine\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/llama_index/finetuning/gradient/base.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Optional, overload\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLLMFinetuneEngine\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientModelAdapterLLM\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGradientFinetuneEngine\u001b[39;00m(BaseLLMFinetuneEngine):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m         workspace_id: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/llama_index/llms/gradient/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBaseModelLLM, GradientModelAdapterLLM\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradientBaseModelLLM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradientModelAdapterLLM\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/llama_index/llms/gradient/base.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Optional, Sequence\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gradient\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     ChatMessage,\n\u001b[1;32m      6\u001b[0m     CompletionResponse,\n\u001b[1;32m      7\u001b[0m     CompletionResponseGen,\n\u001b[1;32m      8\u001b[0m     LLMMetadata,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbridge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Field, PrivateAttr\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/gradientai/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata \u001b[38;5;28;01mas\u001b[39;00m _metadata\n\u001b[1;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m _metadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradientai\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, CapabilityFilterOption\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_gradient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gradient\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Guidance, Model\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/gradientai/_base_model.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_model_adapter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelAdapter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/gradientai/_model.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Literal, Optional, TypedDict\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masyncio_threads\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_thread \u001b[38;5;28;01mas\u001b[39;00m _asyncio_to_thread\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomplete_model_body_params\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     CompleteModelBodyParams,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompleteResponse\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/gradientai/openapi/client/__init__.py:19\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    Gradient AI API\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    Do not edit the class manually.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# import apis into sdk package\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlocksApi\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingsApi\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/gradientai/openapi/client/api/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# import apis into api package\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlocksApi\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingsApi\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/gradientai/openapi/client/api/blocks_api.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_arguments, ValidationError\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Annotated\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constr\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/pydantic/__init__.py:374\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/pydantic/_migration.py:287\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(name)\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/llama/lib/python3.11/site-packages/pydantic/_internal/_validators.py:52\u001b[0m, in \u001b[0;36mimport_string\u001b[0;34m(value)\u001b[0m\n",
      "\u001b[0;31mPydanticCustomError\u001b[0m: Invalid python path: No module named 'pydantic.deprecated.decorator'"
     ]
    }
   ],
   "source": [
    "from llama_index.finetuning import generate_qa_embedding_pairs\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# define LLM\n",
    "llm_oai = OpenAI(temperature=0.0, model=\"gpt-4-0125-preview\")\n",
    "\n",
    "qa_dataset = generate_qa_embedding_pairs(\n",
    "    qa_generate_prompt_tmpl=qa_sagsbehandler_tmlp,\n",
    "    llm=llm_oai,\n",
    "    nodes=nodes_vejledninger_filtered[0:10],\n",
    "    num_questions_per_chunk=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an experienced software engineer and following best practice, write a function that takes a list of strings and"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
