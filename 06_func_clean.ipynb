{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function overview\n",
    "\n",
    "- Step 0: Loading and chunking text\n",
    "- Step 1: Filter contexts\n",
    "    - W. Textdescriptives\n",
    "    - W. LLM call, egnet til spørgsmål?\n",
    "- Step 2: Generate questions\n",
    "- Step 3: Filter generated questions\n",
    "    - Text length\n",
    "    - (Opt: LLM call: Is the answer clear and in a natural language?)\n",
    "- Step 4: Update context-question pairs\n",
    "    - Embed chunks, embed questions (Local Vector DB)\n",
    "    - Use vector search to identify top k matches\n",
    "    - If \"source\" context-question pair not in @1\n",
    "        - Use LLM to check any context that scored > than \"source\" context\n",
    "        - If context passes LLM check, update context-question pair to include additional context IDs\n",
    "\n",
    "Not done yet\n",
    "- Step 5: Convert to BEIR format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jealk/mambaforge/envs/llama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from hub\n",
    "ds_vejledninger = load_dataset(\n",
    "    \"jealk/dk_retrieval_benchmark\",\n",
    "    \"retsinformation\",\n",
    "    split=\"train\",\n",
    "    #download_mode=\"force_redownload\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>html_content</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.\\n1.Indledni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "1  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "2  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "3  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "4  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Vejledning om regulering af satser fra 1. janu...   \n",
       "1  Vejledning om satser i 2024 for betaling af ud...   \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...   \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...   \n",
       "4                 Vejledning om fleksløntilskud m.v.   \n",
       "\n",
       "                                        html_content  \\\n",
       "0  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "1  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "2  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "3  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "4  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "\n",
       "                                        text_content  \n",
       "0  Vejledning om regulering af satser fra 1. janu...  \n",
       "1  Vejledning om satser i 2024 for betaling af ud...  \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...  \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...  \n",
       "4  Vejledning om fleksløntilskud m.v.\\n1.Indledni...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe from the dataset using the huggingface datasets library\n",
    "df_vejledninger = ds_vejledninger.to_pandas()\n",
    "df_vejledninger.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Chunking text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-base-v2\")\n",
    "\n",
    "def token_length_function(text_input):\n",
    "  return len(tokenizer.encode(text_input, add_special_tokens=False))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 0,\n",
    "    length_function = token_length_function,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For some reason, Langchains text splitter is horribly slow (compared to llamaindex) takes 2+ minutes to run on my CPU\n",
    "split_documents = text_splitter.create_documents(list(df_vejledninger[\"text_content\"]), metadatas = [{\"title\": title} for title in df_vejledninger[\"title\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Filtering contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering using TextDescriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdescriptives as td\n",
    "import spacy\n",
    "from typing import List, Dict, Optional\n",
    "import os\n",
    "\n",
    "#add optional meta data, list of dicts\n",
    "def filter_text_by_td(text_list: List[str], filter_type: bool=True) -> List[str]:\n",
    "    \"\"\"Filter nodes by the textdescriptives quality check\n",
    "\n",
    "    Args:\n",
    "    text_list> a list of stext strings\n",
    "    fiter_type: A boolean defining whether to filter by texts that passed (True) or failed (False) the textdescriptives quality check\n",
    "\n",
    "    Returns:\n",
    "    A list of text chunks that passed the textdescriptives quality check\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank(\"da\")\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    quality_pipe = nlp.add_pipe(\"textdescriptives/quality\")\n",
    "    docs = list(nlp.pipe(text_list))\n",
    "    filtered_texts = [doc.text for doc in docs if doc._.passed_quality_check==filter_type]\n",
    "    \n",
    "    return filtered_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample 300 texts\n",
    "texts_passed_td = filter_text_by_td([text.page_content for text in split_documents[0:300]])\n",
    "docs_passed_td = [doc for doc in split_documents if doc.page_content in texts_passed_td]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def q_eval_system_prompt():\n",
    "    sys_prompt = \"\"\"Din opgave er at evaluere et givet tekstuddrag for at bestemme, om det er egnet til at danne grundlag for et generelt spørgsmål, der er relevant for eksempelvis en eksamen eller en test. \n",
    "    For at vurdere dette, skal du fokusere på følgende tre nøglekriterier:\n",
    "\n",
    "    1. Klarhed: Vurder, om teksten er formuleret klart og direkte, således at et spørgsmål til denne tekst, vil kunne besvares uden yderligere forklaringer. Teksten skal være læsbar og ikke usammenhængende i sin struktur.\n",
    "    \n",
    "    2. Konkret Information: Afgør, om uddraget indeholder specifikke, faktuelle informationer, der kan danne grundlag for et præcist og direkte spørgsmål. Teksten skal præsentere håndgribelige fakta eller data, som et spørgsmål kan baseres på.\n",
    "\n",
    "    3. Kontekstuel Helhed: Bedøm, om teksten leverer tilstrækkelig kontekst for at et spørgsmål baseret på uddraget vil være meningsfuldt og forståeligt uden behov for yderligere information. Teksten skal være selvstændig og give en fuld forståelse af det emne, der behandles.\n",
    "\n",
    "    Baseret på din evaluering:\n",
    "\n",
    "    - Tildel scoren 1, hvis tekstuddraget opfylder alle tre kriterier, og der kan formuleres et naturligt, klart og kontekstuelt meningsfuldt spørgsmål baseret på teksten.\n",
    "\n",
    "    - Tildel scoren 0, hvis tekstuddraget ikke opfylder et eller flere af de ovenstående kriterier, hvilket gør det uegnet til at danne grundlag for et generelt spørgsmål.\n",
    "    \"\"\"\n",
    "    return sys_prompt\n",
    "\n",
    "def q_eval_user_prompt(text: str) -> str:\n",
    "    \"\"\"Prepare the prompt for the API call.\"\"\"\n",
    "    \n",
    "    qa_egnet_tmlp = \"\"\"Du er en erfaren sagsbehandler. \n",
    "    Din Opgave:\n",
    "    Vurder det følgende tekstuddrag og angiv, om det er egnet til at stille et generelt spørgsmål til.\n",
    "\n",
    "    Uddrag:\n",
    "    {chunk_text}\n",
    "    \n",
    "    Returner din vurdering i følgende JSON-format:\n",
    "\n",
    "    {{\n",
    "    \"llm_score\": [indsæt enten 0 eller 1 her]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return qa_egnet_tmlp.format(chunk_text=text)\n",
    "\n",
    "\n",
    "def json_api_call(system_prompt: str, user_prompt: str, oai_model: str=\"gpt-3.5-turbo-0125\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {}\n",
    "\n",
    "def filter_text_by_llm(text_list: List[str]) -> List[str]:\n",
    "    \"\"\"Filter text chunks by a LLM quality check\n",
    "    \n",
    "    Args: A list of text strings\n",
    "    \n",
    "    Returns: A list of text chunks that passed the LLM quality check\n",
    "    \"\"\"\n",
    "    texts_passed_llm = []\n",
    "    system_prompt = q_eval_system_prompt()\n",
    "    for text in tqdm(text_list, desc=\"Evaluating texts\"):\n",
    "        user_prompt = q_eval_user_prompt(text)\n",
    "        response = json_api_call(system_prompt, user_prompt)\n",
    "        if response:\n",
    "            if response['llm_score'] == 1:\n",
    "                texts_passed_llm.append(text)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            logging.error(f'Failed to evaluate below text due to an earlier error. \\n {text}')\n",
    "    return texts_passed_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating texts: 100%|██████████| 50/50 [00:47<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#Sample just 50 texts\n",
    "texts_passed_llm = filter_text_by_llm([text.page_content for text in docs_passed_td[:50]])\n",
    "docs_passed_llm = [doc for doc in split_documents if doc.page_content in texts_passed_llm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generating Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_template(text: str, num_q: int=1) -> str:\n",
    "    question_tmlp = \"\"\"Nedenfor er et uddrag (kontekst) fra en længere tekst:\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Givet ovenstående uddrag og ingen forudgående viden, er din opgave at generere præcis {num_questions_per_chunk} spørgsmål til teksten.\n",
    "    En sætning skal kun indeholde 1 spørgsmål, og spørgsmålet skal være formuleret kort og præcist. \n",
    "    Svaret til spørgsmålet, skal kunne findes i ovenstående uddrag.\n",
    "    Spørgsmålet skal indeholde specifik kontekst, således at spørgsmålet efterfølgende kan besvares entydigt og uden kendskab til uddraget. \n",
    "    Spørgsmålene skal stilles i et sprog som en borger uden juridisk ekspertise kan forstå.\n",
    "\n",
    "    Eksempel på et spørgsmål der ikke har en specifik kontekst, og som fejlagtigt indeholder 2 spørgsmål i 1 sætning: \n",
    "    \"Hvilket dokument har den nye vejledning erstattet, og hvornår blev den udsendt?\" -Da det ikke angivet hvilket dokument der er tale om, og derfor er svaret til spørgsmålet ikke entyidgt, uden kendskab til uddraget. Sætningen indeholder desuden 2 spørgsmål i samme sætning. \n",
    "\n",
    "    Eksempel på et godt spørgsmål, som kan besvares entydigt uden kendskab til uddraget:\n",
    "    \"Hvilke to indbetalinger udgør det samlede medlemsbidrag til en a-kasse?\" - Da det er klart hvad der spørges om, og der kun er 1 rigtigt svar i den givne lovtekst.\n",
    "    \"\"\"\n",
    "    return question_tmlp.format(context_str=text, num_questions_per_chunk=num_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_api_call(user_prompt: str, oai_model: str=\"gpt-4-0125-preview\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Din opgave er at stille præcise spørgsmål til et givet tekstuddrag og returnere en JSON med en liste af spørgsmål i formatet {{Q: [spørgsmål1, spørsmål2, ...}}.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {'Q': 'API error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from langchain_core.documents import Document  # Import statement assumed; adjust based on actual import path\n",
    "\n",
    "class QuestionContextManager:\n",
    "    \"\"\"\n",
    "    Manages a collection of questions and their associated context chunks as Document objects.\n",
    "    Allows for adding questions with contexts and displaying a specified number of these question-context pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.questions: Dict[str, Document] = {}\n",
    "        self.contexts: Dict[str, Document] = {}\n",
    "        self.question_context_id_pairs: Dict[str, List[str]] = {}\n",
    "\n",
    "    def add_question_context(self, question: Document, context: Document):\n",
    "        \"\"\"\n",
    "        Adds a question and its associated context (both as Document objects) to the manager.\n",
    "        Generates unique IDs for both the question and the context, storing them and their association.\n",
    "\n",
    "        Parameters:\n",
    "        - question (Document): The Document object containing the question.\n",
    "        - context (Document): The Document object containing the context.\n",
    "        \"\"\"\n",
    "        unique_question_id = str(uuid.uuid4())\n",
    "        unique_context_id = str(uuid.uuid4())\n",
    "        self.questions[unique_question_id] = question\n",
    "        self.contexts[unique_context_id] = context\n",
    "        self.question_context_id_pairs[unique_question_id] = [unique_context_id]\n",
    "\n",
    "    @property\n",
    "    def question_context_pairs(self) -> List[Tuple[Document, List[Document]]]:\n",
    "        \"\"\"\n",
    "        Returns a list of tuples, each containing a question Document and a list of its associated context Documents.\n",
    "        \"\"\"\n",
    "        return [(self.questions[qid], [self.contexts[cid] for cid in self.question_context_id_pairs[qid]]) for qid in self.questions]\n",
    "\n",
    "    def display_question_context_pairs(self, num_pairs: int = None):\n",
    "        \"\"\"\n",
    "        Displays a specified number of question-context pairs. If no number is specified, all pairs are displayed.\n",
    "\n",
    "        Parameters:\n",
    "        - num_pairs (int, optional): The number of question-context pairs to display. If None, all pairs are displayed. Defaults to None.\n",
    "        \"\"\"\n",
    "        displayed_pairs = 0\n",
    "        for q_id, context_ids in self.question_context_id_pairs.items():\n",
    "            if num_pairs is not None and displayed_pairs >= num_pairs:\n",
    "                break\n",
    "\n",
    "            question = self.questions[q_id]\n",
    "            print(f\"Question: {question.page_content}\")\n",
    "            for c_id in context_ids:\n",
    "                context = self.contexts[c_id]\n",
    "                print(f\"\\nContext: {context.page_content}\")\n",
    "            print(\"-\" * 40)  # Separator for readability\n",
    "            displayed_pairs += 1\n",
    "\n",
    "    def filter_questions_by_length(self, min_length: int = 20, max_length: int = 150):\n",
    "        \"\"\"\n",
    "        Filters out questions that do not fall within the specified minimum and maximum character length.\n",
    "        Updates the object by removing questions and their associated contexts that do not meet the criteria.\n",
    "\n",
    "        Parameters:\n",
    "        - min_length (int): The minimum character length for questions to be kept. Default to 20.\n",
    "        - max_length (int): The maximum character length for questions to be kept. Default to 150.\n",
    "        \"\"\"\n",
    "        questions_to_remove = [q_id for q_id, question in self.questions.items()\n",
    "                               if not (min_length <= len(question.page_content) <= max_length)]\n",
    "\n",
    "        # Remove the questions and question_context pairs\n",
    "        for q_id in questions_to_remove:\n",
    "            del self.questions[q_id]\n",
    "            del self.question_context_id_pairs[q_id]\n",
    "\n",
    "        # Identify contexts that are no longer linked to any questions\n",
    "        contexts_to_remove = {context_id for context_id in self.contexts\n",
    "                              if all(context_id not in contexts for contexts in self.question_context_id_pairs.values())}\n",
    "\n",
    "        # Remove these contexts\n",
    "        for context_id in contexts_to_remove:\n",
    "            del self.contexts[context_id]\n",
    "\n",
    "        print(f\"Removed {len(questions_to_remove)} questions.\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<QuestionContextManager with {len(self.questions)} questions>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(textContexts: List[Document], num_questions: int = 1, oai_model: str = \"gpt-4-0125-preview\", duplicate_metadata: bool = True) -> QuestionContextManager:\n",
    "    \"\"\"\n",
    "    Generates questions from a list of context Documents and returns a QuestionContextManager\n",
    "    containing the generated questions and their contexts.\n",
    "\n",
    "    Parameters:\n",
    "    - contexts (List[Document]): A list of Document objects to generate questions from.\n",
    "    - num_questions (int): Number of questions to generate per context. Default is 1.\n",
    "    - oai_model (str): The model to use for generating questions. Default is \"gpt-4-0125-preview\".\n",
    "    - duplicate_metadata (bool): If True, duplicate the metadata from context to the generated questions.\n",
    "\n",
    "    Returns:\n",
    "    QuestionContextManager: An object containing the generated questions and their contexts.\n",
    "    \"\"\"\n",
    "    result = QuestionContextManager()\n",
    "    for context in tqdm(textContexts):\n",
    "        question_prompt = generate_question_template(context.page_content, num_questions)\n",
    "        response = question_api_call(question_prompt, oai_model)  \n",
    "        try:\n",
    "            questions = response['Q']\n",
    "            for question_text in questions:\n",
    "                question_document = Document(page_content=question_text.strip(), metadata=context.metadata if duplicate_metadata else {})\n",
    "                result.add_question_context(question_document, context)\n",
    "        except KeyError as e:\n",
    "            print(f'Error parsing json response: {e}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:29<00:00,  2.99s/it]\n"
     ]
    }
   ],
   "source": [
    "#Generate questions for a sub-sample of the passed documents\n",
    "qc_meta = generate_questions(docs_passed_llm[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Question filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 questions.\n",
      "Question: Hvem skal regulere løbende erstatninger tilkendt før 1. januar 2024?\n",
      "\n",
      "Context: De private arbejdsskadeforsikringsselskaber samt de arbejdsgivere, der er fritaget for at afgive risikoen efter loven, skal selv regulere løbende erstatninger, som er tilkendt før 1. januar 2024. Ved løbende erstatninger tilkendt i 2024 vil det fremgå af Arbejdsmarkedets Erhvervssikrings afgørelse, hvilke beløb, der skal udbetales i 2024.\n",
      "----------------------------------------\n",
      "Question: Hvordan beregnes grundlønnen for løbende erstatninger for tab af erhvervsevne ifølge Arbejdstilsynets vejledning fra den 5. januar 2024?\n",
      "\n",
      "Context: Arbejdstilsynet, den 5. januar 2024\n",
      "Sine Frederiksen\n",
      "/ Helle Klostergaard Christensen\n",
      "Bilag 1\n",
      "Bilaget indeholder eksempler på beregninger af kapitalerstatninger, godtgørelsesbeløb og overgangsbeløb samt løbende erstatninger og godtgørelser, som tilskadekomne eller dennes efterladte har ret til efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde.\n",
      "Arbejdsskader indtruffet i tiden 1. juli 2024 til 31. december 2024\n",
      "Til brug ved beregning og fremtidig regulering af løbende erstatninger for tab af erhvervsevne og tab af forsørger samt uddannelsesgodtgørelser beregnes grundlønnen (§ 24 a) ved at multiplicere den fastsatte årsløn med forholdet mellem den maksimale årsløn pr. 1. januar 2024 (608.000 kr.) og den maksimale årsløn på skadestidspunktet (608.000 kr.), det vil sige:\n",
      "Grundløn = årsløn × 608.000 / 608.000.\n",
      "Beløbet afrundes til hele kroner. Grundlønnen svarer til årslønnen reguleret tilbage til niveauet pr. 1. januar 2024.\n",
      "----------------------------------------\n",
      "Question: Hvem er omfattet af pligten til selvbooking ifølge loven om en aktiv beskæftigelsesindsats fra 22. maj 2022?\n",
      "\n",
      "Context: Indledning\n",
      "Denne vejledning omfatter pligt til selvbooking for visse målgrupper i lov om en aktiv beskæftigelsesindsats, jf. lovbekendtgørelse nr. 701 af 22. maj 2022. Pligt til selvbooking for sygedagpengemodtagere er ikke omfattet af denne vejledning.\n",
      "Pligt til selvbooking gælder for dagpengemodtagere, kontanthjælps- og uddannelseshjælpsmodtagere, overgangsydelsesmodtagere, som ikke er omfattet af introduktionsprogrammet efter integrationsloven, personer i jobafklaringsforløb, personer i ressourceforløb, fleksjobvisiterede, som modtager ledighedsydelse, og personer i revalideringsforløb.\n",
      "Pligt til selvbooking omfatter jobsamtaler efter kapitel 7 i lov om en aktiv beskæftigelsesindsats. Dagpengemodtagere har derudover pligt til at selvbooke rådighedssamtaler i arbejdsløshedskassen, hvis arbejdsløshedskassen har fastsat, at der skal ske selvbooking af en rådighedssamtale, jf. rådighedsbekendtgørelsens § 10 (bekendtgørelse nr. 1210 af 28. september 2023).\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "qc_meta.filter_questions_by_length()\n",
    "qc_meta.display_question_context_pairs(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Updating the question-context pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "collection_name = \"qc_collection\"\n",
    "\n",
    "# Check if the collection already exists\n",
    "if chroma_client.get_collection(collection_name):\n",
    "    # If it does, delete the existing collection\n",
    "    chroma_client.delete_collection(collection_name)\n",
    "\n",
    "db_collection = chroma_client.create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction('intfloat/multilingual-e5-base', normalize_embeddings=True),\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_qc_to_chroma(question_context_obj: QuestionContextManager, chroma_collection, question_prepend: str = \"query:\", context_prepend: str = \"passage:\"):\n",
    "    # Extracting question documents and their IDs\n",
    "    \"\"\"\n",
    "    question_documents = list(question_context_obj.questions.values())\n",
    "    question_texts = [f'{question_prepend} {doc.page_content}' for doc in question_documents]\n",
    "    question_ids = list(question_context_obj.questions.keys())\n",
    "    \n",
    "    # Assuming each Document can carry its own metadata, we can enrich the ChromaDB metadata with it\n",
    "    question_metadatas = [{\"type\": \"question\", **doc.metadata} for doc in question_documents]\n",
    "    \n",
    "    chroma_collection.add(\n",
    "        documents=question_texts,\n",
    "        ids=question_ids,\n",
    "        metadatas=question_metadatas\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Extracting context documents and their IDs\n",
    "    context_documents = list(question_context_obj.contexts.values())\n",
    "    context_texts = [f'{context_prepend} {doc.page_content}' for doc in context_documents]\n",
    "    context_ids = list(question_context_obj.contexts.keys())\n",
    "    \n",
    "    # Assuming each Document can carry its own metadata, we can enrich the ChromaDB metadata with it\n",
    "    context_metadatas = [{\"type\": \"context\", **doc.metadata} for doc in context_documents]\n",
    "    \n",
    "    chroma_collection.add(\n",
    "        documents=context_texts,\n",
    "        ids=context_ids,\n",
    "        metadatas=context_metadatas\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_qc_to_chroma(qc_meta, db_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_context_candidates(chroma_db_collection, question_context_object: QuestionContextManager, top_k: int = 5, question_prepend: str='query:', dist_threshold: float = 0, include_origin_context: bool = False) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Filters context candidates for each question based on similarity scores and optionally includes the original context.\n",
    "\n",
    "    This function queries a database collection for context candidates related to a set of questions. It filters these\n",
    "    candidates based on a distance threshold compared to the ground truth context's distance. The function can include\n",
    "    the original context in the results if specified.\n",
    "\n",
    "    Parameters:\n",
    "    - chroma_db_collection: The database collection to query for context candidates.\n",
    "    - question_context_object: An object containing question and context information.\n",
    "    - top_k: The number of top results to consider from the query.\n",
    "    - dist_threshold: The threshold for including additional contexts based on their distance from the ground truth context.\n",
    "    - include_origin_context: A boolean to indicate whether the original context should be included in the results.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary mapping each question ID to a list of filtered context candidate IDs.\n",
    "    \"\"\"\n",
    "    \n",
    "    query_filtered = {}\n",
    "    question_texts = [f'{question_prepend} {doc.page_content}' for doc in question_context_object.questions.values()]\n",
    "\n",
    "    batch_query_result = chroma_db_collection.query(\n",
    "        query_texts=question_texts,\n",
    "        where={\"type\": \"context\"},\n",
    "        n_results=top_k\n",
    "    )\n",
    "\n",
    "    for idx, (q_id, q_document) in enumerate(question_context_object.questions.items()):\n",
    "        query_id_list = batch_query_result['ids'][idx]\n",
    "        query_distances_list = batch_query_result.get('distances', [])[idx]\n",
    "\n",
    "        ground_truth_id = question_context_object.question_context_id_pairs[q_id][0]  # Assuming one ground truth per question\n",
    "\n",
    "        if ground_truth_id in query_id_list:\n",
    "            gt_idx = query_id_list.index(ground_truth_id)\n",
    "            ground_truth_distance = query_distances_list[gt_idx]\n",
    "            # Adjust the starting point based on whether the original context is included\n",
    "            start_idx = gt_idx if include_origin_context else gt_idx + 1\n",
    "            context_ids = []\n",
    "\n",
    "            # Include IDs that are within the distance threshold\n",
    "            for id_, distance in zip(query_id_list[start_idx:], query_distances_list[start_idx:]):\n",
    "                if abs(distance - ground_truth_distance) <= dist_threshold:\n",
    "                    context_ids.append(id_)\n",
    "            # Optionally include the ground truth ID if required\n",
    "            if include_origin_context:\n",
    "                context_ids.insert(0, ground_truth_id)\n",
    "        else:\n",
    "            context_ids = query_id_list if include_origin_context else []\n",
    "\n",
    "        query_filtered[q_id] = context_ids\n",
    "\n",
    "    return query_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'8e89c5c8-56aa-447c-9566-82e927396208': ['92a977ff-de34-4716-90d4-b0cacc3cee6d'],\n",
       " '69dd61a1-a550-44ff-b889-071e47f8e880': ['1592317d-ce26-4fd2-bef2-6f27ddbd11be'],\n",
       " '1e423702-3a47-49e3-9091-3aca496ff105': ['6fd3df39-57cf-4163-a23e-c33d63b3bd87',\n",
       "  '03f949b3-7afe-4b87-b8fa-24f94fdbd712'],\n",
       " '80e804eb-fb01-4841-aa87-2bfeccf02ae4': ['1592317d-ce26-4fd2-bef2-6f27ddbd11be',\n",
       "  '03f949b3-7afe-4b87-b8fa-24f94fdbd712',\n",
       "  '1979dc66-4820-463f-8310-faace278cbfb'],\n",
       " '3d21924a-6893-4390-97a3-799a0489c853': ['6fd3df39-57cf-4163-a23e-c33d63b3bd87',\n",
       "  '1592317d-ce26-4fd2-bef2-6f27ddbd11be',\n",
       "  '1979dc66-4820-463f-8310-faace278cbfb'],\n",
       " '6f7d27b7-61d2-400b-8b97-54fa200ce19c': ['6fd3df39-57cf-4163-a23e-c33d63b3bd87',\n",
       "  '1979dc66-4820-463f-8310-faace278cbfb'],\n",
       " '8510d0f4-42a9-4c6e-b1bc-eddf24d2651a': ['cd7283eb-3cb3-4d5f-81bd-95ac70b891fe',\n",
       "  '1979dc66-4820-463f-8310-faace278cbfb',\n",
       "  'a322ce23-a3f3-4f15-abf2-054f758fbf59',\n",
       "  '1592317d-ce26-4fd2-bef2-6f27ddbd11be']}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_candidates_id = filter_context_candidates(db_collection, qc_meta, dist_threshold=0.05, include_origin_context=False)\n",
    "context_candidates_id = {k: v for k, v in context_candidates_id.items() if v}\n",
    "context_candidates_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LLM to assess context candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_eval_system_prompt():\n",
    "    sys_prompt = \"\"\"Din opgave er at evaluere hvorvidt et givent tekstuddrag indeholder svaret til et spørgsmål. Du skal alene vurdere om uddraget indeholder svaret, og ikke om svaret er korrekt.\n",
    "\n",
    "    - Tildel scoren 1, hvis tekstuddraget indeholder svaret til spørgsmålet.\n",
    "\n",
    "    - Tildel scoren 0, hvis tekstuddraget ikke kan bruges til at besvare spørgsmålet.\n",
    "    \"\"\"\n",
    "    return sys_prompt\n",
    "\n",
    "def c_eval_user_prompt(question: str, context: str) -> str:\n",
    "    \"\"\"Prepare the prompt for the API call.\"\"\"\n",
    "    \n",
    "    qa_egnet_tmlp = \"\"\"Din Opgave:\n",
    "    \n",
    "    Vurder om følgende spørgsmål kan besvares ud fra den givne kontekst i tekstuddraget:\n",
    "    \n",
    "    spørgsmål:\n",
    "    {insert_question}\n",
    "    \n",
    "    tekstuddrag:\n",
    "    {insert_context}\n",
    "    \n",
    "    Returner din vurdering i følgende JSON-format:\n",
    "\n",
    "    {{\n",
    "    \"context_score\": [indsæt enten 0 eller 1 her]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return qa_egnet_tmlp.format(insert_question=question, insert_context=context)\n",
    "\n",
    "\n",
    "def context_question_assesment(context_candidates, question_context_object: QuestionContextManager) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Iterates over the context candidate texts and uses a LLM call to assess whether the context matches the corresponding question\n",
    "    \"\"\"\n",
    "    question_context_matches = {}\n",
    "    system_prompt = c_eval_system_prompt()\n",
    "    \n",
    "    for q_id, c_id_list in tqdm(context_candidates.items()):\n",
    "        question_text = question_context_object.questions[q_id].page_content\n",
    "        for c_id in c_id_list:\n",
    "            context_text = question_context_object.contexts[c_id].page_content\n",
    "            user_prompt = c_eval_user_prompt(question=question_text, context=context_text)\n",
    "            response = json_api_call(system_prompt, user_prompt)\n",
    "            if response:\n",
    "                if response['context_score'] == 1:\n",
    "                    if q_id not in question_context_matches:\n",
    "                        question_context_matches[q_id] = [c_id]\n",
    "                    else:\n",
    "                        question_context_matches[q_id].append(c_id)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                logging.error(f'Failed to evaluate below text due to an earlier error. \\n {text}')\n",
    "    return question_context_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:11<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "question_context_matches = context_question_assesment(context_candidates_id, qc_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to append the filtered question-context matches to the existing qc_meta.question_context_id_pairs\n",
    "def update_question_context_pairs(q_c_to_append, question_context_object: QuestionContextManager):\n",
    "    for q_id, c_id_list in q_c_to_append.items():\n",
    "        if q_id in question_context_object.question_context_id_pairs:\n",
    "            # Create a set from the existing IDs for quick lookup\n",
    "            existing_ids_set = set(question_context_object.question_context_id_pairs[q_id])\n",
    "            # Filter out duplicates while preserving order\n",
    "            filtered_c_id_list = [c_id for c_id in c_id_list if c_id not in existing_ids_set]\n",
    "            # Extend the existing list with the filtered, non-duplicate IDs\n",
    "            question_context_object.question_context_id_pairs[q_id].extend(filtered_c_id_list)\n",
    "        else:\n",
    "            # Directly assign the list if the q_id is not already present\n",
    "            question_context_object.question_context_id_pairs[q_id] = c_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'af879f4e-769a-48ed-a06d-b68612ae72b3': ['92a977ff-de34-4716-90d4-b0cacc3cee6d'],\n",
       " '8e89c5c8-56aa-447c-9566-82e927396208': ['4b76eac4-af83-41d2-a301-9bb68fbad516'],\n",
       " '69dd61a1-a550-44ff-b889-071e47f8e880': ['03f949b3-7afe-4b87-b8fa-24f94fdbd712',\n",
       "  '1592317d-ce26-4fd2-bef2-6f27ddbd11be'],\n",
       " '1e423702-3a47-49e3-9091-3aca496ff105': ['1592317d-ce26-4fd2-bef2-6f27ddbd11be'],\n",
       " '80e804eb-fb01-4841-aa87-2bfeccf02ae4': ['769c0932-22ac-44ca-9f6b-6e483e922fc5',\n",
       "  '1592317d-ce26-4fd2-bef2-6f27ddbd11be',\n",
       "  '03f949b3-7afe-4b87-b8fa-24f94fdbd712'],\n",
       " '3f54b2c2-aa98-4230-9158-3d40c98041dd': ['0f37ace7-3661-492d-94b9-8cd75fd5ef4a'],\n",
       " '3d21924a-6893-4390-97a3-799a0489c853': ['a322ce23-a3f3-4f15-abf2-054f758fbf59',\n",
       "  '1592317d-ce26-4fd2-bef2-6f27ddbd11be'],\n",
       " '6f7d27b7-61d2-400b-8b97-54fa200ce19c': ['cd7283eb-3cb3-4d5f-81bd-95ac70b891fe',\n",
       "  '6fd3df39-57cf-4163-a23e-c33d63b3bd87',\n",
       "  '1979dc66-4820-463f-8310-faace278cbfb'],\n",
       " '59b53755-29b9-4bd6-98ba-024ec284065b': ['1979dc66-4820-463f-8310-faace278cbfb'],\n",
       " '8510d0f4-42a9-4c6e-b1bc-eddf24d2651a': ['6fd3df39-57cf-4163-a23e-c33d63b3bd87',\n",
       "  'cd7283eb-3cb3-4d5f-81bd-95ac70b891fe',\n",
       "  '1979dc66-4820-463f-8310-faace278cbfb']}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_question_context_pairs(question_context_matches, qc_meta)\n",
    "qc_meta.question_context_id_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'af879f4e-769a-48ed-a06d-b68612ae72b3': Document(page_content='Hvem skal regulere løbende erstatninger tilkendt før 1. januar 2024?', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '8e89c5c8-56aa-447c-9566-82e927396208': Document(page_content='Hvordan beregnes grundlønnen for løbende erstatninger for tab af erhvervsevne ifølge Arbejdstilsynets vejledning fra den 5. januar 2024?', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '69dd61a1-a550-44ff-b889-071e47f8e880': Document(page_content='Hvem er omfattet af pligten til selvbooking ifølge loven om en aktiv beskæftigelsesindsats fra 22. maj 2022?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '1e423702-3a47-49e3-9091-3aca496ff105': Document(page_content='Hvem har ansvaret for kontaktforløbet for dagpengemodtagere i de første 3 måneder fra 1. januar 2024?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '80e804eb-fb01-4841-aa87-2bfeccf02ae4': Document(page_content='Hvordan kan dagpengemodtagere selvbooke jobsamtaler i arbejdsløshedskassen?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '3f54b2c2-aa98-4230-9158-3d40c98041dd': Document(page_content='Hvordan opgøres ledighed for dagpengemodtagere ifølge lov om en aktiv beskæftigelsesindsats?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '3d21924a-6893-4390-97a3-799a0489c853': Document(page_content='Hvem aftaler det videre kontaktforløb med jobcenteret efter de første 6 måneders ledighed?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '6f7d27b7-61d2-400b-8b97-54fa200ce19c': Document(page_content=\"Hvad kræves der for at opfylde betingelsen for 'personligt digitalt fremmøde' ved jobsamtaler ifølge § 33, stk. 1, 2. pkt.?\", metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '59b53755-29b9-4bd6-98ba-024ec284065b': Document(page_content='Kan jobcenteret eller arbejdsløshedskassen ændre en personlig jobsamtale til en telefonisk samtale?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '8510d0f4-42a9-4c6e-b1bc-eddf24d2651a': Document(page_content='Hvordan kan personer på barsel vælge at deres jobsamtale skal foregå ifølge § 33, stk. 2, 3. pkt.?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'})}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_meta.questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'92a977ff-de34-4716-90d4-b0cacc3cee6d': Document(page_content='De private arbejdsskadeforsikringsselskaber samt de arbejdsgivere, der er fritaget for at afgive risikoen efter loven, skal selv regulere løbende erstatninger, som er tilkendt før 1. januar 2024. Ved løbende erstatninger tilkendt i 2024 vil det fremgå af Arbejdsmarkedets Erhvervssikrings afgørelse, hvilke beløb, der skal udbetales i 2024.', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '4b76eac4-af83-41d2-a301-9bb68fbad516': Document(page_content='Arbejdstilsynet, den 5. januar 2024\\nSine Frederiksen\\n/ Helle Klostergaard Christensen\\nBilag 1\\nBilaget indeholder eksempler på beregninger af kapitalerstatninger, godtgørelsesbeløb og overgangsbeløb samt løbende erstatninger og godtgørelser, som tilskadekomne eller dennes efterladte har ret til efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde.\\nArbejdsskader indtruffet i tiden 1. juli 2024 til 31. december 2024\\nTil brug ved beregning og fremtidig regulering af løbende erstatninger for tab af erhvervsevne og tab af forsørger samt uddannelsesgodtgørelser beregnes grundlønnen (§ 24 a) ved at multiplicere den fastsatte årsløn med forholdet mellem den maksimale årsløn pr. 1. januar 2024 (608.000 kr.) og den maksimale årsløn på skadestidspunktet (608.000 kr.), det vil sige:\\nGrundløn = årsløn × 608.000 / 608.000.\\nBeløbet afrundes til hele kroner. Grundlønnen svarer til årslønnen reguleret tilbage til niveauet pr. 1. januar 2024.', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '03f949b3-7afe-4b87-b8fa-24f94fdbd712': Document(page_content='Indledning\\nDenne vejledning omfatter pligt til selvbooking for visse målgrupper i lov om en aktiv beskæftigelsesindsats, jf. lovbekendtgørelse nr. 701 af 22. maj 2022. Pligt til selvbooking for sygedagpengemodtagere er ikke omfattet af denne vejledning.\\nPligt til selvbooking gælder for dagpengemodtagere, kontanthjælps- og uddannelseshjælpsmodtagere, overgangsydelsesmodtagere, som ikke er omfattet af introduktionsprogrammet efter integrationsloven, personer i jobafklaringsforløb, personer i ressourceforløb, fleksjobvisiterede, som modtager ledighedsydelse, og personer i revalideringsforløb.\\nPligt til selvbooking omfatter jobsamtaler efter kapitel 7 i lov om en aktiv beskæftigelsesindsats. Dagpengemodtagere har derudover pligt til at selvbooke rådighedssamtaler i arbejdsløshedskassen, hvis arbejdsløshedskassen har fastsat, at der skal ske selvbooking af en rådighedssamtale, jf. rådighedsbekendtgørelsens § 10 (bekendtgørelse nr. 1210 af 28. september 2023).', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '1592317d-ce26-4fd2-bef2-6f27ddbd11be': Document(page_content='Fra 1. januar 2024 får arbejdsløshedskasserne ansvaret for kontaktforløbet for dagpengemodtagere i de første 3 måneder, mens jobcenteret har ansvaret for dagpengemodtageres kontaktforløb efter de første 3 måneder. Vejledningen tager afsæt i denne arbejdsdeling, hvor dagpengemodtagere i målgruppen for uddannelsespålæg, jf. § 27, stk. 3, i lov om en aktiv beskæftigelsesindsats, imidlertid visiteres til et kontaktforløb i jobcenteret senest 2 uger efter personens tilmelding som jobsøgende. Jobcenteret har således ansvaret for kontaktforløbet for dagpengemodtagere i målgruppen for uddannelsespålæg. På den baggrund er dagpengemodtagere i målgruppe for uddannelsespålæg omfattet af pligten til selvbooking af jobsamtaler med jobcenteret.\\nFra 1. januar 2024 kan fælles jobsamtaler med dagpengemodtagere selvbookes i det omfang den enkelte kommune understøtter dette – og den enkelte kommune og arbejdsløshedskasser har aftalt timeslots, hvor de fælles jobsamtaler kan afholdes. En dagpengemodtager vil have pligt til at selvbooke en fælles jobsamtale med dagpengemodtageren i det omfang jobcenteret udstiller en frist for at selvbooke den fælles jobsamtale.\\nDenne vejledning erstatter vejledning nr. 9207 af 21. marts 2023 om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper.\\nFormål', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '769c0932-22ac-44ca-9f6b-6e483e922fc5': Document(page_content='Selvbooking af jobsamtaler har til formål at give personen ansvaret for sit eget ledighedsforløb, og at personen har medindflydelse på, hvornår jobsamtalen skal foregå. Det medvirker til at styrke personens muligheder for at komme i job.\\nSelvbooking skal ske digitalt. Selvbooking kan foregå via Jobnet, men det kan også være muligt via andre løsninger, fx via kommunens egen hjemmeside eller fremmødestandere. Der er således ikke krav om, at selvbooking foregår via Jobnet. Baggrunden herfor er, at en binding til Jobnet kan fastlåse en arbejdsdeling mellem digitale løsninger og aktørerne, der med tiden måtte vise sig ikke at være hensigtsmæssig. Derudover kan personen tilbydes en bedre service, når personen har mulighed for at booke møder ad flere kanaler end Jobnet.\\nFor dagpengemodtagere vil selvbooking af jobsamtaler i arbejdsløshedskassen foregå gennem arbejdsløshedskassens digitale bookingsystem, dvs. typisk via arbejdsløshedskassens \"Min Side\".', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '0f37ace7-3661-492d-94b9-8cd75fd5ef4a': Document(page_content='Ledighed opgøres forskelligt alt efter, hvilken målgruppe personen er omfattet af. Reglerne om, hvordan ledighed opgøres fremgår af § 9 i lov om en aktiv beskæftigelsesindsats. For dagpengemodtagere opgøres ledighed som sammenlagt ledighed. For de øvrige målgrupper, som denne vejledning handler om, som har pligt til selvbooking, dvs. kontanthjælpsmodtagere1)uddannelseshjælpsmodtagere2)personer i jobafklaringsforløb, personer i ressourceforløb, fleksjobvisiterede, som modtager ledighedsydelse og personer i revalideringsforløb, opgøres ledighed som sammenhængende ledighed.', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'a322ce23-a3f3-4f15-abf2-054f758fbf59': Document(page_content='Når de første 6 måneder af kontaktforløbet er gået, aftaler den enkelte og jobcenteret det videre kontaktforløb. Det vil sige, at den enkelte person og jobcenteret bliver enige om, hvornår det vil være hensigtsmæssigt at tale sammen igen. Derudover holdes jobsamtaler, når jobcentret vurderer, at der er behov herfor, og den enkelte ledige har ret til en jobsamtale, hvis personen beder om det. Behovet for jobsamtaler kan variere fra person til person og i forhold til, hvilken målgruppe personen tilhører.\\nDet er således i højere grad op til den enkelte sagsbehandler og personen at fastlægge et kontaktforløb, der understøtter, at kontakten med jobcenteret er meningsfuld og tilpasset personens behov, så den enkelte kan få hjælp til hurtigst muligt at komme ud på arbejdsmarkedet eller i gang med en uddannelse.\\nEfter de første 6 måneders ledighed er der således ikke fastsat minimumskrav til jobsamtaler i kontaktfor løbet. Det vil være op til den enkelte og jobcenteret at vurdere behovet for jobsamtaler.\\n1.1.1.Særligt om samtalernes form', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'cd7283eb-3cb3-4d5f-81bd-95ac70b891fe': Document(page_content='Når det fremgår af § 33, stk. 1, 2. pkt., at personen kan vælge ”personligt digitalt fremmøde”, betyder det, at der vil være krav om, at der er en direkte billed- og lydforbindelse ved jobsamtalen (video). Personen får dermed en individuel ret til som hovedregel at bestemme formen på jobsamtaler i hele kontaktforløbet efter den første jobsamtale.', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '1979dc66-4820-463f-8310-faace278cbfb': Document(page_content='.  Jobcenteret eller arbejdsløshedskassen kan i den periode, de hver især varetager kontaktforløbet, udelukkende ændre jobsamtalens form fra telefonisk samtale eller samtale ved personligt digitalt fremmøde til personligt fremmøde, og ikke til en af de øvrige former. Det betyder fx, at jobcenteret eller arbejdsløshedskassen ikke kan ændre personens ønske om en jobsamtale ved personligt fremmøde til en telefonisk jobsamtale.', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '6fd3df39-57cf-4163-a23e-c33d63b3bd87': Document(page_content='Det fremgår af § 33, stk. 2, 3. pkt., at jobsamtaler for personer på barsel efter § 27, stk. 2, skal holdes telefonisk eller ved personligt digitalt fremmøde (video), hvis personen anmoder herom. Personer på barsel har således ikke ret til at bestemme, at jobsamtalen f.eks. skal holdes pr. brev. Personen har alene ret til at bestemme, at jobsamtalen skal holdes telefonisk eller over video.\\nKontaktforløbet for en sygemeldt kan foregå uden kontakt til personen, hvis der er tale om alvorlig sygdom og kontakt ikke er hensigtsmæssig eller mulig på grund af den sygemeldtes helbredssituation (standby), jf. § 33, stk. 3.\\nIfølge § 33, stk. 4, kan arbejdsløshedskassen vælge at deltage ved personligt digitalt fremmøde i de jobsamtaler, hvor personen har valgt, at arbejdsløshedskassen skal deltage efter § 31, stk. 2, og § 32, stk. 2, medmindre personen anmoder om, at arbejdsløshedskassen deltager ved personligt fremmøde (fysisk fremmøde) sammen med personen. Det drejer sig om den første jobsamtale med jobcenteret efter de første 3 måneders ledighed og jobsamtalen om en obligatorisk intensiveret indsats, senest når personen har været ledig i 16 måneder.', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'})}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_meta.contexts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
