{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jealk/mambaforge/envs/llama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from hub\n",
    "ds_vejledninger = load_dataset(\n",
    "    \"jealk/dk_retrieval_benchmark\",\n",
    "    \"retsinformation\",\n",
    "    split=\"train\",\n",
    "    #download_mode=\"force_redownload\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>html_content</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.\\n1.Indledni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "1  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "2  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "3  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "4  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Vejledning om regulering af satser fra 1. janu...   \n",
       "1  Vejledning om satser i 2024 for betaling af ud...   \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...   \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...   \n",
       "4                 Vejledning om fleksløntilskud m.v.   \n",
       "\n",
       "                                        html_content  \\\n",
       "0  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "1  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "2  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "3  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "4  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "\n",
       "                                        text_content  \n",
       "0  Vejledning om regulering af satser fra 1. janu...  \n",
       "1  Vejledning om satser i 2024 for betaling af ud...  \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...  \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...  \n",
       "4  Vejledning om fleksløntilskud m.v.\\n1.Indledni...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe from the dataset using the huggingface datasets library\n",
    "df_vejledninger = ds_vejledninger.to_pandas()\n",
    "df_vejledninger.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-base-v2\")\n",
    "\n",
    "def token_length_function(text_input):\n",
    "  return len(tokenizer.encode(text_input, add_special_tokens=False))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 0,\n",
    "    length_function = token_length_function,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For some reason, Langchains text splitter is horribly slow (compared to llamaindex) takes 2+ minutes to run on my CPU\n",
    "split_documents = text_splitter.create_documents(list(df_vejledninger[\"text_content\"]), metadatas = [{\"title\": title} for title in df_vejledninger[\"title\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering using TextDescriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdescriptives as td\n",
    "import spacy\n",
    "from typing import List, Dict, Optional\n",
    "import os\n",
    "\n",
    "#add optional meta data, list of dicts\n",
    "def filter_text_by_td(text_list: List[str], filter_type: bool=True) -> List[str]:\n",
    "    \"\"\"Filter nodes by the textdescriptives quality check\n",
    "\n",
    "    Args:\n",
    "    text_list> a list of stext strings\n",
    "    fiter_type: A boolean defining whether to filter by texts that passed (True) or failed (False) the textdescriptives quality check\n",
    "\n",
    "    Returns:\n",
    "    A list of text chunks that passed the textdescriptives quality check\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank(\"da\")\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    quality_pipe = nlp.add_pipe(\"textdescriptives/quality\")\n",
    "    docs = list(nlp.pipe(text_list))\n",
    "    filtered_texts = [doc.text for doc in docs if doc._.passed_quality_check==filter_type]\n",
    "    \n",
    "    return filtered_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample 300 texts\n",
    "texts_passed_td = filter_text_by_td([text.page_content for text in split_documents[0:300]])\n",
    "docs_passed_td = [doc for doc in split_documents if doc.page_content in texts_passed_td]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def q_eval_system_prompt():\n",
    "    sys_prompt = \"\"\"Din opgave er at evaluere et givet tekstuddrag for at bestemme, om det er egnet til at danne grundlag for et generelt spørgsmål, der er relevant for eksempelvis en eksamen eller en test. \n",
    "    For at vurdere dette, skal du fokusere på følgende tre nøglekriterier:\n",
    "\n",
    "    1. Klarhed: Vurder, om teksten er formuleret klart og direkte, således at et spørgsmål til denne tekst, vil kunne besvares uden yderligere forklaringer. Teksten skal være læsbar og ikke usammenhængende i sin struktur.\n",
    "    \n",
    "    2. Konkret Information: Afgør, om uddraget indeholder specifikke, faktuelle informationer, der kan danne grundlag for et præcist og direkte spørgsmål. Teksten skal præsentere håndgribelige fakta eller data, som et spørgsmål kan baseres på.\n",
    "\n",
    "    3. Kontekstuel Helhed: Bedøm, om teksten leverer tilstrækkelig kontekst for at et spørgsmål baseret på uddraget vil være meningsfuldt og forståeligt uden behov for yderligere information. Teksten skal være selvstændig og give en fuld forståelse af det emne, der behandles.\n",
    "\n",
    "    Baseret på din evaluering:\n",
    "\n",
    "    - Tildel scoren 1, hvis tekstuddraget opfylder alle tre kriterier, og der kan formuleres et naturligt, klart og kontekstuelt meningsfuldt spørgsmål baseret på teksten.\n",
    "\n",
    "    - Tildel scoren 0, hvis tekstuddraget ikke opfylder et eller flere af de ovenstående kriterier, hvilket gør det uegnet til at danne grundlag for et generelt spørgsmål.\n",
    "    \"\"\"\n",
    "    return sys_prompt\n",
    "\n",
    "def q_eval_user_prompt(text: str) -> str:\n",
    "    \"\"\"Prepare the prompt for the API call.\"\"\"\n",
    "    \n",
    "    qa_egnet_tmlp = \"\"\"Du er en erfaren sagsbehandler. \n",
    "    Din Opgave:\n",
    "    Vurder det følgende tekstuddrag og angiv, om det er egnet til at stille et generelt spørgsmål til.\n",
    "\n",
    "    Uddrag:\n",
    "    {chunk_text}\n",
    "    \n",
    "    Returner din vurdering i følgende JSON-format:\n",
    "\n",
    "    {{\n",
    "    \"llm_score\": [indsæt enten 0 eller 1 her]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return qa_egnet_tmlp.format(chunk_text=text)\n",
    "\n",
    "\n",
    "def json_api_call(system_prompt: str, user_prompt: str, oai_model: str=\"gpt-3.5-turbo-0125\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {}\n",
    "\n",
    "def filter_text_by_llm(text_list: List[str]) -> List[str]:\n",
    "    \"\"\"Filter text chunks by a LLM quality check\n",
    "    \n",
    "    Args: A list of text strings\n",
    "    \n",
    "    Returns: A list of text chunks that passed the LLM quality check\n",
    "    \"\"\"\n",
    "    texts_passed_llm = []\n",
    "    system_prompt = q_eval_system_prompt()\n",
    "    for text in tqdm(text_list, desc=\"Evaluating texts\"):\n",
    "        user_prompt = q_eval_user_prompt(text)\n",
    "        response = json_api_call(system_prompt, user_prompt)\n",
    "        if response:\n",
    "            if response['llm_score'] == 1:\n",
    "                texts_passed_llm.append(text)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            logging.error(f'Failed to evaluate below text due to an earlier error. \\n {text}')\n",
    "    return texts_passed_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating texts: 100%|██████████| 50/50 [00:47<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#Sample just 50 texts\n",
    "texts_passed_llm = filter_text_by_llm([text.page_content for text in docs_passed_td[:50]])\n",
    "docs_passed_llm = [doc for doc in split_documents if doc.page_content in texts_passed_llm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_template(text: str, num_q: int=1) -> str:\n",
    "    question_tmlp = \"\"\"Nedenfor er et uddrag (kontekst) fra en længere tekst:\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Givet ovenstående uddrag og ingen forudgående viden, er din opgave at generere præcis {num_questions_per_chunk} spørgsmål til teksten.\n",
    "    En sætning skal kun indeholde 1 spørgsmål, og spørgsmålet skal være formuleret kort og præcist. \n",
    "    Svaret til spørgsmålet, skal kunne findes i ovenstående uddrag.\n",
    "    Spørgsmålet skal indeholde specifik kontekst, således at spørgsmålet efterfølgende kan besvares entydigt og uden kendskab til uddraget. \n",
    "    Spørgsmålene skal stilles i et sprog som en borger uden juridisk ekspertise kan forstå.\n",
    "\n",
    "    Eksempel på et spørgsmål der ikke har en specifik kontekst, og som fejlagtigt indeholder 2 spørgsmål i 1 sætning: \n",
    "    \"Hvilket dokument har den nye vejledning erstattet, og hvornår blev den udsendt?\" -Da det ikke angivet hvilket dokument der er tale om, og derfor er svaret til spørgsmålet ikke entyidgt, uden kendskab til uddraget. Sætningen indeholder desuden 2 spørgsmål i samme sætning. \n",
    "\n",
    "    Eksempel på et godt spørgsmål, som kan besvares entydigt uden kendskab til uddraget:\n",
    "    \"Hvilke to indbetalinger udgør det samlede medlemsbidrag til en a-kasse?\" - Da det er klart hvad der spørges om, og der kun er 1 rigtigt svar i den givne lovtekst.\n",
    "    \"\"\"\n",
    "    return question_tmlp.format(context_str=text, num_questions_per_chunk=num_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_api_call(user_prompt: str, oai_model: str=\"gpt-4-0125-preview\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Din opgave er at stille præcise spørgsmål til et givet tekstuddrag og returnere en JSON med en liste af spørgsmål i formatet {{Q: [spørgsmål1, spørsmål2, ...}}.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {'Q': 'API error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from langchain_core.documents import Document  # Import statement assumed; adjust based on actual import path\n",
    "\n",
    "class QuestionContextManager:\n",
    "    \"\"\"\n",
    "    Manages a collection of questions and their associated context chunks as Document objects.\n",
    "    Allows for adding questions with contexts and displaying a specified number of these question-context pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.questions: Dict[str, Document] = {}\n",
    "        self.contexts: Dict[str, Document] = {}\n",
    "        self.question_context_id_pairs: Dict[str, List[str]] = {}\n",
    "\n",
    "    def add_question_context(self, question: Document, context: Document):\n",
    "        \"\"\"\n",
    "        Adds a question and its associated context (both as Document objects) to the manager.\n",
    "        Generates unique IDs for both the question and the context, storing them and their association.\n",
    "\n",
    "        Parameters:\n",
    "        - question (Document): The Document object containing the question.\n",
    "        - context (Document): The Document object containing the context.\n",
    "        \"\"\"\n",
    "        unique_question_id = str(uuid.uuid4())\n",
    "        unique_context_id = str(uuid.uuid4())\n",
    "        self.questions[unique_question_id] = question\n",
    "        self.contexts[unique_context_id] = context\n",
    "        self.question_context_id_pairs[unique_question_id] = [unique_context_id]\n",
    "\n",
    "    @property\n",
    "    def question_context_pairs(self) -> List[Tuple[Document, List[Document]]]:\n",
    "        \"\"\"\n",
    "        Returns a list of tuples, each containing a question Document and a list of its associated context Documents.\n",
    "        \"\"\"\n",
    "        return [(self.questions[qid], [self.contexts[cid] for cid in self.question_context_id_pairs[qid]]) for qid in self.questions]\n",
    "\n",
    "    def display_question_context_pairs(self, num_pairs: int = None):\n",
    "        \"\"\"\n",
    "        Displays a specified number of question-context pairs. If no number is specified, all pairs are displayed.\n",
    "\n",
    "        Parameters:\n",
    "        - num_pairs (int, optional): The number of question-context pairs to display. If None, all pairs are displayed. Defaults to None.\n",
    "        \"\"\"\n",
    "        displayed_pairs = 0\n",
    "        for q_id, context_ids in self.question_context_id_pairs.items():\n",
    "            if num_pairs is not None and displayed_pairs >= num_pairs:\n",
    "                break\n",
    "\n",
    "            question = self.questions[q_id]\n",
    "            print(f\"Question: {question.page_content}\")\n",
    "            for c_id in context_ids:\n",
    "                context = self.contexts[c_id]\n",
    "                print(f\"\\nContext: {context.page_content}\")\n",
    "            print(\"-\" * 40)  # Separator for readability\n",
    "            displayed_pairs += 1\n",
    "\n",
    "    def filter_questions_by_length(self, min_length: int = 20, max_length: int = 150):\n",
    "        \"\"\"\n",
    "        Filters out questions that do not fall within the specified minimum and maximum character length.\n",
    "        Updates the object by removing questions and their associated contexts that do not meet the criteria.\n",
    "\n",
    "        Parameters:\n",
    "        - min_length (int): The minimum character length for questions to be kept. Default to 20.\n",
    "        - max_length (int): The maximum character length for questions to be kept. Default to 150.\n",
    "        \"\"\"\n",
    "        questions_to_remove = [q_id for q_id, question in self.questions.items()\n",
    "                               if not (min_length <= len(question.page_content) <= max_length)]\n",
    "\n",
    "        # Remove the questions and question_context pairs\n",
    "        for q_id in questions_to_remove:\n",
    "            del self.questions[q_id]\n",
    "            del self.question_context_id_pairs[q_id]\n",
    "\n",
    "        # Identify contexts that are no longer linked to any questions\n",
    "        contexts_to_remove = {context_id for context_id in self.contexts\n",
    "                              if all(context_id not in contexts for contexts in self.question_context_id_pairs.values())}\n",
    "\n",
    "        # Remove these contexts\n",
    "        for context_id in contexts_to_remove:\n",
    "            del self.contexts[context_id]\n",
    "\n",
    "        print(f\"Removed {len(questions_to_remove)} questions.\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<QuestionContextManager with {len(self.questions)} questions>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(textContexts: List[Document], num_questions: int = 1, oai_model: str = \"gpt-4-0125-preview\", duplicate_metadata: bool = True) -> QuestionContextManager:\n",
    "    \"\"\"\n",
    "    Generates questions from a list of context Documents and returns a QuestionContextManager\n",
    "    containing the generated questions and their contexts.\n",
    "\n",
    "    Parameters:\n",
    "    - contexts (List[Document]): A list of Document objects to generate questions from.\n",
    "    - num_questions (int): Number of questions to generate per context. Default is 1.\n",
    "    - oai_model (str): The model to use for generating questions. Default is \"gpt-4-0125-preview\".\n",
    "    - duplicate_metadata (bool): If True, duplicate the metadata from context to the generated questions.\n",
    "\n",
    "    Returns:\n",
    "    QuestionContextManager: An object containing the generated questions and their contexts.\n",
    "    \"\"\"\n",
    "    result = QuestionContextManager()\n",
    "    for context in tqdm(textContexts):\n",
    "        question_prompt = generate_question_template(context.page_content, num_questions)\n",
    "        response = question_api_call(question_prompt, oai_model)  \n",
    "        try:\n",
    "            questions = response['Q']\n",
    "            for question_text in questions:\n",
    "                question_document = Document(page_content=question_text.strip(), metadata=context.metadata if duplicate_metadata else {})\n",
    "                result.add_question_context(question_document, context)\n",
    "        except KeyError as e:\n",
    "            print(f'Error parsing json response: {e}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "#Generate questions for a sub-sample of the passed documents\n",
    "qc_meta = generate_questions(docs_passed_llm[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 questions.\n",
      "Question: Hvem skal regulere løbende erstatninger tilkendt før 1. januar 2024?\n",
      "\n",
      "Context: De private arbejdsskadeforsikringsselskaber samt de arbejdsgivere, der er fritaget for at afgive risikoen efter loven, skal selv regulere løbende erstatninger, som er tilkendt før 1. januar 2024. Ved løbende erstatninger tilkendt i 2024 vil det fremgå af Arbejdsmarkedets Erhvervssikrings afgørelse, hvilke beløb, der skal udbetales i 2024.\n",
      "----------------------------------------\n",
      "Question: Hvordan beregnes grundlønnen for løbende erstatninger ifølge Arbejdstilsynets bilag fra den 5. januar 2024?\n",
      "\n",
      "Context: Arbejdstilsynet, den 5. januar 2024\n",
      "Sine Frederiksen\n",
      "/ Helle Klostergaard Christensen\n",
      "Bilag 1\n",
      "Bilaget indeholder eksempler på beregninger af kapitalerstatninger, godtgørelsesbeløb og overgangsbeløb samt løbende erstatninger og godtgørelser, som tilskadekomne eller dennes efterladte har ret til efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde.\n",
      "Arbejdsskader indtruffet i tiden 1. juli 2024 til 31. december 2024\n",
      "Til brug ved beregning og fremtidig regulering af løbende erstatninger for tab af erhvervsevne og tab af forsørger samt uddannelsesgodtgørelser beregnes grundlønnen (§ 24 a) ved at multiplicere den fastsatte årsløn med forholdet mellem den maksimale årsløn pr. 1. januar 2024 (608.000 kr.) og den maksimale årsløn på skadestidspunktet (608.000 kr.), det vil sige:\n",
      "Grundløn = årsløn × 608.000 / 608.000.\n",
      "Beløbet afrundes til hele kroner. Grundlønnen svarer til årslønnen reguleret tilbage til niveauet pr. 1. januar 2024.\n",
      "----------------------------------------\n",
      "Question: Hvilke målgrupper er omfattet af pligten til selvbooking ifølge loven om en aktiv beskæftigelsesindsats fra 22. maj 2022?\n",
      "\n",
      "Context: Indledning\n",
      "Denne vejledning omfatter pligt til selvbooking for visse målgrupper i lov om en aktiv beskæftigelsesindsats, jf. lovbekendtgørelse nr. 701 af 22. maj 2022. Pligt til selvbooking for sygedagpengemodtagere er ikke omfattet af denne vejledning.\n",
      "Pligt til selvbooking gælder for dagpengemodtagere, kontanthjælps- og uddannelseshjælpsmodtagere, overgangsydelsesmodtagere, som ikke er omfattet af introduktionsprogrammet efter integrationsloven, personer i jobafklaringsforløb, personer i ressourceforløb, fleksjobvisiterede, som modtager ledighedsydelse, og personer i revalideringsforløb.\n",
      "Pligt til selvbooking omfatter jobsamtaler efter kapitel 7 i lov om en aktiv beskæftigelsesindsats. Dagpengemodtagere har derudover pligt til at selvbooke rådighedssamtaler i arbejdsløshedskassen, hvis arbejdsløshedskassen har fastsat, at der skal ske selvbooking af en rådighedssamtale, jf. rådighedsbekendtgørelsens § 10 (bekendtgørelse nr. 1210 af 28. september 2023).\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "qc_meta.filter_questions_by_length()\n",
    "qc_meta.display_question_context_pairs(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the question-context pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "collection_name = \"qc_collection\"\n",
    "\n",
    "# Check if the collection already exists\n",
    "if chroma_client.get_collection(collection_name):\n",
    "    # If it does, delete the existing collection\n",
    "    chroma_client.delete_collection(collection_name)\n",
    "\n",
    "db_collection = chroma_client.create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction('intfloat/multilingual-e5-base', normalize_embeddings=True),\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_qc_to_chroma(question_context_obj: QuestionContextManager, chroma_collection, question_prepend: str = \"query:\", context_prepend: str = \"passage:\"):\n",
    "    # Extracting question documents and their IDs\n",
    "    \"\"\"\n",
    "    question_documents = list(question_context_obj.questions.values())\n",
    "    question_texts = [f'{question_prepend} {doc.page_content}' for doc in question_documents]\n",
    "    question_ids = list(question_context_obj.questions.keys())\n",
    "    \n",
    "    # Assuming each Document can carry its own metadata, we can enrich the ChromaDB metadata with it\n",
    "    question_metadatas = [{\"type\": \"question\", **doc.metadata} for doc in question_documents]\n",
    "    \n",
    "    chroma_collection.add(\n",
    "        documents=question_texts,\n",
    "        ids=question_ids,\n",
    "        metadatas=question_metadatas\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Extracting context documents and their IDs\n",
    "    context_documents = list(question_context_obj.contexts.values())\n",
    "    context_texts = [f'{context_prepend} {doc.page_content}' for doc in context_documents]\n",
    "    context_ids = list(question_context_obj.contexts.keys())\n",
    "    \n",
    "    # Assuming each Document can carry its own metadata, we can enrich the ChromaDB metadata with it\n",
    "    context_metadatas = [{\"type\": \"context\", **doc.metadata} for doc in context_documents]\n",
    "    \n",
    "    chroma_collection.add(\n",
    "        documents=context_texts,\n",
    "        ids=context_ids,\n",
    "        metadatas=context_metadatas\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_qc_to_chroma(qc_meta, db_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_context_candidates(chroma_db_collection, question_context_object: QuestionContextManager, top_k: int = 5, dist_threshold: float = 0, include_origin_context: bool = False) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Filters context candidates for each question based on similarity scores and optionally includes the original context.\n",
    "\n",
    "    This function queries a database collection for context candidates related to a set of questions. It filters these\n",
    "    candidates based on a distance threshold compared to the ground truth context's distance. The function can include\n",
    "    the original context in the results if specified.\n",
    "\n",
    "    Parameters:\n",
    "    - chroma_db_collection: The database collection to query for context candidates.\n",
    "    - question_context_object: An object containing question and context information.\n",
    "    - top_k: The number of top results to consider from the query.\n",
    "    - dist_threshold: The threshold for including additional contexts based on their distance from the ground truth context.\n",
    "    - include_origin_context: A boolean to indicate whether the original context should be included in the results.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary mapping each question ID to a list of filtered context candidate IDs.\n",
    "    \"\"\"\n",
    "    \n",
    "    query_filtered = {}\n",
    "\n",
    "    questions_list = [doc.page_content for doc in question_context_object.questions.values()]\n",
    "\n",
    "    batch_query_result = chroma_db_collection.query(\n",
    "        query_texts=questions_list,\n",
    "        where={\"type\": \"context\"},\n",
    "        n_results=top_k\n",
    "    )\n",
    "\n",
    "    for idx, (q_id, q_document) in enumerate(question_context_object.questions.items()):\n",
    "        query_id_list = batch_query_result['ids'][idx]\n",
    "        query_distances_list = batch_query_result.get('distances', [])[idx]\n",
    "\n",
    "        ground_truth_id = question_context_object.question_context_id_pairs[q_id][0]  # Assuming one ground truth per question\n",
    "\n",
    "        if ground_truth_id in query_id_list:\n",
    "            gt_idx = query_id_list.index(ground_truth_id)\n",
    "            ground_truth_distance = query_distances_list[gt_idx]\n",
    "            # Adjust the starting point based on whether the original context is included\n",
    "            start_idx = gt_idx if include_origin_context else gt_idx + 1\n",
    "            context_ids = []\n",
    "\n",
    "            # Include IDs that are within the distance threshold\n",
    "            for id_, distance in zip(query_id_list[start_idx:], query_distances_list[start_idx:]):\n",
    "                if abs(distance - ground_truth_distance) <= dist_threshold:\n",
    "                    context_ids.append(id_)\n",
    "            # Optionally include the ground truth ID if required\n",
    "            if include_origin_context:\n",
    "                context_ids.insert(0, ground_truth_id)\n",
    "        else:\n",
    "            context_ids = query_id_list if include_origin_context else []\n",
    "\n",
    "        query_filtered[q_id] = context_ids\n",
    "\n",
    "    return query_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'65e34c14-bf1b-4594-9ea7-21c8a67e5a86': ['ec1a738b-1435-4668-ac4b-1e179f2e2b92'],\n",
       " '3fa3d7dc-9349-44fd-b4fb-cc7574f0447b': ['6cbfa00d-3790-46de-8825-6d541c519b1e'],\n",
       " 'd1ba2c32-f0a0-46b8-a307-eda8255e9afb': ['b6119300-09d2-498f-8d65-a15a0ff27eab',\n",
       "  '29839634-7813-48b9-bfc1-235465dd8f05'],\n",
       " '9e05aa95-bce9-4c8d-a8ec-41a349d407aa': ['6cbfa00d-3790-46de-8825-6d541c519b1e',\n",
       "  '29839634-7813-48b9-bfc1-235465dd8f05',\n",
       "  '447af735-1c24-4bec-ae94-4b2f21156143'],\n",
       " 'ba322d25-8737-4dea-ba40-080785cdd637': ['6cbfa00d-3790-46de-8825-6d541c519b1e',\n",
       "  'b6119300-09d2-498f-8d65-a15a0ff27eab',\n",
       "  '447af735-1c24-4bec-ae94-4b2f21156143'],\n",
       " '7e0964e1-49d9-4a4e-afb6-1f050c1388f5': ['b6119300-09d2-498f-8d65-a15a0ff27eab'],\n",
       " 'c92d3b46-6ee6-452e-bbee-4da8f22c070d': ['b59d5231-9923-43d7-990c-9b9eb2005375',\n",
       "  '447af735-1c24-4bec-ae94-4b2f21156143',\n",
       "  '34ff745b-2f65-4947-8975-3b0340b255fa',\n",
       "  '6cbfa00d-3790-46de-8825-6d541c519b1e']}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_candidates_id = filter_context_candidates(db_collection, qc_meta, dist_threshold=0.05, include_origin_context=False)\n",
    "context_candidates_id = {k: v for k, v in context_candidates_id.items() if v}\n",
    "context_candidates_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LLM to assess context candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_eval_system_prompt():\n",
    "    sys_prompt = \"\"\"Din opgave er at evaluere hvorvidt et givent tekstuddrag indeholder svaret til et spørgsmål. Du skal alene vurdere om uddraget indeholder svaret, og ikke om svaret er korrekt.\n",
    "\n",
    "    - Tildel scoren 1, hvis tekstuddraget indeholder svaret til spørgsmålet.\n",
    "\n",
    "    - Tildel scoren 0, hvis tekstuddraget ikke kan bruges til at besvare spørgsmålet.\n",
    "    \"\"\"\n",
    "    return sys_prompt\n",
    "\n",
    "def c_eval_user_prompt(question: str, context: str) -> str:\n",
    "    \"\"\"Prepare the prompt for the API call.\"\"\"\n",
    "    \n",
    "    qa_egnet_tmlp = \"\"\"Din Opgave:\n",
    "    \n",
    "    Vurder om følgende spørgsmål kan besvares ud fra den givne kontekst i tekstuddraget:\n",
    "    \n",
    "    spørgsmål:\n",
    "    {insert_question}\n",
    "    \n",
    "    tekstuddrag:\n",
    "    {insert_context}\n",
    "    \n",
    "    Returner din vurdering i følgende JSON-format:\n",
    "\n",
    "    {{\n",
    "    \"context_score\": [indsæt enten 0 eller 1 her]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return qa_egnet_tmlp.format(insert_question=question, insert_context=context)\n",
    "\n",
    "\n",
    "def context_question_assesment(context_candidates, question_context_object: QuestionContextManager) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Iterates over the context candidate texts and uses a LLM call to assess whether the context matches the corresponding question\n",
    "    \"\"\"\n",
    "    question_context_matches = {}\n",
    "    system_prompt = c_eval_system_prompt()\n",
    "    \n",
    "    for q_id, c_id_list in tqdm(context_candidates.items()):\n",
    "        question_text = question_context_object.questions[q_id].page_content\n",
    "        for c_id in c_id_list:\n",
    "            context_text = question_context_object.contexts[c_id].page_content\n",
    "            user_prompt = c_eval_user_prompt(question=question_text, context=context_text)\n",
    "            response = json_api_call(system_prompt, user_prompt)\n",
    "            if response:\n",
    "                if response['context_score'] == 1:\n",
    "                    if q_id not in question_context_matches:\n",
    "                        question_context_matches[q_id] = [c_id]\n",
    "                    else:\n",
    "                        question_context_matches[q_id].append(c_id)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                logging.error(f'Failed to evaluate below text due to an earlier error. \\n {text}')\n",
    "    return question_context_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:11<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "source": [
    "question_context_matches = context_question_assesment(context_candidates_id, qc_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to append the filtered question-context matches to the existing qc_meta.question_context_id_pairs\n",
    "def update_question_context_pairs(q_c_to_append, question_context_object: QuestionContextManager):\n",
    "    for q_id, c_id_list in q_c_to_append.items():\n",
    "        if q_id in question_context_object.question_context_id_pairs:\n",
    "            # Create a set from the existing IDs for quick lookup\n",
    "            existing_ids_set = set(question_context_object.question_context_id_pairs[q_id])\n",
    "            # Filter out duplicates while preserving order\n",
    "            filtered_c_id_list = [c_id for c_id in c_id_list if c_id not in existing_ids_set]\n",
    "            # Extend the existing list with the filtered, non-duplicate IDs\n",
    "            question_context_object.question_context_id_pairs[q_id].extend(filtered_c_id_list)\n",
    "        else:\n",
    "            # Directly assign the list if the q_id is not already present\n",
    "            question_context_object.question_context_id_pairs[q_id] = c_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'235d1d09-2db0-47b0-9812-efef4d39b618': ['ec1a738b-1435-4668-ac4b-1e179f2e2b92'],\n",
       " '65e34c14-bf1b-4594-9ea7-21c8a67e5a86': ['cecc6833-2e9d-4275-821f-0f6d2103cf56'],\n",
       " '3fa3d7dc-9349-44fd-b4fb-cc7574f0447b': ['6cbfa00d-3790-46de-8825-6d541c519b1e',\n",
       "  '29839634-7813-48b9-bfc1-235465dd8f05'],\n",
       " 'd1ba2c32-f0a0-46b8-a307-eda8255e9afb': ['6cbfa00d-3790-46de-8825-6d541c519b1e'],\n",
       " '9e05aa95-bce9-4c8d-a8ec-41a349d407aa': ['b316eda5-1236-44ce-a3bd-108b8f861731',\n",
       "  '6cbfa00d-3790-46de-8825-6d541c519b1e',\n",
       "  '29839634-7813-48b9-bfc1-235465dd8f05'],\n",
       " '375558d5-28da-42c9-b5ba-abfa09a40e3b': ['b13a547c-7463-44b3-b15d-1c60a6e8ae02'],\n",
       " 'ba322d25-8737-4dea-ba40-080785cdd637': ['447af735-1c24-4bec-ae94-4b2f21156143',\n",
       "  '6cbfa00d-3790-46de-8825-6d541c519b1e',\n",
       "  '34ff745b-2f65-4947-8975-3b0340b255fa'],\n",
       " '7e0964e1-49d9-4a4e-afb6-1f050c1388f5': ['b59d5231-9923-43d7-990c-9b9eb2005375',\n",
       "  'b6119300-09d2-498f-8d65-a15a0ff27eab'],\n",
       " 'dc0950b0-e95f-409b-b3bc-a135e2411ca5': ['447af735-1c24-4bec-ae94-4b2f21156143'],\n",
       " 'c92d3b46-6ee6-452e-bbee-4da8f22c070d': ['b59d5231-9923-43d7-990c-9b9eb2005375',\n",
       "  '6cbfa00d-3790-46de-8825-6d541c519b1e',\n",
       "  '447af735-1c24-4bec-ae94-4b2f21156143',\n",
       "  'b6119300-09d2-498f-8d65-a15a0ff27eab']}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_question_context_pairs(question_context_matches, qc_meta)\n",
    "qc_meta.question_context_id_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leftovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hvordan kan dagpengemodtagere selvbooke jobsamtaler i arbejdsløshedskassen?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'})"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_meta.questions['9e05aa95-bce9-4c8d-a8ec-41a349d407aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Indledning\\nDenne vejledning omfatter pligt til selvbooking for visse målgrupper i lov om en aktiv beskæftigelsesindsats, jf. lovbekendtgørelse nr. 701 af 22. maj 2022. Pligt til selvbooking for sygedagpengemodtagere er ikke omfattet af denne vejledning.\\nPligt til selvbooking gælder for dagpengemodtagere, kontanthjælps- og uddannelseshjælpsmodtagere, overgangsydelsesmodtagere, som ikke er omfattet af introduktionsprogrammet efter integrationsloven, personer i jobafklaringsforløb, personer i ressourceforløb, fleksjobvisiterede, som modtager ledighedsydelse, og personer i revalideringsforløb.\\nPligt til selvbooking omfatter jobsamtaler efter kapitel 7 i lov om en aktiv beskæftigelsesindsats. Dagpengemodtagere har derudover pligt til at selvbooke rådighedssamtaler i arbejdsløshedskassen, hvis arbejdsløshedskassen har fastsat, at der skal ske selvbooking af en rådighedssamtale, jf. rådighedsbekendtgørelsens § 10 (bekendtgørelse nr. 1210 af 28. september 2023).', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'})"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_meta.contexts['29839634-7813-48b9-bfc1-235465dd8f05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Fra 1. januar 2024 får arbejdsløshedskasserne ansvaret for kontaktforløbet for dagpengemodtagere i de første 3 måneder, mens jobcenteret har ansvaret for dagpengemodtageres kontaktforløb efter de første 3 måneder. Vejledningen tager afsæt i denne arbejdsdeling, hvor dagpengemodtagere i målgruppen for uddannelsespålæg, jf. § 27, stk. 3, i lov om en aktiv beskæftigelsesindsats, imidlertid visiteres til et kontaktforløb i jobcenteret senest 2 uger efter personens tilmelding som jobsøgende. Jobcenteret har således ansvaret for kontaktforløbet for dagpengemodtagere i målgruppen for uddannelsespålæg. På den baggrund er dagpengemodtagere i målgruppe for uddannelsespålæg omfattet af pligten til selvbooking af jobsamtaler med jobcenteret.\\nFra 1. januar 2024 kan fælles jobsamtaler med dagpengemodtagere selvbookes i det omfang den enkelte kommune understøtter dette – og den enkelte kommune og arbejdsløshedskasser har aftalt timeslots, hvor de fælles jobsamtaler kan afholdes. En dagpengemodtager vil have pligt til at selvbooke en fælles jobsamtale med dagpengemodtageren i det omfang jobcenteret udstiller en frist for at selvbooke den fælles jobsamtale.\\nDenne vejledning erstatter vejledning nr. 9207 af 21. marts 2023 om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper.\\nFormål', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_meta.contexts['6cbfa00d-3790-46de-8825-6d541c519b1e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'235d1d09-2db0-47b0-9812-efef4d39b618': ['ec1a738b-1435-4668-ac4b-1e179f2e2b92'],\n",
       " '65e34c14-bf1b-4594-9ea7-21c8a67e5a86': ['cecc6833-2e9d-4275-821f-0f6d2103cf56'],\n",
       " '3fa3d7dc-9349-44fd-b4fb-cc7574f0447b': ['29839634-7813-48b9-bfc1-235465dd8f05'],\n",
       " 'd1ba2c32-f0a0-46b8-a307-eda8255e9afb': ['6cbfa00d-3790-46de-8825-6d541c519b1e'],\n",
       " '9e05aa95-bce9-4c8d-a8ec-41a349d407aa': ['b316eda5-1236-44ce-a3bd-108b8f861731'],\n",
       " '375558d5-28da-42c9-b5ba-abfa09a40e3b': ['b13a547c-7463-44b3-b15d-1c60a6e8ae02'],\n",
       " 'ba322d25-8737-4dea-ba40-080785cdd637': ['34ff745b-2f65-4947-8975-3b0340b255fa'],\n",
       " '7e0964e1-49d9-4a4e-afb6-1f050c1388f5': ['b59d5231-9923-43d7-990c-9b9eb2005375'],\n",
       " 'dc0950b0-e95f-409b-b3bc-a135e2411ca5': ['447af735-1c24-4bec-ae94-4b2f21156143'],\n",
       " 'c92d3b46-6ee6-452e-bbee-4da8f22c070d': ['b6119300-09d2-498f-8d65-a15a0ff27eab']}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_meta.question_context_id_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'235d1d09-2db0-47b0-9812-efef4d39b618': Document(page_content='Hvem skal regulere løbende erstatninger tilkendt før 1. januar 2024?', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '65e34c14-bf1b-4594-9ea7-21c8a67e5a86': Document(page_content='Hvordan beregnes grundlønnen for løbende erstatninger ifølge Arbejdstilsynets bilag fra den 5. januar 2024?', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '3fa3d7dc-9349-44fd-b4fb-cc7574f0447b': Document(page_content='Hvilke målgrupper er omfattet af pligten til selvbooking ifølge loven om en aktiv beskæftigelsesindsats fra 22. maj 2022?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'd1ba2c32-f0a0-46b8-a307-eda8255e9afb': Document(page_content='Hvem har ansvaret for kontaktforløbet for dagpengemodtagere i de første 3 måneder fra 1. januar 2024?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '9e05aa95-bce9-4c8d-a8ec-41a349d407aa': Document(page_content='Hvordan kan dagpengemodtagere selvbooke jobsamtaler i arbejdsløshedskassen?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '375558d5-28da-42c9-b5ba-abfa09a40e3b': Document(page_content='Hvordan opgøres ledighed for kontanthjælpsmodtagere og personer i jobafklaringsforløb ifølge lov om en aktiv beskæftigelsesindsats?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'ba322d25-8737-4dea-ba40-080785cdd637': Document(page_content='Hvem aftaler det videre kontaktforløb med jobcenteret efter de første 6 måneders ledighed?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '7e0964e1-49d9-4a4e-afb6-1f050c1388f5': Document(page_content=\"Hvad indebærer 'personligt digitalt fremmøde' ifølge § 33, stk. 1, 2. pkt.?\", metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'dc0950b0-e95f-409b-b3bc-a135e2411ca5': Document(page_content='Kan jobcenteret eller arbejdsløshedskassen ændre en personlig jobsamtale til en telefonisk samtale?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'c92d3b46-6ee6-452e-bbee-4da8f22c070d': Document(page_content='Hvordan kan personer på barsel vælge at deres jobsamtale skal foregå ifølge § 33, stk. 2, 3. pkt.?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'})}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_meta.questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = [doc.page_content for doc in list(qc_meta.questions.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hvem skal regulere løbende erstatninger tilkendt før 1. januar 2024?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = [doc.page_content for doc in list(qc_meta.questions.values())]\n",
    "\n",
    "db_search = db_collection.query(\n",
    "    query_texts = questions_list,\n",
    "    where={\"type\": \"context\"},\n",
    "    n_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.097584068775177,\n",
       "  0.15659433603286743,\n",
       "  0.17552393674850464,\n",
       "  0.18490701913833618,\n",
       "  0.20026171207427979],\n",
       " [0.09000265598297119,\n",
       "  0.11974334716796875,\n",
       "  0.1689140796661377,\n",
       "  0.1734117865562439,\n",
       "  0.17344695329666138],\n",
       " [0.0862841010093689,\n",
       "  0.12259435653686523,\n",
       "  0.1447177529335022,\n",
       "  0.14601296186447144,\n",
       "  0.18048101663589478],\n",
       " [0.11279726028442383,\n",
       "  0.15674149990081787,\n",
       "  0.1585928201675415,\n",
       "  0.1638789176940918,\n",
       "  0.16871750354766846],\n",
       " [0.0791313648223877,\n",
       "  0.09400498867034912,\n",
       "  0.10000258684158325,\n",
       "  0.1135631799697876,\n",
       "  0.1328728199005127],\n",
       " [0.0892874002456665,\n",
       "  0.1413293480873108,\n",
       "  0.14738941192626953,\n",
       "  0.1564478874206543,\n",
       "  0.16016292572021484],\n",
       " [0.10472530126571655,\n",
       "  0.13769900798797607,\n",
       "  0.1410079002380371,\n",
       "  0.14229196310043335,\n",
       "  0.16628289222717285],\n",
       " [0.1070985198020935,\n",
       "  0.13767129182815552,\n",
       "  0.1634054183959961,\n",
       "  0.18144559860229492,\n",
       "  0.1822643280029297],\n",
       " [0.06129348278045654,\n",
       "  0.11234098672866821,\n",
       "  0.11622011661529541,\n",
       "  0.12383377552032471,\n",
       "  0.13796889781951904],\n",
       " [0.10018384456634521,\n",
       "  0.11758464574813843,\n",
       "  0.13118237257003784,\n",
       "  0.13521206378936768,\n",
       "  0.1432037353515625]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.902415931224823,\n",
       "  0.8434056639671326,\n",
       "  0.8244760632514954,\n",
       "  0.8150929808616638,\n",
       "  0.7997382879257202],\n",
       " [0.9099973440170288,\n",
       "  0.8802566528320312,\n",
       "  0.8310859203338623,\n",
       "  0.8265882134437561,\n",
       "  0.8265530467033386],\n",
       " [0.9137158989906311,\n",
       "  0.8774056434631348,\n",
       "  0.8552822470664978,\n",
       "  0.8539870381355286,\n",
       "  0.8195189833641052],\n",
       " [0.8872027397155762,\n",
       "  0.8432585000991821,\n",
       "  0.8414071798324585,\n",
       "  0.8361210823059082,\n",
       "  0.8312824964523315],\n",
       " [0.9208686351776123,\n",
       "  0.9059950113296509,\n",
       "  0.8999974131584167,\n",
       "  0.8864368200302124,\n",
       "  0.8671271800994873],\n",
       " [0.9107125997543335,\n",
       "  0.8586706519126892,\n",
       "  0.8526105880737305,\n",
       "  0.8435521125793457,\n",
       "  0.8398370742797852],\n",
       " [0.8952746987342834,\n",
       "  0.8623009920120239,\n",
       "  0.8589920997619629,\n",
       "  0.8577080368995667,\n",
       "  0.8337171077728271],\n",
       " [0.8929014801979065,\n",
       "  0.8623287081718445,\n",
       "  0.8365945816040039,\n",
       "  0.8185544013977051,\n",
       "  0.8177356719970703],\n",
       " [0.9387065172195435,\n",
       "  0.8876590132713318,\n",
       "  0.8837798833847046,\n",
       "  0.8761662244796753,\n",
       "  0.862031102180481],\n",
       " [0.8998161554336548,\n",
       "  0.8824153542518616,\n",
       "  0.8688176274299622,\n",
       "  0.8647879362106323,\n",
       "  0.8567962646484375]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a list comprehension that calculates 1 - dist for each element in the nested lists of db_search['distances'] \n",
    "similarity = [[1 - dist for dist in dist_list] for dist_list in db_search['distances']]\n",
    "similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_search_with_ground_truth(search_results: List[List[str]], question_context_id_pairs: dict) -> dict:\n",
    "    # Initialize a dictionary to store the comparison results\n",
    "    comparison_results = {}\n",
    "\n",
    "    # Iterate over each question ID and its corresponding ground truth context ID(s)\n",
    "    for idx, (question_id, ground_truth_context_ids) in enumerate(question_context_id_pairs.items()):\n",
    "        # Assuming the order of search_results matches the order of question_context_id_pairs\n",
    "        # Fetch the search result list for the current question\n",
    "        current_search_ids = search_results[idx]\n",
    "\n",
    "        # Initialize an empty list to store context IDs ranked higher than the ground truth\n",
    "        higher_ranked_context_ids = []\n",
    "\n",
    "        for ground_truth_id in ground_truth_context_ids:\n",
    "            # Check if the ground truth context ID is in the current list of search IDs\n",
    "            if ground_truth_id in current_search_ids:\n",
    "                # Find the index of the ground truth context ID in the search results\n",
    "                print(f'Match found for question {question_id}!')\n",
    "                ground_truth_index = current_search_ids.index(ground_truth_id)\n",
    "\n",
    "                # Add all context IDs ranked higher than (including) the ground truth context ID\n",
    "                higher_ranked_context_ids = current_search_ids[:ground_truth_index + 1]\n",
    "                break  # Assuming one ground truth context ID per question, we can break after finding it\n",
    "\n",
    "        # Update the comparison results dictionary\n",
    "        comparison_results[question_id] = higher_ranked_context_ids\n",
    "\n",
    "    return comparison_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_potential_context_answers(chroma_db_collection, question_context_object):\n",
    "    # Initialize a dictionary to store the filtered query results\n",
    "    query_filtered = {}\n",
    "\n",
    "    # Iterate over each question ID and its corresponding Document object\n",
    "    for q_id, q_document in question_context_object.questions.items():\n",
    "        # Perform a query using the text of the current question\n",
    "        query_result = chroma_db_collection.query(\n",
    "            query_texts=[q_document.page_content],\n",
    "            where={\"type\": \"context\"},\n",
    "            n_results=5\n",
    "        )\n",
    "\n",
    "        # Assuming query_result returns a list of lists of IDs, take the first list as we performed a single query\n",
    "        query_id_list = query_result['ids'][0]  # Adjust this line based on the actual structure of query_result\n",
    "\n",
    "        # Initialize a list to store context IDs ranked higher than the ground truth\n",
    "        higher_ranked_context_ids = []\n",
    "\n",
    "        # Iterate over ground truth context IDs for the current question\n",
    "        for ground_truth_id in question_context_object.question_context_id_pairs[q_id]:\n",
    "            # Check if the ground truth context ID is in the list of query IDs\n",
    "            if ground_truth_id in query_id_list:\n",
    "                # Find the index of the ground truth context ID in the query results\n",
    "                idx = query_id_list.index(ground_truth_id)\n",
    "\n",
    "                # Add all context IDs ranked higher than or equal to the ground truth context ID\n",
    "                higher_ranked_context_ids = query_id_list[:idx + 1]\n",
    "                break  # Assuming one ground truth context ID per question, we can break after finding it\n",
    "\n",
    "        # Update the filtered query results dictionary\n",
    "        query_filtered[q_id] = higher_ranked_context_ids\n",
    "\n",
    "    return query_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_filtered = filter_potential_context_answers(db_collection, qc_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_potential_context_answers_batch(chroma_db_collection, question_context_object):\n",
    "    # Initialize a dictionary to store the filtered query results\n",
    "    query_filtered = {}\n",
    "\n",
    "    # Extract all questions into a list\n",
    "    questions_list = [doc.page_content for doc in question_context_object.questions.values()]\n",
    "\n",
    "    # Perform a batch query using the list of question texts\n",
    "    batch_query_result = chroma_db_collection.query(\n",
    "        query_texts=questions_list,\n",
    "        where={\"type\": \"context\"},\n",
    "        n_results=5\n",
    "    )\n",
    "\n",
    "    # Iterate over the questions and their corresponding results\n",
    "    for idx, (q_id, q_document) in enumerate(question_context_object.questions.items()):\n",
    "        # Extract the list of IDs for the current question's results\n",
    "        query_id_list = batch_query_result['ids'][idx]\n",
    "\n",
    "        # Initialize a list to store context IDs ranked higher than the ground truth\n",
    "        higher_ranked_context_ids = []\n",
    "\n",
    "        # Iterate over ground truth context IDs for the current question\n",
    "        for ground_truth_id in question_context_object.question_context_id_pairs[q_id]:\n",
    "            # Check if the ground truth context ID is in the list of query IDs\n",
    "            if ground_truth_id in query_id_list:\n",
    "                # Find the index of the ground truth context ID in the query results\n",
    "                idx = query_id_list.index(ground_truth_id)\n",
    "\n",
    "                # Add all context IDs ranked higher than or equal to the ground truth context ID\n",
    "                higher_ranked_context_ids = query_id_list[:idx + 1]\n",
    "                break  # Assuming one ground truth context ID per question, we can break after finding it\n",
    "\n",
    "        # Update the filtered query results dictionary\n",
    "        query_filtered[q_id] = higher_ranked_context_ids\n",
    "\n",
    "    return query_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_filtered = filter_potential_context_answers_batch(db_collection, qc_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_potential_context_answers_batch(chroma_db_collection, question_context_object, dist_threshold: float=0):\n",
    "    # Initialize a dictionary to store the filtered query results\n",
    "    query_filtered = {}\n",
    "\n",
    "    # Extract all questions into a list\n",
    "    questions_list = [doc.page_content for doc in question_context_object.questions.values()]\n",
    "\n",
    "    # Perform a batch query using the list of question texts\n",
    "    batch_query_result = chroma_db_collection.query(\n",
    "        query_texts=questions_list,\n",
    "        where={\"type\": \"context\"},\n",
    "        n_results=5\n",
    "    )\n",
    "\n",
    "    for idx, (q_id, q_document) in enumerate(question_context_object.questions.items()):\n",
    "        query_id_list = batch_query_result['ids'][idx]\n",
    "        query_distances_list = batch_query_result['distances'][idx] if 'distances' in batch_query_result else []\n",
    "\n",
    "        ground_truth_id = question_context_object.question_context_id_pairs[q_id][0]  # Assuming one ground truth per question\n",
    "\n",
    "        if ground_truth_id in query_id_list:\n",
    "            gt_idx = query_id_list.index(ground_truth_id)\n",
    "            ground_truth_distance = query_distances_list[gt_idx]\n",
    "\n",
    "            # Include all IDs up to and including the ground truth's position\n",
    "            context_ids = query_id_list[:gt_idx+1]\n",
    "\n",
    "            # Additionally, include IDs beyond the ground truth's position if they are within the distance threshold\n",
    "            for id_, distance in zip(query_id_list[gt_idx+1:], query_distances_list[gt_idx+1:]):\n",
    "                if abs(distance - ground_truth_distance) <= dist_threshold:\n",
    "                    context_ids.append(id_)\n",
    "        else:\n",
    "            # If the ground truth is not in the top K, return the entire list\n",
    "            context_ids = query_id_list\n",
    "\n",
    "        # Update the filtered query results dictionary\n",
    "        query_filtered[q_id] = context_ids\n",
    "\n",
    "    return query_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_filtered = filter_potential_context_answers_batch(db_collection, qc_meta, dist_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'235d1d09-2db0-47b0-9812-efef4d39b618': ['ec1a738b-1435-4668-ac4b-1e179f2e2b92'],\n",
       " '65e34c14-bf1b-4594-9ea7-21c8a67e5a86': ['cecc6833-2e9d-4275-821f-0f6d2103cf56',\n",
       "  'ec1a738b-1435-4668-ac4b-1e179f2e2b92'],\n",
       " '3fa3d7dc-9349-44fd-b4fb-cc7574f0447b': ['29839634-7813-48b9-bfc1-235465dd8f05',\n",
       "  '6cbfa00d-3790-46de-8825-6d541c519b1e'],\n",
       " 'd1ba2c32-f0a0-46b8-a307-eda8255e9afb': ['6cbfa00d-3790-46de-8825-6d541c519b1e',\n",
       "  'b6119300-09d2-498f-8d65-a15a0ff27eab',\n",
       "  '29839634-7813-48b9-bfc1-235465dd8f05'],\n",
       " '9e05aa95-bce9-4c8d-a8ec-41a349d407aa': ['b316eda5-1236-44ce-a3bd-108b8f861731',\n",
       "  '6cbfa00d-3790-46de-8825-6d541c519b1e',\n",
       "  '29839634-7813-48b9-bfc1-235465dd8f05',\n",
       "  '447af735-1c24-4bec-ae94-4b2f21156143'],\n",
       " '375558d5-28da-42c9-b5ba-abfa09a40e3b': ['b13a547c-7463-44b3-b15d-1c60a6e8ae02'],\n",
       " 'ba322d25-8737-4dea-ba40-080785cdd637': ['34ff745b-2f65-4947-8975-3b0340b255fa',\n",
       "  '6cbfa00d-3790-46de-8825-6d541c519b1e',\n",
       "  'b6119300-09d2-498f-8d65-a15a0ff27eab',\n",
       "  '447af735-1c24-4bec-ae94-4b2f21156143'],\n",
       " '7e0964e1-49d9-4a4e-afb6-1f050c1388f5': ['b59d5231-9923-43d7-990c-9b9eb2005375',\n",
       "  'b6119300-09d2-498f-8d65-a15a0ff27eab'],\n",
       " 'dc0950b0-e95f-409b-b3bc-a135e2411ca5': ['447af735-1c24-4bec-ae94-4b2f21156143'],\n",
       " 'c92d3b46-6ee6-452e-bbee-4da8f22c070d': ['b6119300-09d2-498f-8d65-a15a0ff27eab',\n",
       "  'b59d5231-9923-43d7-990c-9b9eb2005375',\n",
       "  '447af735-1c24-4bec-ae94-4b2f21156143',\n",
       "  '34ff745b-2f65-4947-8975-3b0340b255fa',\n",
       "  '6cbfa00d-3790-46de-8825-6d541c519b1e']}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found for question 235d1d09-2db0-47b0-9812-efef4d39b618!\n",
      "Match found for question 65e34c14-bf1b-4594-9ea7-21c8a67e5a86!\n",
      "Match found for question 3fa3d7dc-9349-44fd-b4fb-cc7574f0447b!\n",
      "Match found for question d1ba2c32-f0a0-46b8-a307-eda8255e9afb!\n",
      "Match found for question 9e05aa95-bce9-4c8d-a8ec-41a349d407aa!\n",
      "Match found for question 375558d5-28da-42c9-b5ba-abfa09a40e3b!\n",
      "Match found for question ba322d25-8737-4dea-ba40-080785cdd637!\n",
      "Match found for question 7e0964e1-49d9-4a4e-afb6-1f050c1388f5!\n",
      "Match found for question dc0950b0-e95f-409b-b3bc-a135e2411ca5!\n",
      "Match found for question c92d3b46-6ee6-452e-bbee-4da8f22c070d!\n"
     ]
    }
   ],
   "source": [
    "comp_results = compare_search_with_ground_truth(db_search['ids'], qc_meta.question_context_id_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'235d1d09-2db0-47b0-9812-efef4d39b618': ['ec1a738b-1435-4668-ac4b-1e179f2e2b92'],\n",
       " '65e34c14-bf1b-4594-9ea7-21c8a67e5a86': ['cecc6833-2e9d-4275-821f-0f6d2103cf56'],\n",
       " '3fa3d7dc-9349-44fd-b4fb-cc7574f0447b': ['29839634-7813-48b9-bfc1-235465dd8f05'],\n",
       " 'd1ba2c32-f0a0-46b8-a307-eda8255e9afb': ['6cbfa00d-3790-46de-8825-6d541c519b1e'],\n",
       " '9e05aa95-bce9-4c8d-a8ec-41a349d407aa': ['b316eda5-1236-44ce-a3bd-108b8f861731'],\n",
       " '375558d5-28da-42c9-b5ba-abfa09a40e3b': ['b13a547c-7463-44b3-b15d-1c60a6e8ae02'],\n",
       " 'ba322d25-8737-4dea-ba40-080785cdd637': ['34ff745b-2f65-4947-8975-3b0340b255fa'],\n",
       " '7e0964e1-49d9-4a4e-afb6-1f050c1388f5': ['b59d5231-9923-43d7-990c-9b9eb2005375'],\n",
       " 'dc0950b0-e95f-409b-b3bc-a135e2411ca5': ['447af735-1c24-4bec-ae94-4b2f21156143'],\n",
       " 'c92d3b46-6ee6-452e-bbee-4da8f22c070d': ['b6119300-09d2-498f-8d65-a15a0ff27eab']}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that takes the db_search result and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'235d1d09-2db0-47b0-9812-efef4d39b618': Document(page_content='Hvem skal regulere løbende erstatninger tilkendt før 1. januar 2024?', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '65e34c14-bf1b-4594-9ea7-21c8a67e5a86': Document(page_content='Hvordan beregnes grundlønnen for løbende erstatninger ifølge Arbejdstilsynets bilag fra den 5. januar 2024?', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '3fa3d7dc-9349-44fd-b4fb-cc7574f0447b': Document(page_content='Hvilke målgrupper er omfattet af pligten til selvbooking ifølge loven om en aktiv beskæftigelsesindsats fra 22. maj 2022?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'd1ba2c32-f0a0-46b8-a307-eda8255e9afb': Document(page_content='Hvem har ansvaret for kontaktforløbet for dagpengemodtagere i de første 3 måneder fra 1. januar 2024?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '9e05aa95-bce9-4c8d-a8ec-41a349d407aa': Document(page_content='Hvordan kan dagpengemodtagere selvbooke jobsamtaler i arbejdsløshedskassen?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '375558d5-28da-42c9-b5ba-abfa09a40e3b': Document(page_content='Hvordan opgøres ledighed for kontanthjælpsmodtagere og personer i jobafklaringsforløb ifølge lov om en aktiv beskæftigelsesindsats?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'ba322d25-8737-4dea-ba40-080785cdd637': Document(page_content='Hvem aftaler det videre kontaktforløb med jobcenteret efter de første 6 måneders ledighed?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '7e0964e1-49d9-4a4e-afb6-1f050c1388f5': Document(page_content=\"Hvad indebærer 'personligt digitalt fremmøde' ifølge § 33, stk. 1, 2. pkt.?\", metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'dc0950b0-e95f-409b-b3bc-a135e2411ca5': Document(page_content='Kan jobcenteret eller arbejdsløshedskassen ændre en personlig jobsamtale til en telefonisk samtale?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'c92d3b46-6ee6-452e-bbee-4da8f22c070d': Document(page_content='Hvordan kan personer på barsel vælge at deres jobsamtale skal foregå ifølge § 33, stk. 2, 3. pkt.?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'})}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_meta.questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
