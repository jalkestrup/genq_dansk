{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jealk/mambaforge/envs/llama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from hub\n",
    "ds_vejledninger = load_dataset(\n",
    "    \"jealk/dk_retrieval_benchmark\",\n",
    "    \"retsinformation\",\n",
    "    split=\"train\",\n",
    "    #download_mode=\"force_redownload\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>html_content</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.\\n1.Indledni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "1  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "2  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "3  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "4  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Vejledning om regulering af satser fra 1. janu...   \n",
       "1  Vejledning om satser i 2024 for betaling af ud...   \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...   \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...   \n",
       "4                 Vejledning om fleksløntilskud m.v.   \n",
       "\n",
       "                                        html_content  \\\n",
       "0  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "1  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "2  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "3  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "4  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "\n",
       "                                        text_content  \n",
       "0  Vejledning om regulering af satser fra 1. janu...  \n",
       "1  Vejledning om satser i 2024 for betaling af ud...  \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...  \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...  \n",
       "4  Vejledning om fleksløntilskud m.v.\\n1.Indledni...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe from the dataset using the huggingface datasets library\n",
    "df_vejledninger = ds_vejledninger.to_pandas()\n",
    "df_vejledninger.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-base-v2\")\n",
    "\n",
    "def token_length_function(text_input):\n",
    "  return len(tokenizer.encode(text_input, add_special_tokens=False))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 0,\n",
    "    length_function = token_length_function,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For some reason, Langchains text splitter is horribly slow (compared to llamaindex) takes 2+ minutes to run on my CPU\n",
    "split_documents = text_splitter.create_documents(list(df_vejledninger[\"text_content\"]), metadatas = [{\"title\": title} for title in df_vejledninger[\"title\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering using TextDescriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdescriptives as td\n",
    "import spacy\n",
    "from typing import List, Dict, Optional\n",
    "import os\n",
    "\n",
    "#add optional meta data, list of dicts\n",
    "def filter_text_by_td(text_list: List[str], filter_type: bool=True) -> List[str]:\n",
    "    \"\"\"Filter nodes by the textdescriptives quality check\n",
    "\n",
    "    Args:\n",
    "    text_list> a list of stext strings\n",
    "    fiter_type: A boolean defining whether to filter by texts that passed (True) or failed (False) the textdescriptives quality check\n",
    "\n",
    "    Returns:\n",
    "    A list of text chunks that passed the textdescriptives quality check\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank(\"da\")\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    quality_pipe = nlp.add_pipe(\"textdescriptives/quality\")\n",
    "    docs = list(nlp.pipe(text_list))\n",
    "    filtered_texts = [doc.text for doc in docs if doc._.passed_quality_check==filter_type]\n",
    "    \n",
    "    return filtered_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample 300 texts\n",
    "texts_passed_td = filter_text_by_td([text.page_content for text in split_documents[0:300]])\n",
    "docs_passed_td = [doc for doc in split_documents if doc.page_content in texts_passed_td]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def q_eval_system_prompt():\n",
    "    sys_prompt = \"\"\"Din opgave er at evaluere et givet tekstuddrag for at bestemme, om det er egnet til at danne grundlag for et generelt spørgsmål, der er relevant for eksempelvis en eksamen eller en test. \n",
    "    For at vurdere dette, skal du fokusere på følgende tre nøglekriterier:\n",
    "\n",
    "    1. Klarhed: Vurder, om teksten er formuleret klart og direkte, således at et spørgsmål til denne tekst, vil kunne besvares uden yderligere forklaringer. Teksten skal være læsbar og ikke usammenhængende i sin struktur.\n",
    "    \n",
    "    2. Konkret Information: Afgør, om uddraget indeholder specifikke, faktuelle informationer, der kan danne grundlag for et præcist og direkte spørgsmål. Teksten skal præsentere håndgribelige fakta eller data, som et spørgsmål kan baseres på.\n",
    "\n",
    "    3. Kontekstuel Helhed: Bedøm, om teksten leverer tilstrækkelig kontekst for at et spørgsmål baseret på uddraget vil være meningsfuldt og forståeligt uden behov for yderligere information. Teksten skal være selvstændig og give en fuld forståelse af det emne, der behandles.\n",
    "\n",
    "    Baseret på din evaluering:\n",
    "\n",
    "    - Tildel scoren 1, hvis tekstuddraget opfylder alle tre kriterier, og der kan formuleres et naturligt, klart og kontekstuelt meningsfuldt spørgsmål baseret på teksten.\n",
    "\n",
    "    - Tildel scoren 0, hvis tekstuddraget ikke opfylder et eller flere af de ovenstående kriterier, hvilket gør det uegnet til at danne grundlag for et generelt spørgsmål.\n",
    "    \"\"\"\n",
    "    return sys_prompt\n",
    "\n",
    "def q_eval_user_prompt(text: str) -> str:\n",
    "    \"\"\"Prepare the prompt for the API call.\"\"\"\n",
    "    \n",
    "    qa_egnet_tmlp = \"\"\"Du er en erfaren sagsbehandler. \n",
    "    Din Opgave:\n",
    "    Vurder det følgende tekstuddrag og angiv, om det er egnet til at stille et generelt spørgsmål til.\n",
    "\n",
    "    Uddrag:\n",
    "    {chunk_text}\n",
    "    \n",
    "    Returner din vurdering i følgende JSON-format:\n",
    "\n",
    "    {{\n",
    "    \"llm_score\": [indsæt enten 0 eller 1 her]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return qa_egnet_tmlp.format(chunk_text=text)\n",
    "\n",
    "\n",
    "def json_api_call(system_prompt: str, user_prompt: str, oai_model: str=\"gpt-3.5-turbo-0125\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {}\n",
    "\n",
    "def filter_text_by_llm(text_list: List[str]) -> List[str]:\n",
    "    \"\"\"Filter text chunks by a LLM quality check\n",
    "    \n",
    "    Args: A list of text strings\n",
    "    \n",
    "    Returns: A list of text chunks that passed the LLM quality check\n",
    "    \"\"\"\n",
    "    texts_passed_llm = []\n",
    "    system_prompt = q_eval_system_prompt()\n",
    "    for text in tqdm(text_list, desc=\"Evaluating texts\"):\n",
    "        user_prompt = q_eval_user_prompt(text)\n",
    "        response = json_api_call(system_prompt, user_prompt)\n",
    "        if response:\n",
    "            if response['llm_score'] == 1:\n",
    "                texts_passed_llm.append(text)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            logging.error(f'Failed to evaluate below text due to an earlier error. \\n {text}')\n",
    "    return texts_passed_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating texts: 100%|██████████| 50/50 [00:47<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#Sample just 50 texts\n",
    "texts_passed_llm = filter_text_by_llm([text.page_content for text in docs_passed_td[:50]])\n",
    "docs_passed_llm = [doc for doc in split_documents if doc.page_content in texts_passed_llm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_template(text: str, num_q: int=1) -> str:\n",
    "    question_tmlp = \"\"\"Nedenfor er et uddrag (kontekst) fra en længere tekst:\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Givet ovenstående uddrag og ingen forudgående viden, er din opgave at generere præcis {num_questions_per_chunk} spørgsmål til teksten.\n",
    "    En sætning skal kun indeholde 1 spørgsmål, og spørgsmålet skal være formuleret kort og præcist. \n",
    "    Svaret til spørgsmålet, skal kunne findes i ovenstående uddrag.\n",
    "    Spørgsmålet skal indeholde specifik kontekst, således at spørgsmålet efterfølgende kan besvares entydigt og uden kendskab til uddraget. \n",
    "    Spørgsmålene skal stilles i et sprog som en borger uden juridisk ekspertise kan forstå.\n",
    "\n",
    "    Eksempel på et spørgsmål der ikke har en specifik kontekst, og som fejlagtigt indeholder 2 spørgsmål i 1 sætning: \n",
    "    \"Hvilket dokument har den nye vejledning erstattet, og hvornår blev den udsendt?\" -Da det ikke angivet hvilket dokument der er tale om, og derfor er svaret til spørgsmålet ikke entyidgt, uden kendskab til uddraget. Sætningen indeholder desuden 2 spørgsmål i samme sætning. \n",
    "\n",
    "    Eksempel på et godt spørgsmål, som kan besvares entydigt uden kendskab til uddraget:\n",
    "    \"Hvilke to indbetalinger udgør det samlede medlemsbidrag til en a-kasse?\" - Da det er klart hvad der spørges om, og der kun er 1 rigtigt svar i den givne lovtekst.\n",
    "    \"\"\"\n",
    "    return question_tmlp.format(context_str=text, num_questions_per_chunk=num_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_api_call(user_prompt: str, oai_model: str=\"gpt-4-0125-preview\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Din opgave er at stille præcise spørgsmål til et givet tekstuddrag og returnere en JSON med en liste af spørgsmål i formatet {{Q: [spørgsmål1, spørsmål2, ...}}.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {'Q': 'API error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from langchain_core.documents import Document  # Import statement assumed; adjust based on actual import path\n",
    "\n",
    "class QuestionContextManager:\n",
    "    \"\"\"\n",
    "    Manages a collection of questions and their associated context chunks as Document objects.\n",
    "    Allows for adding questions with contexts and displaying a specified number of these question-context pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.questions: Dict[str, Document] = {}\n",
    "        self.contexts: Dict[str, Document] = {}\n",
    "        self.question_context_id_pairs: Dict[str, List[str]] = {}\n",
    "\n",
    "    def add_question_context(self, question: Document, context: Document):\n",
    "        \"\"\"\n",
    "        Adds a question and its associated context (both as Document objects) to the manager.\n",
    "        Generates unique IDs for both the question and the context, storing them and their association.\n",
    "\n",
    "        Parameters:\n",
    "        - question (Document): The Document object containing the question.\n",
    "        - context (Document): The Document object containing the context.\n",
    "        \"\"\"\n",
    "        unique_question_id = str(uuid.uuid4())\n",
    "        unique_context_id = str(uuid.uuid4())\n",
    "        self.questions[unique_question_id] = question\n",
    "        self.contexts[unique_context_id] = context\n",
    "        self.question_context_id_pairs[unique_question_id] = [unique_context_id]\n",
    "\n",
    "    @property\n",
    "    def question_context_pairs(self) -> List[Tuple[Document, List[Document]]]:\n",
    "        \"\"\"\n",
    "        Returns a list of tuples, each containing a question Document and a list of its associated context Documents.\n",
    "        \"\"\"\n",
    "        return [(self.questions[qid], [self.contexts[cid] for cid in self.question_context_id_pairs[qid]]) for qid in self.questions]\n",
    "\n",
    "    def display_question_context_pairs(self, num_pairs: int = None):\n",
    "        \"\"\"\n",
    "        Displays a specified number of question-context pairs. If no number is specified, all pairs are displayed.\n",
    "\n",
    "        Parameters:\n",
    "        - num_pairs (int, optional): The number of question-context pairs to display. If None, all pairs are displayed. Defaults to None.\n",
    "        \"\"\"\n",
    "        displayed_pairs = 0\n",
    "        for q_id, context_ids in self.question_context_id_pairs.items():\n",
    "            if num_pairs is not None and displayed_pairs >= num_pairs:\n",
    "                break\n",
    "\n",
    "            question = self.questions[q_id]\n",
    "            print(f\"Question: {question.page_content}\")\n",
    "            for c_id in context_ids:\n",
    "                context = self.contexts[c_id]\n",
    "                print(f\"\\nContext: {context.page_content}\")\n",
    "            print(\"-\" * 40)  # Separator for readability\n",
    "            displayed_pairs += 1\n",
    "\n",
    "    def filter_questions_by_length(self, min_length: int = 20, max_length: int = 150):\n",
    "        \"\"\"\n",
    "        Filters out questions that do not fall within the specified minimum and maximum character length.\n",
    "        Updates the object by removing questions and their associated contexts that do not meet the criteria.\n",
    "\n",
    "        Parameters:\n",
    "        - min_length (int): The minimum character length for questions to be kept. Default to 20.\n",
    "        - max_length (int): The maximum character length for questions to be kept. Default to 150.\n",
    "        \"\"\"\n",
    "        questions_to_remove = [q_id for q_id, question in self.questions.items()\n",
    "                               if not (min_length <= len(question.page_content) <= max_length)]\n",
    "\n",
    "        # Remove the questions and question_context pairs\n",
    "        for q_id in questions_to_remove:\n",
    "            del self.questions[q_id]\n",
    "            del self.question_context_id_pairs[q_id]\n",
    "\n",
    "        # Identify contexts that are no longer linked to any questions\n",
    "        contexts_to_remove = {context_id for context_id in self.contexts\n",
    "                              if all(context_id not in contexts for contexts in self.question_context_id_pairs.values())}\n",
    "\n",
    "        # Remove these contexts\n",
    "        for context_id in contexts_to_remove:\n",
    "            del self.contexts[context_id]\n",
    "\n",
    "        print(f\"Removed {len(questions_to_remove)} questions.\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<QuestionContextManager with {len(self.questions)} questions>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(textContexts: List[Document], num_questions: int = 1, oai_model: str = \"gpt-4-0125-preview\", duplicate_metadata: bool = True) -> QuestionContextManager:\n",
    "    \"\"\"\n",
    "    Generates questions from a list of context Documents and returns a QuestionContextManager\n",
    "    containing the generated questions and their contexts.\n",
    "\n",
    "    Parameters:\n",
    "    - contexts (List[Document]): A list of Document objects to generate questions from.\n",
    "    - num_questions (int): Number of questions to generate per context. Default is 1.\n",
    "    - oai_model (str): The model to use for generating questions. Default is \"gpt-4-0125-preview\".\n",
    "    - duplicate_metadata (bool): If True, duplicate the metadata from context to the generated questions.\n",
    "\n",
    "    Returns:\n",
    "    QuestionContextManager: An object containing the generated questions and their contexts.\n",
    "    \"\"\"\n",
    "    result = QuestionContextManager()\n",
    "    for context in tqdm(textContexts):\n",
    "        question_prompt = generate_question_template(context.page_content, num_questions)\n",
    "        response = question_api_call(question_prompt, oai_model)  \n",
    "        try:\n",
    "            questions = response['Q']\n",
    "            for question_text in questions:\n",
    "                question_document = Document(page_content=question_text.strip(), metadata=context.metadata if duplicate_metadata else {})\n",
    "                result.add_question_context(question_document, context)\n",
    "        except KeyError as e:\n",
    "            print(f'Error parsing json response: {e}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "#Generate questions for a sub-sample of the passed documents\n",
    "qc_meta = generate_questions(docs_passed_llm[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_meta.filter_questions_by_length()\n",
    "qc_meta.display_question_context_pairs(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the question-context pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "db_collection = chroma_client.create_collection(\n",
    "    name=\"qc_collection\",\n",
    "    embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction('intfloat/multilingual-e5-base'),\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "def add_qc_to_chroma(question_context_obj: QuestionContextManager, chroma_collection, question_prepend: str = \"query:\", context_prepend: str = \"passage:\"):\n",
    "    # Extracting question documents and their IDs\n",
    "    question_documents = question_context_obj.get_question_documents()  # This method should return a dict of {id: Document}\n",
    "    question_texts = [f'{question_prepend} {doc.text}' for doc in question_documents.values()]\n",
    "    question_ids = list(question_documents.keys())\n",
    "    \n",
    "    # Assuming each Document can carry its own metadata, we can enrich the ChromaDB metadata with it\n",
    "    question_metadatas = [{\"type\": \"question\", **doc.metadata} for doc in question_documents.values()]\n",
    "    \n",
    "    chroma_collection.add(\n",
    "        documents=question_texts,\n",
    "        ids=question_ids,\n",
    "        metadatas=question_metadatas\n",
    "    )\n",
    "    \n",
    "    # Extracting context documents and their IDs\n",
    "    context_documents = question_context_obj.get_context_documents()  # This method should return a dict of {id: Document}\n",
    "    context_texts = [f'{context_prepend} {doc.text}' for doc in context_documents.values()]\n",
    "    context_ids = list(context_documents.keys())\n",
    "    \n",
    "    # Similarly, enriching ChromaDB metadata with Document metadata\n",
    "    context_metadatas = [{\"type\": \"context\", **doc.metadata} for doc in context_documents.values()]\n",
    "    \n",
    "    chroma_collection.add(\n",
    "        documents=context_texts,\n",
    "        ids=context_ids,\n",
    "        metadatas=context_metadatas\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
