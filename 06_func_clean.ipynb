{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function overview\n",
    "\n",
    "- Step 0: Loading and chunking text\n",
    "- Step 1: Filter contexts\n",
    "    - W. Textdescriptives\n",
    "    - W. LLM call, egnet til spørgsmål?\n",
    "- Step 2: Generate questions\n",
    "- Step 3: Filter generated questions\n",
    "    - W. Text length\n",
    "    - (Opt: LLM call: Is the answer clear and in a natural language?)\n",
    "- Step 4: Relabel context-question pairs\n",
    "    - Embed chunks, embed questions (Local Vector DB)\n",
    "    - Use vector search to identify top k matches\n",
    "    - If \"source\" context-question pair not in @1\n",
    "        - Use LLM to check any context that scored > than \"source\" context\n",
    "        - If context passes LLM check, update context-question pair labels to include additional context IDs\n",
    "\n",
    "Not done yet\n",
    "- Step 5: Convert to BEIR format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from hub\n",
    "ds_vejledninger = load_dataset(\n",
    "    \"jealk/dk_retrieval_benchmark\",\n",
    "    \"retsinformation\",\n",
    "    split=\"train\",\n",
    "    #download_mode=\"force_redownload\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>html_content</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.\\n1.Indledni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "1  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "2  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "3  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "4  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Vejledning om regulering af satser fra 1. janu...   \n",
       "1  Vejledning om satser i 2024 for betaling af ud...   \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...   \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...   \n",
       "4                 Vejledning om fleksløntilskud m.v.   \n",
       "\n",
       "                                        html_content  \\\n",
       "0  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "1  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "2  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "3  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "4  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "\n",
       "                                        text_content  \n",
       "0  Vejledning om regulering af satser fra 1. janu...  \n",
       "1  Vejledning om satser i 2024 for betaling af ud...  \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...  \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...  \n",
       "4  Vejledning om fleksløntilskud m.v.\\n1.Indledni...  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe from the dataset using the huggingface datasets library\n",
    "df_vejledninger = ds_vejledninger.to_pandas()\n",
    "df_vejledninger.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Chunking text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-base-v2\")\n",
    "\n",
    "def token_length_function(text_input):\n",
    "  return len(tokenizer.encode(text_input, add_special_tokens=False))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 0,\n",
    "    length_function = token_length_function,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For some reason, Langchains text splitter is horribly slow (compared to llamaindex) takes 2+ minutes to run on my CPU\n",
    "split_documents = text_splitter.create_documents(list(df_vejledninger[\"text_content\"]), metadatas = [{\"title\": title} for title in df_vejledninger[\"title\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Filtering contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering using TextDescriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdescriptives as td\n",
    "import spacy\n",
    "from typing import List, Dict, Optional\n",
    "import os\n",
    "\n",
    "#add optional meta data, list of dicts\n",
    "def filter_text_by_td(text_list: List[str], filter_type: bool=True) -> List[str]:\n",
    "    \"\"\"Filter nodes by the textdescriptives quality check\n",
    "\n",
    "    Args:\n",
    "    text_list> a list of stext strings\n",
    "    fiter_type: A boolean defining whether to filter by texts that passed (True) or failed (False) the textdescriptives quality check\n",
    "\n",
    "    Returns:\n",
    "    A list of text chunks that passed the textdescriptives quality check\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank(\"da\")\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    quality_pipe = nlp.add_pipe(\"textdescriptives/quality\")\n",
    "    docs = list(nlp.pipe(text_list))\n",
    "    filtered_texts = [doc.text for doc in docs if doc._.passed_quality_check==filter_type]\n",
    "    \n",
    "    return filtered_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "import spacy\n",
    "from langchain_core.documents import Document  # Assuming Document is imported from here\n",
    "\n",
    "def filter_text_by_td(text_list: List[Union[str, Document]], filter_type: bool=True) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Filter documents by the textdescriptives quality check, converts strings to langchain Docs\n",
    "\n",
    "    Args:\n",
    "        text_list (List[Union[str, Document]]): A list of text strings or Document objects.\n",
    "        filter_type (bool): A boolean defining whether to filter by texts that passed (True) or failed (False) the textdescriptives quality check.\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: A list of Document objects that passed the textdescriptives quality check.\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank(\"da\")  # Assuming 'da' is the desired model\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    quality_pipe = nlp.add_pipe(\"textdescriptives/quality\")\n",
    "\n",
    "    # Process the texts with SpaCy, handling both strings and Document objects\n",
    "    processed_docs = list(nlp.pipe(doc.page_content if isinstance(doc, Document) else doc for doc in text_list))\n",
    "\n",
    "    # Filter based on the quality check, merge with existing metadata\n",
    "    filtered_docs = [Document(page_content=doc.text, metadata=getattr(original_doc, 'metadata', {}))\n",
    "                     for original_doc, doc in zip(text_list, processed_docs) if doc._.passed_quality_check == filter_type]\n",
    "\n",
    "    return filtered_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_passed_td = filter_text_by_td(split_documents[0:300], filter_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample 300 texts\n",
    "texts_passed_td = filter_text_by_td([text.page_content for text in split_documents[0:300]])\n",
    "docs_passed_td = [doc for doc in split_documents if doc.page_content in texts_passed_td]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def q_eval_system_prompt():\n",
    "    sys_prompt = \"\"\"Din opgave er at evaluere et givet tekstuddrag for at bestemme, om det er egnet til at danne grundlag for et generelt spørgsmål, der er relevant for eksempelvis en eksamen eller en test. \n",
    "    For at vurdere dette, skal du fokusere på følgende tre nøglekriterier:\n",
    "\n",
    "    1. Klarhed: Vurder, om teksten er formuleret klart og direkte, således at et spørgsmål til denne tekst, vil kunne besvares uden yderligere forklaringer. Teksten skal være læsbar og ikke usammenhængende i sin struktur.\n",
    "    \n",
    "    2. Konkret Information: Afgør, om uddraget indeholder specifikke, faktuelle informationer, der kan danne grundlag for et præcist og direkte spørgsmål. Teksten skal præsentere håndgribelige fakta eller data, som et spørgsmål kan baseres på.\n",
    "\n",
    "    3. Kontekstuel Helhed: Bedøm, om teksten leverer tilstrækkelig kontekst for at et spørgsmål baseret på uddraget vil være meningsfuldt og forståeligt uden behov for yderligere information. Teksten skal være selvstændig og give en fuld forståelse af det emne, der behandles.\n",
    "\n",
    "    Baseret på din evaluering:\n",
    "\n",
    "    - Tildel scoren 1, hvis tekstuddraget opfylder alle tre kriterier, og der kan formuleres et naturligt, klart og kontekstuelt meningsfuldt spørgsmål baseret på teksten.\n",
    "\n",
    "    - Tildel scoren 0, hvis tekstuddraget ikke opfylder et eller flere af de ovenstående kriterier, hvilket gør det uegnet til at danne grundlag for et generelt spørgsmål.\n",
    "    \"\"\"\n",
    "    return sys_prompt\n",
    "\n",
    "def q_eval_user_prompt(text: str) -> str:\n",
    "    \"\"\"Prepare the prompt for the API call.\"\"\"\n",
    "    \n",
    "    qa_egnet_tmlp = \"\"\"Du er en erfaren sagsbehandler. \n",
    "    Din Opgave:\n",
    "    Vurder det følgende tekstuddrag og angiv, om det er egnet til at stille et generelt spørgsmål til.\n",
    "\n",
    "    Uddrag:\n",
    "    {chunk_text}\n",
    "    \n",
    "    Returner din vurdering i følgende JSON-format:\n",
    "\n",
    "    {{\n",
    "    \"llm_score\": [indsæt enten 0 eller 1 her]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return qa_egnet_tmlp.format(chunk_text=text)\n",
    "\n",
    "\n",
    "def json_api_call(system_prompt: str, user_prompt: str, oai_model: str=\"gpt-3.5-turbo-0125\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {}\n",
    "\n",
    "\n",
    "def filter_text_by_llm(text_list: List[Union[str, Document]]) -> List[Document]:\n",
    "    \"\"\"Filter text chunks by an LLM quality check\n",
    "\n",
    "    Args:\n",
    "        text_list (List[Union[str, Document]]): A list of text strings or Document objects.\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: A list of Document objects that passed the LLM quality check.\n",
    "    \"\"\"\n",
    "    texts_passed_llm = []\n",
    "    system_prompt = q_eval_system_prompt()\n",
    "    for text_item in tqdm(text_list, desc=\"Evaluating texts\"):\n",
    "        # Extract text content from Document objects or use string directly\n",
    "        text_content = text_item.page_content if isinstance(text_item, Document) else text_item\n",
    "        \n",
    "        user_prompt = q_eval_user_prompt(text_content)\n",
    "        response = json_api_call(system_prompt, user_prompt)\n",
    "        if response:\n",
    "            if response.get('llm_score') == 1:\n",
    "                # Preserve original Document object or create a new one if the input was a string\n",
    "                passed_text_doc = text_item if isinstance(text_item, Document) else Document(page_content=text_content)\n",
    "                texts_passed_llm.append(passed_text_doc)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            logging.error(f'Failed to evaluate the following text due to an earlier error:\\n{text_content}')\n",
    "\n",
    "    return texts_passed_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating texts: 100%|██████████| 50/50 [00:43<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "#Sample just 50 texts\n",
    "docs_passed_llm = filter_text_by_llm(docs_passed_td[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generating Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_template(text: str, num_q: int=1) -> str:\n",
    "    question_tmlp = \"\"\"Nedenfor er et uddrag (kontekst) fra en længere tekst:\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Givet ovenstående uddrag og ingen forudgående viden, er din opgave at generere præcis {num_questions_per_chunk} spørgsmål til teksten.\n",
    "    En sætning skal kun indeholde 1 spørgsmål, og spørgsmålet skal være formuleret kort og præcist. \n",
    "    Svaret til spørgsmålet, skal kunne findes i ovenstående uddrag.\n",
    "    Spørgsmålet skal indeholde specifik kontekst, således at spørgsmålet efterfølgende kan besvares entydigt og uden kendskab til uddraget. \n",
    "    Spørgsmålene skal stilles i et sprog som en borger uden juridisk ekspertise kan forstå.\n",
    "\n",
    "    Eksempel på et spørgsmål der ikke har en specifik kontekst, og som fejlagtigt indeholder 2 spørgsmål i 1 sætning: \n",
    "    \"Hvilket dokument har den nye vejledning erstattet, og hvornår blev den udsendt?\" -Da det ikke angivet hvilket dokument der er tale om, og derfor er svaret til spørgsmålet ikke entyidgt, uden kendskab til uddraget. Sætningen indeholder desuden 2 spørgsmål i samme sætning. \n",
    "\n",
    "    Eksempel på et godt spørgsmål, som kan besvares entydigt uden kendskab til uddraget:\n",
    "    \"Hvilke to indbetalinger udgør det samlede medlemsbidrag til en a-kasse?\" - Da det er klart hvad der spørges om, og der kun er 1 rigtigt svar i den givne lovtekst.\n",
    "    \"\"\"\n",
    "    return question_tmlp.format(context_str=text, num_questions_per_chunk=num_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_api_call(user_prompt: str, oai_model: str=\"gpt-4-0125-preview\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Din opgave er at stille præcise spørgsmål til et givet tekstuddrag og returnere en JSON med en liste af spørgsmål i formatet {{Q: [spørgsmål1, spørsmål2, ...}}.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {'Q': 'API error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from langchain_core.documents import Document \n",
    "\n",
    "class QuestionContextManager:\n",
    "    \"\"\"\n",
    "    Manages a collection of questions and their associated context chunks as Document objects.\n",
    "    Allows for adding questions with contexts and displaying a specified number of these question-context pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.questions: Dict[str, Document] = {}\n",
    "        self.contexts: Dict[str, Document] = {}\n",
    "        self.question_context_id_pairs: Dict[str, List[str]] = {}\n",
    "\n",
    "    def add_question_context(self, question: Document, context: Document):\n",
    "        \"\"\"\n",
    "        Adds a question and its associated context (both as Document objects) to the manager.\n",
    "        Generates unique IDs for both the question and the context, storing them and their association.\n",
    "\n",
    "        Parameters:\n",
    "        - question (Document): The Document object containing the question.\n",
    "        - context (Document): The Document object containing the context.\n",
    "        \"\"\"\n",
    "        unique_question_id = str(uuid.uuid4())\n",
    "        unique_context_id = str(uuid.uuid4())\n",
    "        self.questions[unique_question_id] = question\n",
    "        self.contexts[unique_context_id] = context\n",
    "        self.question_context_id_pairs[unique_question_id] = [unique_context_id]\n",
    "\n",
    "    @property\n",
    "    def question_context_pairs(self) -> List[Tuple[Document, List[Document]]]:\n",
    "        \"\"\"\n",
    "        Returns a list of tuples, each containing a question Document and a list of its associated context Documents.\n",
    "        \"\"\"\n",
    "        return [(self.questions[qid], [self.contexts[cid] for cid in self.question_context_id_pairs[qid]]) for qid in self.questions]\n",
    "\n",
    "    def display_question_context_pairs(self, num_pairs: int = None):\n",
    "        \"\"\"\n",
    "        Displays a specified number of question-context pairs. If no number is specified, all pairs are displayed.\n",
    "\n",
    "        Parameters:\n",
    "        - num_pairs (int, optional): The number of question-context pairs to display. If None, all pairs are displayed. Defaults to None.\n",
    "        \"\"\"\n",
    "        displayed_pairs = 0\n",
    "        for q_id, context_ids in self.question_context_id_pairs.items():\n",
    "            if num_pairs is not None and displayed_pairs >= num_pairs:\n",
    "                break\n",
    "\n",
    "            question = self.questions[q_id]\n",
    "            print(f\"Question: {question.page_content}\")\n",
    "            for c_id in context_ids:\n",
    "                context = self.contexts[c_id]\n",
    "                print(f\"\\nContext: {context.page_content}\")\n",
    "            print(\"-\" * 40)  # Separator for readability\n",
    "            displayed_pairs += 1\n",
    "\n",
    "    def filter_questions_by_length(self, min_length: int = 20, max_length: int = 150):\n",
    "        \"\"\"\n",
    "        Filters out questions that do not fall within the specified minimum and maximum character length.\n",
    "        Updates the object by removing questions and their associated contexts that do not meet the criteria.\n",
    "\n",
    "        Parameters:\n",
    "        - min_length (int): The minimum character length for questions to be kept. Default to 20.\n",
    "        - max_length (int): The maximum character length for questions to be kept. Default to 150.\n",
    "        \"\"\"\n",
    "        questions_to_remove = [q_id for q_id, question in self.questions.items()\n",
    "                               if not (min_length <= len(question.page_content) <= max_length)]\n",
    "\n",
    "        # Remove the questions and question_context pairs\n",
    "        for q_id in questions_to_remove:\n",
    "            del self.questions[q_id]\n",
    "            del self.question_context_id_pairs[q_id]\n",
    "\n",
    "        # Identify contexts that are no longer linked to any questions\n",
    "        contexts_to_remove = {context_id for context_id in self.contexts\n",
    "                              if all(context_id not in contexts for contexts in self.question_context_id_pairs.values())}\n",
    "\n",
    "        # Remove these contexts\n",
    "        for context_id in contexts_to_remove:\n",
    "            del self.contexts[context_id]\n",
    "\n",
    "        print(f\"Removed {len(questions_to_remove)} questions.\")\n",
    "        \n",
    "    def update_question_context_pairs(self, q_c_to_append: Dict[str, List[str]]):\n",
    "        \"\"\"\n",
    "        Appends the question-context matches to the existing question_context_id_pairs,\n",
    "        ensuring no duplicates are added.\n",
    "\n",
    "        Parameters:\n",
    "        - q_c_to_append (Dict[str, List[str]]): A dictionary with question IDs as keys and lists of context IDs to append as values.\n",
    "        \"\"\"\n",
    "        for q_id, c_id_list in q_c_to_append.items():\n",
    "            if q_id in self.question_context_id_pairs:\n",
    "                # Create a set from the existing IDs for quick lookup\n",
    "                existing_ids_set = set(self.question_context_id_pairs[q_id])\n",
    "                # Filter out duplicates while preserving order\n",
    "                filtered_c_id_list = [c_id for c_id in c_id_list if c_id not in existing_ids_set]\n",
    "                # Extend the existing list with the filtered, non-duplicate IDs\n",
    "                self.question_context_id_pairs[q_id].extend(filtered_c_id_list)\n",
    "            else:\n",
    "                # Directly assign the list if the q_id is not already present\n",
    "                self.question_context_id_pairs[q_id] = c_id_list\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<QuestionContextManager with {len(self.questions)} questions>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def generate_questions(textContexts: List[Union[Document, str]], num_questions: int = 1, oai_model: str = \"gpt-4-0125-preview\", duplicate_metadata: bool = True) -> QuestionContextManager:\n",
    "    \"\"\"\n",
    "    Generates questions from a list of context Documents and returns a QuestionContextManager\n",
    "    containing the generated questions and their contexts.\n",
    "\n",
    "    Parameters:\n",
    "    - textContexts (List[Union[Document, str]]): A list of Document objects or strings to generate questions from.\n",
    "    - num_questions (int): Number of questions to generate per context. Default is 1.\n",
    "    - oai_model (str): The model to use for generating questions. Default is \"gpt-4-0125-preview\".\n",
    "    - duplicate_metadata (bool): If True, duplicate the metadata from context to the generated questions.\n",
    "\n",
    "    Returns:\n",
    "    QuestionContextManager: An object containing the generated questions and their contexts.\n",
    "    \"\"\"\n",
    "    result = QuestionContextManager()\n",
    "    for context in tqdm(textContexts):\n",
    "        #If input is simply a list of strings, convert to doc with empty metadata\n",
    "        if isinstance(context, str):\n",
    "            context = Document(page_content=context, metadata={})\n",
    "            \n",
    "        question_prompt = generate_question_template(context.page_content, num_questions)\n",
    "        response = question_api_call(question_prompt, oai_model)  \n",
    "        try:\n",
    "            questions = response['Q']\n",
    "            for question_text in questions:\n",
    "                question_document = Document(page_content=question_text.strip(), metadata=context.metadata if duplicate_metadata else {})\n",
    "                result.add_question_context(question_document, context)\n",
    "        except KeyError as e:\n",
    "            print(f'Error parsing json response: {e}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:26<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "#Generate questions for a sub-sample of the passed documents\n",
    "qc_meta = generate_questions(docs_passed_llm[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Question filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 questions.\n",
      "Question: Hvem skal regulere løbende erstatninger tilkendt før 1. januar 2024?\n",
      "\n",
      "Context: De private arbejdsskadeforsikringsselskaber samt de arbejdsgivere, der er fritaget for at afgive risikoen efter loven, skal selv regulere løbende erstatninger, som er tilkendt før 1. januar 2024. Ved løbende erstatninger tilkendt i 2024 vil det fremgå af Arbejdsmarkedets Erhvervssikrings afgørelse, hvilke beløb, der skal udbetales i 2024.\n",
      "----------------------------------------\n",
      "Question: Hvordan beregnes grundlønnen for løbende erstatninger ifølge Arbejdstilsynets vejledning fra den 5. januar 2024?\n",
      "\n",
      "Context: Arbejdstilsynet, den 5. januar 2024\n",
      "Sine Frederiksen\n",
      "/ Helle Klostergaard Christensen\n",
      "Bilag 1\n",
      "Bilaget indeholder eksempler på beregninger af kapitalerstatninger, godtgørelsesbeløb og overgangsbeløb samt løbende erstatninger og godtgørelser, som tilskadekomne eller dennes efterladte har ret til efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde.\n",
      "Arbejdsskader indtruffet i tiden 1. juli 2024 til 31. december 2024\n",
      "Til brug ved beregning og fremtidig regulering af løbende erstatninger for tab af erhvervsevne og tab af forsørger samt uddannelsesgodtgørelser beregnes grundlønnen (§ 24 a) ved at multiplicere den fastsatte årsløn med forholdet mellem den maksimale årsløn pr. 1. januar 2024 (608.000 kr.) og den maksimale årsløn på skadestidspunktet (608.000 kr.), det vil sige:\n",
      "Grundløn = årsløn × 608.000 / 608.000.\n",
      "Beløbet afrundes til hele kroner. Grundlønnen svarer til årslønnen reguleret tilbage til niveauet pr. 1. januar 2024.\n",
      "----------------------------------------\n",
      "Question: Hvilke målgrupper er omfattet af pligten til selvbooking ifølge lovbekendtgørelse nr. 701 af 22. maj 2022?\n",
      "\n",
      "Context: Indledning\n",
      "Denne vejledning omfatter pligt til selvbooking for visse målgrupper i lov om en aktiv beskæftigelsesindsats, jf. lovbekendtgørelse nr. 701 af 22. maj 2022. Pligt til selvbooking for sygedagpengemodtagere er ikke omfattet af denne vejledning.\n",
      "Pligt til selvbooking gælder for dagpengemodtagere, kontanthjælps- og uddannelseshjælpsmodtagere, overgangsydelsesmodtagere, som ikke er omfattet af introduktionsprogrammet efter integrationsloven, personer i jobafklaringsforløb, personer i ressourceforløb, fleksjobvisiterede, som modtager ledighedsydelse, og personer i revalideringsforløb.\n",
      "Pligt til selvbooking omfatter jobsamtaler efter kapitel 7 i lov om en aktiv beskæftigelsesindsats. Dagpengemodtagere har derudover pligt til at selvbooke rådighedssamtaler i arbejdsløshedskassen, hvis arbejdsløshedskassen har fastsat, at der skal ske selvbooking af en rådighedssamtale, jf. rådighedsbekendtgørelsens § 10 (bekendtgørelse nr. 1210 af 28. september 2023).\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "qc_meta.filter_questions_by_length(min_length=20, max_length=150) #default values\n",
    "qc_meta.display_question_context_pairs(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Updating the question-context pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "def initialize_chroma_collection(client: chromadb.Client, collection_name: str, embedding_model: str, similarity_metric: str=\"cosine\") -> chromadb.Collection:\n",
    "    \"\"\"Initialize or reset a ChromaDB collection with a specified embedding model.\n",
    "\n",
    "    Args:\n",
    "        client (chromadb.Client): The ChromaDB client instance.\n",
    "        collection_name (str): The name of the collection to create or reset.\n",
    "        embedding_model (str): The embedding model to use for the collection.\n",
    "        similarity_metric (str): Similarity metric used for calculating embedding distance\n",
    "\n",
    "    Returns:\n",
    "        chromadb.Collection: The created ChromaDB collection.\n",
    "    \"\"\"\n",
    "    # Create a new collection with the specified embedding function\n",
    "    db_collection = client.create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(embedding_model, normalize_embeddings=True),\n",
    "        metadata={\"hnsw:space\": similarity_metric}\n",
    "    )\n",
    "    return db_collection\n",
    "\n",
    "def add_documents_to_chroma(collection: chromadb.Collection,  id_document_pairs: Dict[str, Union[List[str], List[Document]]], document_prepend: str):\n",
    "    \"\"\"Add documents to a specified ChromaDB collection with optional metadata.\n",
    "\n",
    "    Args:\n",
    "        collection (chromadb.Collection): The ChromaDB collection to add documents to.\n",
    "        id_document_pairs: Dict[str, Union[List[str], List[Document]]]: A Dict of IDs as keys and a list of Documents or strings as values\n",
    "        document_prepend (str, optional): String to prepend to documents prior embedding)\n",
    "    \"\"\"\n",
    "\n",
    "    #If values are Documents\n",
    "    if isinstance(list(id_document_pairs.values())[0], Document):\n",
    "        context_documents = list(id_document_pairs.values())\n",
    "        context_texts = [f'{document_prepend} {doc.page_content}' for doc in context_documents]\n",
    "        context_ids = list(id_document_pairs.keys())\n",
    "        context_metadatas = [{\"type\": \"context\", **doc.metadata} for doc in context_documents]\n",
    "    #If values are Strings\n",
    "    else:\n",
    "        context_texts = [f'{document_prepend} {doc}' for doc in id_document_pairs.values()]\n",
    "        context_ids = list(id_document_pairs.keys())\n",
    "        context_metadatas = [{\"type\": \"context\"} for _ in context_texts]\n",
    "    \n",
    "    collection.add(\n",
    "        documents=context_texts,\n",
    "        ids=context_ids,\n",
    "        metadatas=context_metadatas\n",
    "    )\n",
    "    \n",
    "# Example usage\n",
    "chroma_client = chromadb.Client()\n",
    "collection_name = \"qc_collection\"\n",
    "embedding_model = 'intfloat/multilingual-e5-base'\n",
    "\n",
    "# Check if the collection already exists\n",
    "if chroma_client.get_collection(collection_name):\n",
    "    # If it does, delete the existing collection\n",
    "    chroma_client.delete_collection(collection_name)\n",
    "\n",
    "# Initialize or reset the ChromaDB collection\n",
    "db_collection = initialize_chroma_collection(chroma_client, collection_name, embedding_model)\n",
    "add_documents_to_chroma(db_collection, qc_meta.contexts, document_prepend='passage:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_context_candidates(chroma_db_collection, question_context_object: QuestionContextManager, top_k: int = 5, question_prepend: str='query:', dist_threshold: float = 0, include_origin_context: bool = False) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Filters context candidates for each question based on similarity scores and optionally includes the original context.\n",
    "\n",
    "    Parameters:\n",
    "    - chroma_db_collection: The database collection to query for context candidates.\n",
    "    - question_context_object: An object containing questions, contexts and queston-context ID pairs\n",
    "    - top_k: The number of top results to consider from the query.\n",
    "    - dist_threshold: The threshold for including additional contexts based on their distance from the ground truth context.\n",
    "    - include_origin_context: A boolean to indicate whether the original context should be included in the results.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary mapping each question ID to a list of filtered context candidate IDs.\n",
    "    \"\"\"\n",
    "    \n",
    "    query_filtered = {}\n",
    "    \n",
    "    question_texts = [f'{question_prepend} {doc.page_content}' for doc in question_context_object.questions.values()]\n",
    "\n",
    "    batch_query_result = chroma_db_collection.query(\n",
    "        query_texts=question_texts,\n",
    "        where={\"type\": \"context\"},\n",
    "        n_results=top_k\n",
    "    )\n",
    "\n",
    "    for idx, (q_id, q_document) in enumerate(question_context_object.questions.items()):\n",
    "        query_id_list = batch_query_result['ids'][idx]\n",
    "        query_distances_list = batch_query_result.get('distances', [])[idx]\n",
    "\n",
    "        ground_truth_id = question_context_object.question_context_id_pairs[q_id][0]\n",
    "        context_ids = []\n",
    "\n",
    "        if ground_truth_id in query_id_list:\n",
    "            gt_index = query_id_list.index(ground_truth_id)\n",
    "            gt_distance = query_distances_list[gt_index]\n",
    "\n",
    "            # Include higher-ranked items than the ground truth\n",
    "            context_ids.extend(query_id_list[:gt_index])\n",
    "\n",
    "            # Optionally include the ground truth\n",
    "            if include_origin_context:\n",
    "                context_ids.append(ground_truth_id)\n",
    "\n",
    "            # Include lower-ranked items within the distance threshold\n",
    "            for id_, distance in zip(query_id_list[gt_index + 1:], query_distances_list[gt_index + 1:]):\n",
    "                if abs(distance - gt_distance) <= dist_threshold:\n",
    "                    context_ids.append(id_)\n",
    "        else:\n",
    "            # If ground truth is not in the list, return the full list of querries (top_k)\n",
    "            context_ids.extend(query_id_list)\n",
    "\n",
    "        query_filtered[q_id] = context_ids\n",
    "\n",
    "    return query_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'512f3d46-fe16-44e4-a2af-41e4cd863b68': [],\n",
       " '4639269a-aac5-4533-8ebd-72d67bc2d1bd': ['27c95174-557d-41e6-bca0-fcaba2ed3995'],\n",
       " '807d007e-4de1-4701-b412-89cbfdeaabf0': [],\n",
       " '411d0a43-e58e-4abe-bb23-642414a8d95b': ['b8355203-fda9-4d44-8d5d-e99b13df41a8',\n",
       "  'cbf49bab-01e7-4747-9b07-a294d524de23'],\n",
       " '1b9a4c43-31c2-4605-8892-a2a886d82aa5': ['954076d4-15f8-4d59-b523-71c75a9801e2',\n",
       "  'cbf49bab-01e7-4747-9b07-a294d524de23'],\n",
       " '132b4306-cd81-47f1-8674-a1644d3d544a': [],\n",
       " '2b630fbe-830d-493e-8ea1-10d214493034': ['b8355203-fda9-4d44-8d5d-e99b13df41a8',\n",
       "  '954076d4-15f8-4d59-b523-71c75a9801e2',\n",
       "  '3ee5a517-271b-4a28-83f9-33c52fdb6bb0'],\n",
       " '4283f5e1-29c5-42c5-bc58-bd7ce1381216': ['b8355203-fda9-4d44-8d5d-e99b13df41a8',\n",
       "  '3ee5a517-271b-4a28-83f9-33c52fdb6bb0'],\n",
       " 'e8eb6c03-2ad7-4bde-b2f7-a99a67bb46b4': [],\n",
       " 'be587ec5-f06f-4a77-b9c7-da0bcc507763': ['3ee5a517-271b-4a28-83f9-33c52fdb6bb0',\n",
       "  'da55bea0-ae38-492e-bf60-a9f7e81269bf',\n",
       "  '9640f0aa-b801-40b6-9ccd-440983f4c3a1',\n",
       "  '954076d4-15f8-4d59-b523-71c75a9801e2']}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_candidates_id = filter_context_candidates(db_collection, qc_meta, dist_threshold=0.05, include_origin_context=False)\n",
    "context_candidates_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'512f3d46-fe16-44e4-a2af-41e4cd863b68': [],\n",
       " '4639269a-aac5-4533-8ebd-72d67bc2d1bd': ['27c95174-557d-41e6-bca0-fcaba2ed3995'],\n",
       " '807d007e-4de1-4701-b412-89cbfdeaabf0': [],\n",
       " '411d0a43-e58e-4abe-bb23-642414a8d95b': ['b8355203-fda9-4d44-8d5d-e99b13df41a8',\n",
       "  'cbf49bab-01e7-4747-9b07-a294d524de23'],\n",
       " '1b9a4c43-31c2-4605-8892-a2a886d82aa5': ['954076d4-15f8-4d59-b523-71c75a9801e2',\n",
       "  'cbf49bab-01e7-4747-9b07-a294d524de23'],\n",
       " '132b4306-cd81-47f1-8674-a1644d3d544a': [],\n",
       " '2b630fbe-830d-493e-8ea1-10d214493034': ['b8355203-fda9-4d44-8d5d-e99b13df41a8',\n",
       "  '954076d4-15f8-4d59-b523-71c75a9801e2',\n",
       "  '3ee5a517-271b-4a28-83f9-33c52fdb6bb0'],\n",
       " '4283f5e1-29c5-42c5-bc58-bd7ce1381216': ['b8355203-fda9-4d44-8d5d-e99b13df41a8',\n",
       "  '3ee5a517-271b-4a28-83f9-33c52fdb6bb0'],\n",
       " 'e8eb6c03-2ad7-4bde-b2f7-a99a67bb46b4': [],\n",
       " 'be587ec5-f06f-4a77-b9c7-da0bcc507763': ['3ee5a517-271b-4a28-83f9-33c52fdb6bb0',\n",
       "  'da55bea0-ae38-492e-bf60-a9f7e81269bf',\n",
       "  '9640f0aa-b801-40b6-9ccd-440983f4c3a1',\n",
       "  '954076d4-15f8-4d59-b523-71c75a9801e2']}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove empty lists\n",
    "context_candidates_id = {k: v for k, v in context_candidates_id.items() if v}\n",
    "context_candidates_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using LLM to assess context candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_eval_system_prompt():\n",
    "    sys_prompt = \"\"\"Din opgave er at evaluere hvorvidt et givent tekstuddrag indeholder svaret til et spørgsmål. Du skal alene vurdere om uddraget indeholder svaret, og ikke om svaret er korrekt.\n",
    "\n",
    "    - Tildel scoren 1, hvis tekstuddraget indeholder svaret til spørgsmålet.\n",
    "\n",
    "    - Tildel scoren 0, hvis tekstuddraget ikke kan bruges til at besvare spørgsmålet.\n",
    "    \"\"\"\n",
    "    return sys_prompt\n",
    "\n",
    "def c_eval_user_prompt(question: str, context: str) -> str:\n",
    "    \"\"\"Prepare the prompt for the API call.\"\"\"\n",
    "    \n",
    "    qa_egnet_tmlp = \"\"\"Din Opgave:\n",
    "    \n",
    "    Vurder om følgende spørgsmål kan besvares ud fra den givne kontekst i tekstuddraget:\n",
    "    \n",
    "    spørgsmål:\n",
    "    {insert_question}\n",
    "    \n",
    "    tekstuddrag:\n",
    "    {insert_context}\n",
    "    \n",
    "    Returner din vurdering i følgende JSON-format:\n",
    "\n",
    "    {{\n",
    "    \"context_score\": [indsæt enten 0 eller 1 her]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return qa_egnet_tmlp.format(insert_question=question, insert_context=context)\n",
    "\n",
    "\n",
    "def context_question_assesment(context_candidates, question_context_object: QuestionContextManager) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Iterates over the context candidate texts and uses a LLM call to assess whether the context matches the corresponding question\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary mapping each question ID to a list of context IDs, that according to the LLM can be used to answer the question\n",
    "    \"\"\"\n",
    "    question_context_matches = {}\n",
    "    system_prompt = c_eval_system_prompt()\n",
    "    \n",
    "    for q_id, c_id_list in tqdm(context_candidates.items()):\n",
    "        question_text = question_context_object.questions[q_id].page_content\n",
    "        for c_id in c_id_list:\n",
    "            context_text = question_context_object.contexts[c_id].page_content\n",
    "            user_prompt = c_eval_user_prompt(question=question_text, context=context_text)\n",
    "            response = json_api_call(system_prompt, user_prompt)\n",
    "            if response:\n",
    "                if response['context_score'] == 1:\n",
    "                    if q_id not in question_context_matches:\n",
    "                        question_context_matches[q_id] = [c_id]\n",
    "                    else:\n",
    "                        question_context_matches[q_id].append(c_id)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                logging.error(f'Failed to evaluate below text due to an earlier error. \\n')\n",
    "    return question_context_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "question_context_matches = context_question_assesment(context_candidates_id, qc_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1b9a4c43-31c2-4605-8892-a2a886d82aa5': ['954076d4-15f8-4d59-b523-71c75a9801e2',\n",
       "  'cbf49bab-01e7-4747-9b07-a294d524de23'],\n",
       " '2b630fbe-830d-493e-8ea1-10d214493034': ['954076d4-15f8-4d59-b523-71c75a9801e2',\n",
       "  '3ee5a517-271b-4a28-83f9-33c52fdb6bb0'],\n",
       " '4283f5e1-29c5-42c5-bc58-bd7ce1381216': ['b8355203-fda9-4d44-8d5d-e99b13df41a8',\n",
       "  '3ee5a517-271b-4a28-83f9-33c52fdb6bb0'],\n",
       " 'be587ec5-f06f-4a77-b9c7-da0bcc507763': ['3ee5a517-271b-4a28-83f9-33c52fdb6bb0',\n",
       "  'da55bea0-ae38-492e-bf60-a9f7e81269bf',\n",
       "  '9640f0aa-b801-40b6-9ccd-440983f4c3a1']}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_context_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to append the filtered question-context matches to the existing qc_meta.question_context_id_pairs\n",
    "def update_question_context_pairs(q_c_to_append, question_context_object: QuestionContextManager):\n",
    "    for q_id, c_id_list in q_c_to_append.items():\n",
    "        if q_id in question_context_object.question_context_id_pairs:\n",
    "            # Create a set from the existing IDs for quick lookup\n",
    "            existing_ids_set = set(question_context_object.question_context_id_pairs[q_id])\n",
    "            # Filter out duplicates while preserving order\n",
    "            filtered_c_id_list = [c_id for c_id in c_id_list if c_id not in existing_ids_set]\n",
    "            # Extend the existing list with the filtered, non-duplicate IDs\n",
    "            question_context_object.question_context_id_pairs[q_id].extend(filtered_c_id_list)\n",
    "        else:\n",
    "            # Directly assign the list if the q_id is not already present\n",
    "            question_context_object.question_context_id_pairs[q_id] = c_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_question_context_pairs(question_context_matches, qc_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QuestionContextManager' object has no attribute 'update_question_context_pairs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[270], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mqc_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_question_context_pairs\u001b[49m(question_context_matches)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QuestionContextManager' object has no attribute 'update_question_context_pairs'"
     ]
    }
   ],
   "source": [
    "qc_meta.update_question_context_pairs(question_context_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'af879f4e-769a-48ed-a06d-b68612ae72b3': ['92a977ff-de34-4716-90d4-b0cacc3cee6d'],\n",
       " '8e89c5c8-56aa-447c-9566-82e927396208': ['4b76eac4-af83-41d2-a301-9bb68fbad516'],\n",
       " '69dd61a1-a550-44ff-b889-071e47f8e880': ['03f949b3-7afe-4b87-b8fa-24f94fdbd712',\n",
       "  '1592317d-ce26-4fd2-bef2-6f27ddbd11be'],\n",
       " '1e423702-3a47-49e3-9091-3aca496ff105': ['1592317d-ce26-4fd2-bef2-6f27ddbd11be'],\n",
       " '80e804eb-fb01-4841-aa87-2bfeccf02ae4': ['769c0932-22ac-44ca-9f6b-6e483e922fc5',\n",
       "  '1592317d-ce26-4fd2-bef2-6f27ddbd11be',\n",
       "  '03f949b3-7afe-4b87-b8fa-24f94fdbd712'],\n",
       " '3f54b2c2-aa98-4230-9158-3d40c98041dd': ['0f37ace7-3661-492d-94b9-8cd75fd5ef4a'],\n",
       " '3d21924a-6893-4390-97a3-799a0489c853': ['a322ce23-a3f3-4f15-abf2-054f758fbf59',\n",
       "  '1592317d-ce26-4fd2-bef2-6f27ddbd11be'],\n",
       " '6f7d27b7-61d2-400b-8b97-54fa200ce19c': ['cd7283eb-3cb3-4d5f-81bd-95ac70b891fe',\n",
       "  '6fd3df39-57cf-4163-a23e-c33d63b3bd87',\n",
       "  '1979dc66-4820-463f-8310-faace278cbfb'],\n",
       " '59b53755-29b9-4bd6-98ba-024ec284065b': ['1979dc66-4820-463f-8310-faace278cbfb'],\n",
       " '8510d0f4-42a9-4c6e-b1bc-eddf24d2651a': ['6fd3df39-57cf-4163-a23e-c33d63b3bd87',\n",
       "  'cd7283eb-3cb3-4d5f-81bd-95ac70b891fe',\n",
       "  '1979dc66-4820-463f-8310-faace278cbfb']}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_meta.question_context_id_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'af879f4e-769a-48ed-a06d-b68612ae72b3': Document(page_content='Hvem skal regulere løbende erstatninger tilkendt før 1. januar 2024?', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '8e89c5c8-56aa-447c-9566-82e927396208': Document(page_content='Hvordan beregnes grundlønnen for løbende erstatninger for tab af erhvervsevne ifølge Arbejdstilsynets vejledning fra den 5. januar 2024?', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '69dd61a1-a550-44ff-b889-071e47f8e880': Document(page_content='Hvem er omfattet af pligten til selvbooking ifølge loven om en aktiv beskæftigelsesindsats fra 22. maj 2022?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '1e423702-3a47-49e3-9091-3aca496ff105': Document(page_content='Hvem har ansvaret for kontaktforløbet for dagpengemodtagere i de første 3 måneder fra 1. januar 2024?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '80e804eb-fb01-4841-aa87-2bfeccf02ae4': Document(page_content='Hvordan kan dagpengemodtagere selvbooke jobsamtaler i arbejdsløshedskassen?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '3f54b2c2-aa98-4230-9158-3d40c98041dd': Document(page_content='Hvordan opgøres ledighed for dagpengemodtagere ifølge lov om en aktiv beskæftigelsesindsats?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '3d21924a-6893-4390-97a3-799a0489c853': Document(page_content='Hvem aftaler det videre kontaktforløb med jobcenteret efter de første 6 måneders ledighed?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '6f7d27b7-61d2-400b-8b97-54fa200ce19c': Document(page_content=\"Hvad kræves der for at opfylde betingelsen for 'personligt digitalt fremmøde' ved jobsamtaler ifølge § 33, stk. 1, 2. pkt.?\", metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '59b53755-29b9-4bd6-98ba-024ec284065b': Document(page_content='Kan jobcenteret eller arbejdsløshedskassen ændre en personlig jobsamtale til en telefonisk samtale?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '8510d0f4-42a9-4c6e-b1bc-eddf24d2651a': Document(page_content='Hvordan kan personer på barsel vælge at deres jobsamtale skal foregå ifølge § 33, stk. 2, 3. pkt.?', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'})}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_meta.questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'92a977ff-de34-4716-90d4-b0cacc3cee6d': Document(page_content='De private arbejdsskadeforsikringsselskaber samt de arbejdsgivere, der er fritaget for at afgive risikoen efter loven, skal selv regulere løbende erstatninger, som er tilkendt før 1. januar 2024. Ved løbende erstatninger tilkendt i 2024 vil det fremgå af Arbejdsmarkedets Erhvervssikrings afgørelse, hvilke beløb, der skal udbetales i 2024.', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '4b76eac4-af83-41d2-a301-9bb68fbad516': Document(page_content='Arbejdstilsynet, den 5. januar 2024\\nSine Frederiksen\\n/ Helle Klostergaard Christensen\\nBilag 1\\nBilaget indeholder eksempler på beregninger af kapitalerstatninger, godtgørelsesbeløb og overgangsbeløb samt løbende erstatninger og godtgørelser, som tilskadekomne eller dennes efterladte har ret til efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde.\\nArbejdsskader indtruffet i tiden 1. juli 2024 til 31. december 2024\\nTil brug ved beregning og fremtidig regulering af løbende erstatninger for tab af erhvervsevne og tab af forsørger samt uddannelsesgodtgørelser beregnes grundlønnen (§ 24 a) ved at multiplicere den fastsatte årsløn med forholdet mellem den maksimale årsløn pr. 1. januar 2024 (608.000 kr.) og den maksimale årsløn på skadestidspunktet (608.000 kr.), det vil sige:\\nGrundløn = årsløn × 608.000 / 608.000.\\nBeløbet afrundes til hele kroner. Grundlønnen svarer til årslønnen reguleret tilbage til niveauet pr. 1. januar 2024.', metadata={'title': 'Vejledning om regulering af satser fra 1. januar 2024 efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde'}),\n",
       " '03f949b3-7afe-4b87-b8fa-24f94fdbd712': Document(page_content='Indledning\\nDenne vejledning omfatter pligt til selvbooking for visse målgrupper i lov om en aktiv beskæftigelsesindsats, jf. lovbekendtgørelse nr. 701 af 22. maj 2022. Pligt til selvbooking for sygedagpengemodtagere er ikke omfattet af denne vejledning.\\nPligt til selvbooking gælder for dagpengemodtagere, kontanthjælps- og uddannelseshjælpsmodtagere, overgangsydelsesmodtagere, som ikke er omfattet af introduktionsprogrammet efter integrationsloven, personer i jobafklaringsforløb, personer i ressourceforløb, fleksjobvisiterede, som modtager ledighedsydelse, og personer i revalideringsforløb.\\nPligt til selvbooking omfatter jobsamtaler efter kapitel 7 i lov om en aktiv beskæftigelsesindsats. Dagpengemodtagere har derudover pligt til at selvbooke rådighedssamtaler i arbejdsløshedskassen, hvis arbejdsløshedskassen har fastsat, at der skal ske selvbooking af en rådighedssamtale, jf. rådighedsbekendtgørelsens § 10 (bekendtgørelse nr. 1210 af 28. september 2023).', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '1592317d-ce26-4fd2-bef2-6f27ddbd11be': Document(page_content='Fra 1. januar 2024 får arbejdsløshedskasserne ansvaret for kontaktforløbet for dagpengemodtagere i de første 3 måneder, mens jobcenteret har ansvaret for dagpengemodtageres kontaktforløb efter de første 3 måneder. Vejledningen tager afsæt i denne arbejdsdeling, hvor dagpengemodtagere i målgruppen for uddannelsespålæg, jf. § 27, stk. 3, i lov om en aktiv beskæftigelsesindsats, imidlertid visiteres til et kontaktforløb i jobcenteret senest 2 uger efter personens tilmelding som jobsøgende. Jobcenteret har således ansvaret for kontaktforløbet for dagpengemodtagere i målgruppen for uddannelsespålæg. På den baggrund er dagpengemodtagere i målgruppe for uddannelsespålæg omfattet af pligten til selvbooking af jobsamtaler med jobcenteret.\\nFra 1. januar 2024 kan fælles jobsamtaler med dagpengemodtagere selvbookes i det omfang den enkelte kommune understøtter dette – og den enkelte kommune og arbejdsløshedskasser har aftalt timeslots, hvor de fælles jobsamtaler kan afholdes. En dagpengemodtager vil have pligt til at selvbooke en fælles jobsamtale med dagpengemodtageren i det omfang jobcenteret udstiller en frist for at selvbooke den fælles jobsamtale.\\nDenne vejledning erstatter vejledning nr. 9207 af 21. marts 2023 om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper.\\nFormål', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '769c0932-22ac-44ca-9f6b-6e483e922fc5': Document(page_content='Selvbooking af jobsamtaler har til formål at give personen ansvaret for sit eget ledighedsforløb, og at personen har medindflydelse på, hvornår jobsamtalen skal foregå. Det medvirker til at styrke personens muligheder for at komme i job.\\nSelvbooking skal ske digitalt. Selvbooking kan foregå via Jobnet, men det kan også være muligt via andre løsninger, fx via kommunens egen hjemmeside eller fremmødestandere. Der er således ikke krav om, at selvbooking foregår via Jobnet. Baggrunden herfor er, at en binding til Jobnet kan fastlåse en arbejdsdeling mellem digitale løsninger og aktørerne, der med tiden måtte vise sig ikke at være hensigtsmæssig. Derudover kan personen tilbydes en bedre service, når personen har mulighed for at booke møder ad flere kanaler end Jobnet.\\nFor dagpengemodtagere vil selvbooking af jobsamtaler i arbejdsløshedskassen foregå gennem arbejdsløshedskassens digitale bookingsystem, dvs. typisk via arbejdsløshedskassens \"Min Side\".', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '0f37ace7-3661-492d-94b9-8cd75fd5ef4a': Document(page_content='Ledighed opgøres forskelligt alt efter, hvilken målgruppe personen er omfattet af. Reglerne om, hvordan ledighed opgøres fremgår af § 9 i lov om en aktiv beskæftigelsesindsats. For dagpengemodtagere opgøres ledighed som sammenlagt ledighed. For de øvrige målgrupper, som denne vejledning handler om, som har pligt til selvbooking, dvs. kontanthjælpsmodtagere1)uddannelseshjælpsmodtagere2)personer i jobafklaringsforløb, personer i ressourceforløb, fleksjobvisiterede, som modtager ledighedsydelse og personer i revalideringsforløb, opgøres ledighed som sammenhængende ledighed.', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'a322ce23-a3f3-4f15-abf2-054f758fbf59': Document(page_content='Når de første 6 måneder af kontaktforløbet er gået, aftaler den enkelte og jobcenteret det videre kontaktforløb. Det vil sige, at den enkelte person og jobcenteret bliver enige om, hvornår det vil være hensigtsmæssigt at tale sammen igen. Derudover holdes jobsamtaler, når jobcentret vurderer, at der er behov herfor, og den enkelte ledige har ret til en jobsamtale, hvis personen beder om det. Behovet for jobsamtaler kan variere fra person til person og i forhold til, hvilken målgruppe personen tilhører.\\nDet er således i højere grad op til den enkelte sagsbehandler og personen at fastlægge et kontaktforløb, der understøtter, at kontakten med jobcenteret er meningsfuld og tilpasset personens behov, så den enkelte kan få hjælp til hurtigst muligt at komme ud på arbejdsmarkedet eller i gang med en uddannelse.\\nEfter de første 6 måneders ledighed er der således ikke fastsat minimumskrav til jobsamtaler i kontaktfor løbet. Det vil være op til den enkelte og jobcenteret at vurdere behovet for jobsamtaler.\\n1.1.1.Særligt om samtalernes form', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " 'cd7283eb-3cb3-4d5f-81bd-95ac70b891fe': Document(page_content='Når det fremgår af § 33, stk. 1, 2. pkt., at personen kan vælge ”personligt digitalt fremmøde”, betyder det, at der vil være krav om, at der er en direkte billed- og lydforbindelse ved jobsamtalen (video). Personen får dermed en individuel ret til som hovedregel at bestemme formen på jobsamtaler i hele kontaktforløbet efter den første jobsamtale.', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '1979dc66-4820-463f-8310-faace278cbfb': Document(page_content='.  Jobcenteret eller arbejdsløshedskassen kan i den periode, de hver især varetager kontaktforløbet, udelukkende ændre jobsamtalens form fra telefonisk samtale eller samtale ved personligt digitalt fremmøde til personligt fremmøde, og ikke til en af de øvrige former. Det betyder fx, at jobcenteret eller arbejdsløshedskassen ikke kan ændre personens ønske om en jobsamtale ved personligt fremmøde til en telefonisk jobsamtale.', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'}),\n",
       " '6fd3df39-57cf-4163-a23e-c33d63b3bd87': Document(page_content='Det fremgår af § 33, stk. 2, 3. pkt., at jobsamtaler for personer på barsel efter § 27, stk. 2, skal holdes telefonisk eller ved personligt digitalt fremmøde (video), hvis personen anmoder herom. Personer på barsel har således ikke ret til at bestemme, at jobsamtalen f.eks. skal holdes pr. brev. Personen har alene ret til at bestemme, at jobsamtalen skal holdes telefonisk eller over video.\\nKontaktforløbet for en sygemeldt kan foregå uden kontakt til personen, hvis der er tale om alvorlig sygdom og kontakt ikke er hensigtsmæssig eller mulig på grund af den sygemeldtes helbredssituation (standby), jf. § 33, stk. 3.\\nIfølge § 33, stk. 4, kan arbejdsløshedskassen vælge at deltage ved personligt digitalt fremmøde i de jobsamtaler, hvor personen har valgt, at arbejdsløshedskassen skal deltage efter § 31, stk. 2, og § 32, stk. 2, medmindre personen anmoder om, at arbejdsløshedskassen deltager ved personligt fremmøde (fysisk fremmøde) sammen med personen. Det drejer sig om den første jobsamtale med jobcenteret efter de første 3 måneders ledighed og jobsamtalen om en obligatorisk intensiveret indsats, senest når personen har været ledig i 16 måneder.', metadata={'title': 'Vejledning om obligatorisk selvbooking af jobsamtaler for forskellige målgrupper'})}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_meta.contexts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
