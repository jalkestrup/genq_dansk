{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Union, Optional, Tuple\n",
    "import textdescriptives as td\n",
    "import spacy\n",
    "import uuid\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code for Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text_by_td(text_list: List[str], filter_type: bool=True) -> List[str]:\n",
    "    \"\"\"Filter nodes by the textdescriptives quality check\n",
    "\n",
    "    Args:\n",
    "    text_list> a list of stext strings\n",
    "    fiter_type: A boolean defining whether to filter by texts that passed (True) or failed (False) the textdescriptives quality check\n",
    "\n",
    "    Returns:\n",
    "    A list of text chunks that passed the textdescriptives quality check\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank(\"da\")\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    quality_pipe = nlp.add_pipe(\"textdescriptives/quality\")\n",
    "    docs = list(nlp.pipe(text_list))\n",
    "    filtered_texts = [doc.text for doc in docs if doc._.passed_quality_check==filter_type]\n",
    "    \n",
    "    return filtered_texts\n",
    "\n",
    "def filter_text_by_td(text_list: List[Union[str, Document]], filter_type: bool=True) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Filter documents by the textdescriptives quality check, converts strings to langchain Docs\n",
    "\n",
    "    Args:\n",
    "        text_list (List[Union[str, Document]]): A list of text strings or Document objects.\n",
    "        filter_type (bool): A boolean defining whether to filter by texts that passed (True) or failed (False) the textdescriptives quality check.\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: A list of Document objects that passed the textdescriptives quality check.\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank(\"da\")  # Assuming 'da' is the desired model\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    quality_pipe = nlp.add_pipe(\"textdescriptives/quality\")\n",
    "\n",
    "    # Process the texts with SpaCy, handling both strings and Document objects\n",
    "    processed_docs = list(nlp.pipe(doc.page_content if isinstance(doc, Document) else doc for doc in text_list))\n",
    "\n",
    "    # Filter based on the quality check, merge with existing metadata\n",
    "    filtered_docs = [Document(page_content=doc.text, metadata=getattr(original_doc, 'metadata', {}))\n",
    "                     for original_doc, doc in zip(text_list, processed_docs) if doc._.passed_quality_check == filter_type]\n",
    "\n",
    "    return filtered_docs\n",
    "\n",
    "def q_eval_system_prompt():\n",
    "    sys_prompt = \"\"\"Din opgave er at evaluere et givet tekstuddrag for at bestemme, om det er egnet til at danne grundlag for et generelt spørgsmål, der er relevant for eksempelvis en eksamen eller en test. \n",
    "    For at vurdere dette, skal du fokusere på følgende tre nøglekriterier:\n",
    "\n",
    "    1. Klarhed: Vurder, om teksten er formuleret klart og direkte, således at et spørgsmål til denne tekst, vil kunne besvares uden yderligere forklaringer. Teksten skal være læsbar og ikke usammenhængende i sin struktur.\n",
    "    \n",
    "    2. Konkret Information: Afgør, om uddraget indeholder specifikke, faktuelle informationer, der kan danne grundlag for et præcist og direkte spørgsmål. Teksten skal præsentere håndgribelige fakta eller data, som et spørgsmål kan baseres på.\n",
    "\n",
    "    3. Kontekstuel Helhed: Bedøm, om teksten leverer tilstrækkelig kontekst for at et spørgsmål baseret på uddraget vil være meningsfuldt og forståeligt uden behov for yderligere information. Teksten skal være selvstændig og give en fuld forståelse af det emne, der behandles.\n",
    "\n",
    "    Baseret på din evaluering:\n",
    "\n",
    "    - Tildel scoren 1, hvis tekstuddraget opfylder alle tre kriterier, og der kan formuleres et naturligt, klart og kontekstuelt meningsfuldt spørgsmål baseret på teksten.\n",
    "\n",
    "    - Tildel scoren 0, hvis tekstuddraget ikke opfylder et eller flere af de ovenstående kriterier, hvilket gør det uegnet til at danne grundlag for et generelt spørgsmål.\n",
    "    \"\"\"\n",
    "    return sys_prompt\n",
    "\n",
    "def q_eval_user_prompt(text: str) -> str:\n",
    "    \"\"\"Prepare the prompt for the API call.\"\"\"\n",
    "    \n",
    "    qa_egnet_tmlp = \"\"\"Du er en erfaren sagsbehandler. \n",
    "    Din Opgave:\n",
    "    Vurder det følgende tekstuddrag og angiv, om det er egnet til at stille et generelt spørgsmål til.\n",
    "\n",
    "    Uddrag:\n",
    "    {chunk_text}\n",
    "    \n",
    "    Returner din vurdering i følgende JSON-format:\n",
    "\n",
    "    {{\n",
    "    \"llm_score\": [indsæt enten 0 eller 1 her]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return qa_egnet_tmlp.format(chunk_text=text)\n",
    "\n",
    "\n",
    "def json_api_call(oai_client,system_prompt: str, user_prompt: str, oai_model: str=\"gpt-3.5-turbo-0125\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = oai_client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {}\n",
    "\n",
    "\n",
    "def filter_text_by_llm(text_list: List[Union[str, Document]]) -> List[Document]:\n",
    "    \"\"\"Filter text chunks by an LLM quality check\n",
    "\n",
    "    Args:\n",
    "        text_list (List[Union[str, Document]]): A list of text strings or Document objects.\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: A list of Document objects that passed the LLM quality check.\n",
    "    \"\"\"\n",
    "    \n",
    "    texts_passed_llm = []\n",
    "    system_prompt = q_eval_system_prompt()\n",
    "    oai_client = OpenAI()\n",
    "    for text_item in tqdm(text_list, desc=\"Evaluating texts\"):\n",
    "        # Extract text content from Document objects or use string directly\n",
    "        text_content = text_item.page_content if isinstance(text_item, Document) else text_item\n",
    "        \n",
    "        user_prompt = q_eval_user_prompt(text_content)\n",
    "        response = json_api_call(oai_client, system_prompt, user_prompt)\n",
    "        if response:\n",
    "            if response.get('llm_score') == 1:\n",
    "                # Preserve original Document object or create a new one if the input was a string\n",
    "                passed_text_doc = text_item if isinstance(text_item, Document) else Document(page_content=text_content)\n",
    "                texts_passed_llm.append(passed_text_doc)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            logging.error(f'Failed to evaluate the following text due to an earlier error:\\n{text_content}')\n",
    "\n",
    "    return texts_passed_llm\n",
    "\n",
    "def generate_question_template(text: str, num_q: int=1) -> str:\n",
    "    question_tmlp = \"\"\"Nedenfor er et uddrag (kontekst) fra en længere tekst:\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Givet ovenstående uddrag og ingen forudgående viden, er din opgave at generere præcis {num_questions_per_chunk} spørgsmål til teksten.\n",
    "    En sætning skal kun indeholde 1 spørgsmål, og spørgsmålet skal være formuleret kort og præcist. \n",
    "    Svaret til spørgsmålet, skal kunne findes i ovenstående uddrag.\n",
    "    Spørgsmålet skal indeholde specifik kontekst, således at spørgsmålet efterfølgende kan besvares entydigt og uden kendskab til uddraget. \n",
    "    Spørgsmålene skal stilles i et sprog som en borger uden juridisk ekspertise kan forstå.\n",
    "\n",
    "    Eksempel på et spørgsmål der ikke har en specifik kontekst, og som fejlagtigt indeholder 2 spørgsmål i 1 sætning: \n",
    "    \"Hvilket dokument har den nye vejledning erstattet, og hvornår blev den udsendt?\" -Da det ikke angivet hvilket dokument der er tale om, og derfor er svaret til spørgsmålet ikke entyidgt, uden kendskab til uddraget. Sætningen indeholder desuden 2 spørgsmål i samme sætning. \n",
    "\n",
    "    Eksempel på et godt spørgsmål, som kan besvares entydigt uden kendskab til uddraget:\n",
    "    \"Hvilke to indbetalinger udgør det samlede medlemsbidrag til en a-kasse?\" - Da det er klart hvad der spørges om, og der kun er 1 rigtigt svar i den givne lovtekst.\n",
    "    \"\"\"\n",
    "    return question_tmlp.format(context_str=text, num_questions_per_chunk=num_q)\n",
    "\n",
    "def question_api_call(oai_client, user_prompt: str, oai_model: str=\"gpt-4-0125-preview\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform the API call to evaluate the text.\"\"\"\n",
    "    try:\n",
    "        completion = oai_client.chat.completions.create(\n",
    "            model=oai_model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Din opgave er at stille præcise spørgsmål til et givet tekstuddrag og returnere en JSON med en liste af spørgsmål i formatet {{Q: [spørgsmål1, spørsmål2, ...}}.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_prompt\n",
    "                },\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f'JSON parsing failed: {e}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'API call failed: {e}')\n",
    "    return {'Q': 'API error'}\n",
    "\n",
    "class QuestionContextManager:\n",
    "    \"\"\"\n",
    "    Manages a collection of questions and their associated context chunks as Document objects.\n",
    "    Allows for adding questions with contexts and displaying a specified number of these question-context pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.questions: Dict[str, Document] = {}\n",
    "        self.contexts: Dict[str, Document] = {}\n",
    "        self.question_context_id_pairs: Dict[str, List[str]] = {}\n",
    "\n",
    "    def add_question_context(self, question: Document, context: Document):\n",
    "        \"\"\"\n",
    "        Adds a question and its associated context (both as Document objects) to the manager.\n",
    "        Generates unique IDs for both the question and the context, storing them and their association.\n",
    "\n",
    "        Parameters:\n",
    "        - question (Document): The Document object containing the question.\n",
    "        - context (Document): The Document object containing the context.\n",
    "        \"\"\"\n",
    "        unique_question_id = str(uuid.uuid4())\n",
    "        unique_context_id = str(uuid.uuid4())\n",
    "        self.questions[unique_question_id] = question\n",
    "        self.contexts[unique_context_id] = context\n",
    "        self.question_context_id_pairs[unique_question_id] = [unique_context_id]\n",
    "\n",
    "    @property\n",
    "    def question_context_pairs(self) -> List[Tuple[Document, List[Document]]]:\n",
    "        \"\"\"\n",
    "        Returns a list of tuples, each containing a question Document and a list of its associated context Documents.\n",
    "        \"\"\"\n",
    "        return [(self.questions[qid], [self.contexts[cid] for cid in self.question_context_id_pairs[qid]]) for qid in self.questions]\n",
    "\n",
    "    def display_question_context_pairs(self, num_pairs: int = None):\n",
    "        \"\"\"\n",
    "        Displays a specified number of question-context pairs. If no number is specified, all pairs are displayed.\n",
    "\n",
    "        Parameters:\n",
    "        - num_pairs (int, optional): The number of question-context pairs to display. If None, all pairs are displayed. Defaults to None.\n",
    "        \"\"\"\n",
    "        displayed_pairs = 0\n",
    "        for q_id, context_ids in self.question_context_id_pairs.items():\n",
    "            if num_pairs is not None and displayed_pairs >= num_pairs:\n",
    "                break\n",
    "\n",
    "            question = self.questions[q_id]\n",
    "            print(f\"Question: {question.page_content}\")\n",
    "            for c_id in context_ids:\n",
    "                context = self.contexts[c_id]\n",
    "                print(f\"\\nContext: {context.page_content}\")\n",
    "            print(\"-\" * 40)  # Separator for readability\n",
    "            displayed_pairs += 1\n",
    "\n",
    "    def filter_questions_by_length(self, min_length: int = 20, max_length: int = 150):\n",
    "        \"\"\"\n",
    "        Filters out questions that do not fall within the specified minimum and maximum character length.\n",
    "        Updates the object by removing questions and their associated contexts that do not meet the criteria.\n",
    "\n",
    "        Parameters:\n",
    "        - min_length (int): The minimum character length for questions to be kept. Default to 20.\n",
    "        - max_length (int): The maximum character length for questions to be kept. Default to 150.\n",
    "        \"\"\"\n",
    "        questions_to_remove = [q_id for q_id, question in self.questions.items()\n",
    "                               if not (min_length <= len(question.page_content) <= max_length)]\n",
    "\n",
    "        # Remove the questions and question_context pairs\n",
    "        for q_id in questions_to_remove:\n",
    "            del self.questions[q_id]\n",
    "            del self.question_context_id_pairs[q_id]\n",
    "\n",
    "        # Identify contexts that are no longer linked to any questions\n",
    "        contexts_to_remove = {context_id for context_id in self.contexts\n",
    "                              if all(context_id not in contexts for contexts in self.question_context_id_pairs.values())}\n",
    "\n",
    "        # Remove these contexts\n",
    "        for context_id in contexts_to_remove:\n",
    "            del self.contexts[context_id]\n",
    "\n",
    "        print(f\"Removed {len(questions_to_remove)} questions.\")\n",
    "        \n",
    "    def update_question_context_pairs(self, q_c_to_append: Dict[str, List[str]]):\n",
    "        \"\"\"\n",
    "        Appends the question-context matches to the existing question_context_id_pairs,\n",
    "        ensuring no duplicates are added.\n",
    "\n",
    "        Parameters:\n",
    "        - q_c_to_append (Dict[str, List[str]]): A dictionary with question IDs as keys and lists of context IDs to append as values.\n",
    "        \"\"\"\n",
    "        for q_id, c_id_list in q_c_to_append.items():\n",
    "            if q_id in self.question_context_id_pairs:\n",
    "                # Create a set from the existing IDs for quick lookup\n",
    "                existing_ids_set = set(self.question_context_id_pairs[q_id])\n",
    "                # Filter out duplicates while preserving order\n",
    "                filtered_c_id_list = [c_id for c_id in c_id_list if c_id not in existing_ids_set]\n",
    "                # Extend the existing list with the filtered, non-duplicate IDs\n",
    "                self.question_context_id_pairs[q_id].extend(filtered_c_id_list)\n",
    "            else:\n",
    "                # Directly assign the list if the q_id is not already present\n",
    "                self.question_context_id_pairs[q_id] = c_id_list\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<QuestionContextManager with {len(self.questions)} questions>\"    \n",
    "    \n",
    "\n",
    "def generate_questions(textContexts: List[Union[Document, str]], num_questions: int = 1, oai_model: str = \"gpt-4-0125-preview\", duplicate_metadata: bool = True) -> QuestionContextManager:\n",
    "    \"\"\"\n",
    "    Generates questions from a list of context Documents and returns a QuestionContextManager\n",
    "    containing the generated questions and their contexts.\n",
    "\n",
    "    Parameters:\n",
    "    - textContexts (List[Union[Document, str]]): A list of Document objects or strings to generate questions from.\n",
    "    - num_questions (int): Number of questions to generate per context. Default is 1.\n",
    "    - oai_model (str): The model to use for generating questions. Default is \"gpt-4-0125-preview\".\n",
    "    - duplicate_metadata (bool): If True, duplicate the metadata from context to the generated questions.\n",
    "\n",
    "    Returns:\n",
    "    QuestionContextManager: An object containing the generated questions and their contexts.\n",
    "    \"\"\"\n",
    "    oai_client = OpenAI()\n",
    "    result = QuestionContextManager()\n",
    "    for context in tqdm(textContexts):\n",
    "        #If input is simply a list of strings, convert to doc with empty metadata\n",
    "        if isinstance(context, str):\n",
    "            context = Document(page_content=context, metadata={})\n",
    "            \n",
    "        question_prompt = generate_question_template(context.page_content, num_questions)\n",
    "        response = question_api_call(oai_client, question_prompt, oai_model)  \n",
    "        try:\n",
    "            questions = response['Q']\n",
    "            for question_text in questions:\n",
    "                question_document = Document(page_content=question_text.strip(), metadata=context.metadata if duplicate_metadata else {})\n",
    "                result.add_question_context(question_document, context)\n",
    "        except KeyError as e:\n",
    "            print(f'Error parsing json response: {e}')\n",
    "    return result\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "def initialize_chroma_collection(client: chromadb.Client, collection_name: str, embedding_model: str, similarity_metric: str=\"cosine\") -> chromadb.Collection:\n",
    "    \"\"\"Initialize or reset a ChromaDB collection with a specified embedding model.\n",
    "\n",
    "    Args:\n",
    "        client (chromadb.Client): The ChromaDB client instance.\n",
    "        collection_name (str): The name of the collection to create or reset.\n",
    "        embedding_model (str): The embedding model to use for the collection.\n",
    "        similarity_metric (str): Similarity metric used for calculating embedding distance\n",
    "\n",
    "    Returns:\n",
    "        chromadb.Collection: The created ChromaDB collection.\n",
    "    \"\"\"\n",
    "    # Create a new collection with the specified embedding function\n",
    "    db_collection = client.create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(embedding_model, normalize_embeddings=True),\n",
    "        metadata={\"hnsw:space\": similarity_metric}\n",
    "    )\n",
    "    return db_collection\n",
    "\n",
    "def add_documents_to_chroma(collection: chromadb.Collection,  id_document_pairs: Dict[str, Union[List[str], List[Document]]], document_prepend: str):\n",
    "    \"\"\"Add documents to a specified ChromaDB collection with optional metadata.\n",
    "\n",
    "    Args:\n",
    "        collection (chromadb.Collection): The ChromaDB collection to add documents to.\n",
    "        id_document_pairs: Dict[str, Union[List[str], List[Document]]]: A Dict of IDs as keys and a list of Documents or strings as values\n",
    "        document_prepend (str, optional): String to prepend to documents prior embedding)\n",
    "    \"\"\"\n",
    "\n",
    "    #If values are Documents\n",
    "    if isinstance(list(id_document_pairs.values())[0], Document):\n",
    "        context_documents = list(id_document_pairs.values())\n",
    "        context_texts = [f'{document_prepend} {doc.page_content}' for doc in context_documents]\n",
    "        context_ids = list(id_document_pairs.keys())\n",
    "        context_metadatas = [{\"type\": \"context\", **doc.metadata} for doc in context_documents]\n",
    "    #If values are Strings\n",
    "    else:\n",
    "        context_texts = [f'{document_prepend} {doc}' for doc in id_document_pairs.values()]\n",
    "        context_ids = list(id_document_pairs.keys())\n",
    "        context_metadatas = [{\"type\": \"context\"} for _ in context_texts]\n",
    "    \n",
    "    collection.add(\n",
    "        documents=context_texts,\n",
    "        ids=context_ids,\n",
    "        metadatas=context_metadatas\n",
    "    )\n",
    "    \n",
    "\n",
    "def filter_context_candidates(chroma_db_collection, question_context_object: QuestionContextManager, top_k: int = 5, question_prepend: str='query:', dist_threshold: float = 0, include_origin_context: bool = False) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Filters context candidates for each question based on similarity scores and optionally includes the original context.\n",
    "\n",
    "    Parameters:\n",
    "    - chroma_db_collection: The database collection to query for context candidates.\n",
    "    - question_context_object: An object containing questions, contexts and queston-context ID pairs\n",
    "    - top_k: The number of top results to consider from the query.\n",
    "    - dist_threshold: The threshold for including additional contexts based on their distance from the ground truth context.\n",
    "    - include_origin_context: A boolean to indicate whether the original context should be included in the results.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary mapping each question ID to a list of filtered context candidate IDs.\n",
    "    \"\"\"\n",
    "    \n",
    "    query_filtered = {}\n",
    "    \n",
    "    question_texts = [f'{question_prepend} {doc.page_content}' for doc in question_context_object.questions.values()]\n",
    "\n",
    "    batch_query_result = chroma_db_collection.query(\n",
    "        query_texts=question_texts,\n",
    "        where={\"type\": \"context\"},\n",
    "        n_results=top_k\n",
    "    )\n",
    "\n",
    "    for idx, (q_id, q_document) in enumerate(question_context_object.questions.items()):\n",
    "        query_id_list = batch_query_result['ids'][idx]\n",
    "        query_distances_list = batch_query_result.get('distances', [])[idx]\n",
    "\n",
    "        ground_truth_id = question_context_object.question_context_id_pairs[q_id][0]\n",
    "        context_ids = []\n",
    "\n",
    "        if ground_truth_id in query_id_list:\n",
    "            gt_index = query_id_list.index(ground_truth_id)\n",
    "            gt_distance = query_distances_list[gt_index]\n",
    "\n",
    "            # Include higher-ranked items than the ground truth\n",
    "            context_ids.extend(query_id_list[:gt_index])\n",
    "\n",
    "            # Optionally include the ground truth\n",
    "            if include_origin_context:\n",
    "                context_ids.append(ground_truth_id)\n",
    "\n",
    "            # Include lower-ranked items within the distance threshold\n",
    "            for id_, distance in zip(query_id_list[gt_index + 1:], query_distances_list[gt_index + 1:]):\n",
    "                if abs(distance - gt_distance) <= dist_threshold:\n",
    "                    context_ids.append(id_)\n",
    "        else:\n",
    "            # If ground truth is not in the list, return the full list of querries (top_k)\n",
    "            context_ids.extend(query_id_list)\n",
    "\n",
    "        query_filtered[q_id] = context_ids\n",
    "\n",
    "    return query_filtered\n",
    "\n",
    "def c_eval_system_prompt():\n",
    "    sys_prompt = \"\"\"Din opgave er at evaluere hvorvidt et givent tekstuddrag indeholder svaret til et spørgsmål. Du skal alene vurdere om uddraget indeholder svaret, og ikke om svaret er korrekt.\n",
    "\n",
    "    - Tildel scoren 1, hvis tekstuddraget indeholder svaret til spørgsmålet.\n",
    "\n",
    "    - Tildel scoren 0, hvis tekstuddraget ikke kan bruges til at besvare spørgsmålet.\n",
    "    \"\"\"\n",
    "    return sys_prompt\n",
    "\n",
    "def c_eval_user_prompt(question: str, context: str) -> str:\n",
    "    \"\"\"Prepare the prompt for the API call.\"\"\"\n",
    "    \n",
    "    qa_egnet_tmlp = \"\"\"Din Opgave:\n",
    "    \n",
    "    Vurder om følgende spørgsmål kan besvares ud fra den givne kontekst i tekstuddraget:\n",
    "    \n",
    "    spørgsmål:\n",
    "    {insert_question}\n",
    "    \n",
    "    tekstuddrag:\n",
    "    {insert_context}\n",
    "    \n",
    "    Returner din vurdering i følgende JSON-format:\n",
    "\n",
    "    {{\n",
    "    \"context_score\": [indsæt enten 0 eller 1 her]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return qa_egnet_tmlp.format(insert_question=question, insert_context=context)\n",
    "\n",
    "\n",
    "def context_question_llm_assesment(context_candidates, question_context_object: QuestionContextManager) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Iterates over the context candidate texts and uses a LLM call to assess whether the context matches the corresponding question\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary mapping each question ID to a list of context IDs, that according to the LLM can be used to answer the question\n",
    "    \"\"\"\n",
    "    question_context_matches = {}\n",
    "    system_prompt = c_eval_system_prompt()\n",
    "    oai_client = OpenAI()\n",
    "    \n",
    "    for q_id, c_id_list in tqdm(context_candidates.items()):\n",
    "        question_text = question_context_object.questions[q_id].page_content\n",
    "        for c_id in c_id_list:\n",
    "            context_text = question_context_object.contexts[c_id].page_content\n",
    "            user_prompt = c_eval_user_prompt(question=question_text, context=context_text)\n",
    "            response = json_api_call(oai_client, system_prompt, user_prompt)\n",
    "            if response:\n",
    "                if response['context_score'] == 1:\n",
    "                    if q_id not in question_context_matches:\n",
    "                        question_context_matches[q_id] = [c_id]\n",
    "                    else:\n",
    "                        question_context_matches[q_id].append(c_id)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                logging.error(f'Failed to evaluate below text due to an earlier error. \\n')\n",
    "    return question_context_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for testing and running all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "#Contains OpenAI API key\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>html_content</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om regulering af satser fra 1. janu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om satser i 2024 for betaling af ud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om obligatorisk selvbooking af jobs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning til bekendtgørelse om tilskud til s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.retsinformation.dk/eli/retsinfo/20...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.</td>\n",
       "      <td>&lt;div class=\"document-content\" id=\"restylingRoo...</td>\n",
       "      <td>Vejledning om fleksløntilskud m.v.\\n1.Indledni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "1  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "2  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "3  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "4  https://www.retsinformation.dk/eli/retsinfo/20...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Vejledning om regulering af satser fra 1. janu...   \n",
       "1  Vejledning om satser i 2024 for betaling af ud...   \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...   \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...   \n",
       "4                 Vejledning om fleksløntilskud m.v.   \n",
       "\n",
       "                                        html_content  \\\n",
       "0  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "1  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "2  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "3  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "4  <div class=\"document-content\" id=\"restylingRoo...   \n",
       "\n",
       "                                        text_content  \n",
       "0  Vejledning om regulering af satser fra 1. janu...  \n",
       "1  Vejledning om satser i 2024 for betaling af ud...  \n",
       "2  Vejledning om obligatorisk selvbooking af jobs...  \n",
       "3  Vejledning til bekendtgørelse om tilskud til s...  \n",
       "4  Vejledning om fleksløntilskud m.v.\\n1.Indledni...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load from hub\n",
    "ds_vejledninger = load_dataset(\n",
    "    \"jealk/dk_retrieval_benchmark\",\n",
    "    \"retsinformation\",\n",
    "    split=\"train\",\n",
    "    #download_mode=\"force_redownload\",\n",
    ")\n",
    "\n",
    "# Create pandas dataframe from the dataset using the huggingface datasets library\n",
    "df_vejledninger = ds_vejledninger.to_pandas()\n",
    "df_vejledninger.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-base-v2\")\n",
    "\n",
    "def token_length_function(text_input):\n",
    "  return len(tokenizer.encode(text_input, add_special_tokens=False))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 0,\n",
    "    length_function = token_length_function,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \"]\n",
    ")\n",
    "\n",
    "#For some reason, Langchains text splitter is horribly slow (compared to llamaindex) takes 2+ minutes to run on my CPU\n",
    "split_documents = text_splitter.create_documents(list(df_vejledninger[\"text_content\"]), metadatas = [{\"title\": title} for title in df_vejledninger[\"title\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run documents through textdesctiptives quality check, returns the Documents that passed\n",
    "docs_passed_td = filter_text_by_td(split_documents[0:300], filter_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating texts: 100%|██████████| 50/50 [00:36<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#Run the documents through LLM quality check, return the documents that passed\n",
    "docs_passed_llm = filter_text_by_llm(docs_passed_td[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:19<00:00,  1.97s/it]\n"
     ]
    }
   ],
   "source": [
    "#Generate questions for a sub-sample of the passed documents\n",
    "qc_meta = generate_questions(docs_passed_llm[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 questions.\n",
      "Question: Hvem skal regulere løbende erstatninger tilkendt før 1. januar 2024?\n",
      "\n",
      "Context: De private arbejdsskadeforsikringsselskaber samt de arbejdsgivere, der er fritaget for at afgive risikoen efter loven, skal selv regulere løbende erstatninger, som er tilkendt før 1. januar 2024. Ved løbende erstatninger tilkendt i 2024 vil det fremgå af Arbejdsmarkedets Erhvervssikrings afgørelse, hvilke beløb, der skal udbetales i 2024.\n",
      "----------------------------------------\n",
      "Question: Hvordan beregnes grundlønnen for løbende erstatninger for tab af erhvervsevne ifølge Arbejdstilsynets bilag fra den 5. januar 2024?\n",
      "\n",
      "Context: Arbejdstilsynet, den 5. januar 2024\n",
      "Sine Frederiksen\n",
      "/ Helle Klostergaard Christensen\n",
      "Bilag 1\n",
      "Bilaget indeholder eksempler på beregninger af kapitalerstatninger, godtgørelsesbeløb og overgangsbeløb samt løbende erstatninger og godtgørelser, som tilskadekomne eller dennes efterladte har ret til efter lov om arbejdsskadesikring, lov om sikring mod følger af arbejdsskade, lov om arbejdsskadeforsikring og lov om forsikring mod følger af ulykkestilfælde.\n",
      "Arbejdsskader indtruffet i tiden 1. juli 2024 til 31. december 2024\n",
      "Til brug ved beregning og fremtidig regulering af løbende erstatninger for tab af erhvervsevne og tab af forsørger samt uddannelsesgodtgørelser beregnes grundlønnen (§ 24 a) ved at multiplicere den fastsatte årsløn med forholdet mellem den maksimale årsløn pr. 1. januar 2024 (608.000 kr.) og den maksimale årsløn på skadestidspunktet (608.000 kr.), det vil sige:\n",
      "Grundløn = årsløn × 608.000 / 608.000.\n",
      "Beløbet afrundes til hele kroner. Grundlønnen svarer til årslønnen reguleret tilbage til niveauet pr. 1. januar 2024.\n",
      "----------------------------------------\n",
      "Question: Hvilke målgrupper er omfattet af pligten til selvbooking ifølge loven om en aktiv beskæftigelsesindsats fra 22. maj 2022?\n",
      "\n",
      "Context: Indledning\n",
      "Denne vejledning omfatter pligt til selvbooking for visse målgrupper i lov om en aktiv beskæftigelsesindsats, jf. lovbekendtgørelse nr. 701 af 22. maj 2022. Pligt til selvbooking for sygedagpengemodtagere er ikke omfattet af denne vejledning.\n",
      "Pligt til selvbooking gælder for dagpengemodtagere, kontanthjælps- og uddannelseshjælpsmodtagere, overgangsydelsesmodtagere, som ikke er omfattet af introduktionsprogrammet efter integrationsloven, personer i jobafklaringsforløb, personer i ressourceforløb, fleksjobvisiterede, som modtager ledighedsydelse, og personer i revalideringsforløb.\n",
      "Pligt til selvbooking omfatter jobsamtaler efter kapitel 7 i lov om en aktiv beskæftigelsesindsats. Dagpengemodtagere har derudover pligt til at selvbooke rådighedssamtaler i arbejdsløshedskassen, hvis arbejdsløshedskassen har fastsat, at der skal ske selvbooking af en rådighedssamtale, jf. rådighedsbekendtgørelsens § 10 (bekendtgørelse nr. 1210 af 28. september 2023).\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Filter out documents wherein the questions are shorter or longer than specified character length and display 3 examples,\n",
    "qc_meta.filter_questions_by_length(min_length=20, max_length=150) #default values\n",
    "qc_meta.display_question_context_pairs(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializes a Chroma DB instance and adds the Contexts to the DB\n",
    "chroma_client = chromadb.Client()\n",
    "collection_name = \"qc_collection\"\n",
    "embedding_model = 'intfloat/multilingual-e5-base'\n",
    "\n",
    "#For testing, delte previous collection \n",
    "#chroma_client.delete_collection(collection_name)\n",
    "    \n",
    "db_collection = initialize_chroma_collection(chroma_client, collection_name, embedding_model)\n",
    "add_documents_to_chroma(db_collection, qc_meta.contexts, document_prepend='passage:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ce7f0145-6b81-4993-bf04-ec70915545bd': [],\n",
       " 'f728d57c-9839-4069-9bba-7bbba99d8e87': ['c357410f-4a94-44c4-9a8f-3810d5b958bd'],\n",
       " 'a40606c7-f82a-484a-8372-dabf074b66c3': ['1f2971c7-495c-4b0b-8d3a-d2f37f0505d0'],\n",
       " '4222f9ec-74b7-4f58-a14f-12ed330e55c6': ['ad0802f9-381c-41f8-9b24-ac17313e5d66',\n",
       "  'e1f09c75-b310-46e2-9d8c-74c2d6f5247b'],\n",
       " 'adedee21-2125-49cd-9891-d387c4a4b70d': ['1f2971c7-495c-4b0b-8d3a-d2f37f0505d0',\n",
       "  'e1f09c75-b310-46e2-9d8c-74c2d6f5247b'],\n",
       " 'f7657ebe-228a-429b-89bd-a34f3660e583': [],\n",
       " '523e5d48-bf77-435e-ad2b-cf56eb56347d': ['ad0802f9-381c-41f8-9b24-ac17313e5d66',\n",
       "  '1f2971c7-495c-4b0b-8d3a-d2f37f0505d0',\n",
       "  'd3378632-21c2-4ab7-bdee-fdbf42b3fc7f'],\n",
       " '02516716-f8ae-4c33-ae9d-15cd255342d3': ['ad0802f9-381c-41f8-9b24-ac17313e5d66',\n",
       "  'd3378632-21c2-4ab7-bdee-fdbf42b3fc7f'],\n",
       " 'cdb5511b-fdfc-40c1-88a5-e449b603734f': ['ad0802f9-381c-41f8-9b24-ac17313e5d66'],\n",
       " '0bd4f8ae-3a2d-445f-98ad-46e9dd41220e': ['d3378632-21c2-4ab7-bdee-fdbf42b3fc7f',\n",
       "  '4d72b0f8-abeb-4cd1-ab9c-5944ff383cfe',\n",
       "  '768df1cd-6257-4b27-ba37-6ff4cde0fe3b',\n",
       "  '1f2971c7-495c-4b0b-8d3a-d2f37f0505d0']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identify a list of context candidates that might be an additional 'match' to the generated questions\n",
    "context_candidates_id = filter_context_candidates(db_collection, qc_meta, dist_threshold=0.05, include_origin_context=False)\n",
    "context_candidates_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "#Use LLM calls to assess whether the potential contexts does indeed contain the answer to the given question\n",
    "question_context_matches = context_question_llm_assesment(context_candidates_id, qc_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the built-in class function to update the context question pairs, given the verified list\n",
    "qc_meta.update_question_context_pairs(question_context_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ce7f0145-6b81-4993-bf04-ec70915545bd': ['c357410f-4a94-44c4-9a8f-3810d5b958bd'],\n",
       " 'f728d57c-9839-4069-9bba-7bbba99d8e87': ['f10565b5-9e32-4f30-b6f2-75c879a0e6b0'],\n",
       " 'a40606c7-f82a-484a-8372-dabf074b66c3': ['e1f09c75-b310-46e2-9d8c-74c2d6f5247b',\n",
       "  '1f2971c7-495c-4b0b-8d3a-d2f37f0505d0'],\n",
       " '4222f9ec-74b7-4f58-a14f-12ed330e55c6': ['1f2971c7-495c-4b0b-8d3a-d2f37f0505d0'],\n",
       " 'adedee21-2125-49cd-9891-d387c4a4b70d': ['a54cc7fb-c05a-4e02-950b-bd62e7218673',\n",
       "  '1f2971c7-495c-4b0b-8d3a-d2f37f0505d0',\n",
       "  'e1f09c75-b310-46e2-9d8c-74c2d6f5247b'],\n",
       " 'f7657ebe-228a-429b-89bd-a34f3660e583': ['f75cb4e8-5f6a-48a4-88e4-1b3a5e9a6696'],\n",
       " '523e5d48-bf77-435e-ad2b-cf56eb56347d': ['768df1cd-6257-4b27-ba37-6ff4cde0fe3b',\n",
       "  '1f2971c7-495c-4b0b-8d3a-d2f37f0505d0',\n",
       "  'd3378632-21c2-4ab7-bdee-fdbf42b3fc7f'],\n",
       " '02516716-f8ae-4c33-ae9d-15cd255342d3': ['4d72b0f8-abeb-4cd1-ab9c-5944ff383cfe',\n",
       "  'ad0802f9-381c-41f8-9b24-ac17313e5d66',\n",
       "  'd3378632-21c2-4ab7-bdee-fdbf42b3fc7f'],\n",
       " 'cdb5511b-fdfc-40c1-88a5-e449b603734f': ['d3378632-21c2-4ab7-bdee-fdbf42b3fc7f',\n",
       "  'ad0802f9-381c-41f8-9b24-ac17313e5d66'],\n",
       " '0bd4f8ae-3a2d-445f-98ad-46e9dd41220e': ['ad0802f9-381c-41f8-9b24-ac17313e5d66',\n",
       "  '768df1cd-6257-4b27-ba37-6ff4cde0fe3b']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the updated list\n",
    "qc_meta.question_context_id_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
